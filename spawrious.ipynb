{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzVjng0cq4V",
        "outputId": "e5a3f257-d1f8-437e-f9fc-5de031c43f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1252, done.\u001b[K\n",
            "remote: Counting objects: 100% (657/657), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 1252 (delta 574), reused 533 (delta 532), pack-reused 595\u001b[K\n",
            "Receiving objects: 100% (1252/1252), 1.03 MiB | 4.11 MiB/s, done.\n",
            "Resolving deltas: 100% (739/739), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HApsEKnU5rM2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxCp4JTdivj",
        "outputId": "8d63436c-a1ac-4b0e-dc39-6604a4149280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjylGMPbTZEl",
        "outputId": "bfe71ce1-e026-466a-ab27-e2a2be6ffd67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa_F2E_wzly"
      },
      "source": [
        "Convert images to /content/...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_g-N8vfERdY",
        "outputId": "b886bd96-9ee0-4d9b-c883-c30c5ab494ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-nccl-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=4823641a1427406f8934adc0c94fd19175a908d90b215029baad2bbc550a82ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wilds\n",
        "# 安装wilds模块\n",
        "# 使用wilds可以帮助研究人员更好地评估他们的机器学习算法在实际应用中的性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_kfReEsJhNO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQUkwkKPp6Us"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "o-gdbwEqDy2A",
        "outputId": "ed3c2c8a-7e86-43e2-f11c-4dcd0f6d090d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'download_spawrious' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6bee08df79ff>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 制定下载数据集所需要的目录\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdownload_spawrious\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 调用其他函数下载其他数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'download_spawrious' is not defined"
          ]
        }
      ],
      "source": [
        "data_dir = \"/content/drive/MyDrive/ip\"\n",
        "# 制定下载数据集所需要的目录\n",
        "\n",
        "download_spawrious(data_dir)\n",
        "# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\n",
        "# 调用其他函数下载其他数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG-PvtDxJOTD"
      },
      "outputs": [],
      "source": [
        "# 创建 SpawriousO2O_easy 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip/spawrious224\"\n",
        "\n",
        "spawrious_easy = SpawriousO2O_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousO2O_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousO2O_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IZdwtDLlbsq"
      },
      "outputs": [],
      "source": [
        "env1 = spawrious_easy[1]\n",
        "env2 = spawrious_easy[2]\n",
        "test = spawrious_easy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avZK4NVnUZxW"
      },
      "outputs": [],
      "source": [
        "env1_medium = spawrious_medium[1]\n",
        "env2_medium = spawrious_medium[2]\n",
        "test_medium = spawrious_medium[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAxRKr-oNWHg",
        "outputId": "cf874ea0-0f54-4ce8-fd4f-2137e7da7462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12672\n",
            "12672\n",
            "25344\n"
          ]
        }
      ],
      "source": [
        "env1_hard = spawrious_hard[1]\n",
        "env2_hard = spawrious_hard[2]\n",
        "test_hard = spawrious_hard[0]\n",
        "\n",
        "print(len(env1_hard))\n",
        "print(len(env2_hard))\n",
        "print(len(test_hard))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs19CK7hOHN"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/ip/testdata_medium.pt'\n",
        "torch.save(test_medium, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZFQQiRyNN71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVYsqDeDtlGw"
      },
      "outputs": [],
      "source": [
        "torch.save(test, '/content/drive/MyDrive/ip/testdata.pt')\n",
        "torch.save(test_medium, '/content/drive/MyDrive/ip/testdata_medium.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWtjDTrG4ho"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:\n"
      ],
      "metadata": {
        "id": "JKGmsTaZZV_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "FTvxrF-j-BTL",
        "outputId": "1d20b852-ffc3-4dc6-a3e3-b1841ddee006"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_tensor = env1_hard[3072][0]\n",
        "label = env1_hard[3072][1]\n",
        "\n",
        "image_array = image_tensor.numpy()\n",
        "image_array_rgb = np.transpose(image_array, (1, 2, 0))\n",
        "plt.imshow(image_array_rgb)\n",
        "plt.axis('off')  # 关闭坐标轴\n",
        "plt.show()\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YGkMyccsmA3i",
        "outputId": "89dd2518-9e30-4d8c-9f57-6469938aba76"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'env1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9cbc88499455>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbulldog_filter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12288\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mbulldog_filter1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11024\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m412\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env1' is not defined"
          ]
        }
      ],
      "source": [
        "bulldog_filter1 = []\n",
        "bulldog_filter2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_filter_medium1 = []\n",
        "bulldog_filter_medium2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_medium2.append(env2_medium[i][0])\n"
      ],
      "metadata": {
        "id": "EIMPsQZtZcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJo9hZ3jOOW5"
      },
      "outputs": [],
      "source": [
        "bulldog_filter_hard1 = []\n",
        "bulldog_filter_hard2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkefLJvgPCDC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "bulldog_filter_hard1_np = np.array(bulldog_filter_hard1)\n",
        "bulldog_filter_hard2_np = np.array(bulldog_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_filter_hard1.npy', bulldog_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_filter_hard2.npy', bulldog_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6X3shuzsRIJ",
        "outputId": "dc299d36-52c8-4e50-8ffe-096415c79af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(bulldog_filter1))\n",
        "print(len(bulldog_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VpDUX6-toEF"
      },
      "outputs": [],
      "source": [
        "bulldog1 = []\n",
        "bulldog2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog1.append(env1[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_medium1 = []\n",
        "bulldog_medium2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "f9TleOcUiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OUywRWdO3_U"
      },
      "outputs": [],
      "source": [
        "bulldog_hard1 = []\n",
        "bulldog_hard2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37zsNDs_zV8E"
      },
      "outputs": [],
      "source": [
        "dachshund_filter1 = []\n",
        "dachshund_filter2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_filter_medium1 = []\n",
        "dachshund_filter_medium2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "sWIoCKWbiw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgctYFvYQPNW"
      },
      "outputs": [],
      "source": [
        "dachshund_filter_hard1 = []\n",
        "dachshund_filter_hard2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnYhdMOyQ2NP"
      },
      "outputs": [],
      "source": [
        "\n",
        "dachshund_filter_hard1_np = np.array(dachshund_filter_hard1)\n",
        "dachshund_filter_hard2_np = np.array(dachshund_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_filter_hard1.npy', dachshund_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_filter_hard2.npy', dachshund_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws4bfU992EmT",
        "outputId": "74817a67-06fb-443f-a861-24f024e967ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(dachshund_filter1))\n",
        "print(len(dachshund_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-neQ3YR2Ewg"
      },
      "outputs": [],
      "source": [
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3072, 3072+3072):\n",
        "  dachshund1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756, 2756+2756):\n",
        "  dachshund2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "L5lNhT5LRJSp",
        "outputId": "52cc8f01-ad77-4f8e-bbb4-9f34a99012d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3072/3072 [17:12<00:00,  2.98it/s]\n",
            "100%|██████████| 2756/2756 [14:45<00:00,  3.11it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-539abb20bb00>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdachshund_hard2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv2_hard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdachshund_hard1_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdachshund_hard1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdachshund_hard2_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdachshund_hard2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "dachshund_hard1 = []\n",
        "dachshund_hard2 = []\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "for i in tqdm(range(3072, 3072+3072)):\n",
        "  dachshund_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756, 2756+2756)):\n",
        "  dachshund_hard2.append(env2_hard[i][0])\n",
        "\n",
        "dachshund_hard1_np = np.array(dachshund_hard1)\n",
        "dachshund_hard2_np = np.array(dachshund_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_hard1.npy', dachshund_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_hard2.npy', dachshund_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdAXRNhPiawJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "dachshund_hard1_np = np.array(dachshund_hard1)\n",
        "dachshund_hard2_np = np.array(dachshund_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_hard1.npy', dachshund_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_hard2.npy', dachshund_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_NDN7bK2e9X",
        "outputId": "4fbcabd8-db32-44d4-f446-ee501b62fa03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(dachshund1))\n",
        "print(len(dachshund2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaW3o4hj2e_5"
      },
      "outputs": [],
      "source": [
        "dachshund_filter1_np = np.array(dachshund_filter1)\n",
        "dachshund_filter2_np = np.array(dachshund_filter2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_filter1.npy', dachshund_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_filter2.npy', dachshund_filter2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmGrmbhU2fB5"
      },
      "outputs": [],
      "source": [
        "dachshund1_np = np.array(dachshund1)\n",
        "dachshund2_np = np.array(dachshund2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/dachshund1.npy', dachshund1_np)\n",
        "np.save('/content/drive/MyDrive/ip/dachshund2.npy', dachshund2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftTNGcd2m0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNUdbmZ2m45"
      },
      "outputs": [],
      "source": [
        "labrador_filter1 = []\n",
        "labrador_filter2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "errs4ycoihsi"
      },
      "outputs": [],
      "source": [
        "labrador_filter_hard1 = []\n",
        "labrador_filter_hard2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter_hard2.append(env2_hard[i][0])\n",
        "\n",
        "labrador_filter_hard1_np = np.array(labrador_filter_hard1)\n",
        "labrador_filter_hard2_np = np.array(labrador_filter_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip/labrador_filter_hard1.npy', labrador_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/labrador_filter_hard2.npy', labrador_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsjBViSE2m6-",
        "outputId": "21026ea7-6367-41ea-f241-1543b1bd2379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador_filter1))\n",
        "print(len(labrador_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwSyffW2m9D"
      },
      "outputs": [],
      "source": [
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3072*2, 3072*3):\n",
        "  labrador1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756*2, 2756*3):\n",
        "  labrador2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "WdFYxleUj3ce",
        "outputId": "bd75eeb8-cea3-4a36-9f8d-7ea4c0d32476"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3072/3072 [20:35<00:00,  2.49it/s]\n",
            "100%|██████████| 2756/2756 [22:46<00:00,  2.02it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0d4ebd7f4210>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlabrador_hard2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv2_hard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlabrador_hard1_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabrador_hard1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlabrador_hard2_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabrador_hard2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_hard1 = []\n",
        "labrador_hard2 = []\n",
        "for i in tqdm(range(3072*2, 3072*3)):\n",
        "  labrador_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756*2, 2756*3)):\n",
        "  labrador_hard2.append(env2_hard[i][0])\n",
        "\n",
        "labrador_hard1_np = np.array(labrador_hard1)\n",
        "labrador_hard2_np = np.array(labrador_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip/labrador_hard1.npy', labrador_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/labrador_hard2.npy', labrador_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbOg21uK0C1L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "labrador_hard1_np = np.array(labrador_hard1)\n",
        "labrador_hard2_np = np.array(labrador_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip/labrador_hard1.npy', labrador_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/labrador_hard2.npy', labrador_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H77kpkdb2m-9",
        "outputId": "7e9dac0c-cf6c-40cf-ece7-06c295af4841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador1))\n",
        "print(len(labrador2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsH4R2d0DbW4"
      },
      "outputs": [],
      "source": [
        "labrador_filter1_np = np.array(labrador_filter1)\n",
        "labrador_filter2_np = np.array(labrador_filter2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip/labrador_filter1.npy', labrador_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip/labrador_filter2.npy', labrador_filter2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej9GfiA6DbdD"
      },
      "outputs": [],
      "source": [
        "labrador1_np = np.array(labrador1)\n",
        "labrador2_np = np.array(labrador2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip/labrador1.npy', labrador1_np)\n",
        "np.save('/content/drive/MyDrive/ip/labrador2.npy', labrador2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQtiHE4WDbfZ"
      },
      "outputs": [],
      "source": [
        "corgi_filter1 = []\n",
        "corgi_filter2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-mdt_fa0PXD"
      },
      "outputs": [],
      "source": [
        "corgi_filter_hard1 = []\n",
        "corgi_filter_hard2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3FRKNaS0ws6"
      },
      "outputs": [],
      "source": [
        "corgi_filter_hard1_np = np.array(corgi_filter_hard1)\n",
        "corgi_filter_hard2_np = np.array(corgi_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/corgi_filter_hard1.npy', corgi_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/corgi_filter_hard2.npy', corgi_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO4h8kzKDbhh",
        "outputId": "39abb8e5-30a4-4e6d-d167-c61603e550b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador_filter1))\n",
        "print(len(labrador_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7IptW5pIsFD"
      },
      "outputs": [],
      "source": [
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3072*3, 3072*4):\n",
        "  corgi1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756*3, 2756*4):\n",
        "  corgi2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDJY8xv73gIe",
        "outputId": "2b7ac503-2015-4bcf-859c-2b590e83a25e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3072/3072 [16:23<00:00,  3.12it/s]\n",
            "100%|██████████| 2756/2756 [14:43<00:00,  3.12it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "corgi_hard1 = []\n",
        "corgi_hard2 = []\n",
        "for i in tqdm(range(3072*3, 3072*4)):\n",
        "  corgi_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756*3, 2756*4)):\n",
        "  corgi_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOYWgQ7GsbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ugpaEp_Lcc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi_hard1_np = np.array(corgi_hard1)\n",
        "corgi_hard2_np = np.array(corgi_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/corgi_hard1.npy', corgi_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip/corgi_hard2.npy', corgi_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWjce4R9I5y7",
        "outputId": "43df0f35-9264-4270-9d2b-07343a6268b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi1))\n",
        "print(len(corgi2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qep-GkqRI51d"
      },
      "outputs": [],
      "source": [
        "corgi_filter1_np = np.array(corgi_filter1)\n",
        "corgi_filter2_np = np.array(corgi_filter2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/corgi_filter1.npy', corgi_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip/corgi_filter2.npy', corgi_filter2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSt-PjHa0vxU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IePUzIhvI53q"
      },
      "outputs": [],
      "source": [
        "corgi1_np = np.array(corgi1)\n",
        "corgi2_np = np.array(corgi2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip/corgi1.npy', corgi1_np)\n",
        "np.save('/content/drive/MyDrive/ip/corgi2.npy', corgi2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49q4nMcrOk7q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQyAlC-VAall"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip/corgi1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip/corgi2.npy')\n",
        "corgi_filter1 = np.load('/content/drive/MyDrive/ip/corgi_filter1.npy')\n",
        "corgi_filter2 = np.load('/content/drive/MyDrive/ip/corgi_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_S__AIVuAhL3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi_hard1 = np.load('/content/drive/MyDrive/ip/corgi_hard1.npy')\n",
        "corgi_hard2 = np.load('/content/drive/MyDrive/ip/corgi_hard2.npy')\n",
        "corgi_filter_hard1 = np.load('/content/drive/MyDrive/ip/corgi_filter_hard1.npy')\n",
        "corgi_filter_hard2 = np.load('/content/drive/MyDrive/ip/corgi_filter_hard2.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZwOYqQjbC7l"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip/labrador_filter1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip/labrador_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504i9eqpyujC"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip/dachshund_filter1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip/dachshund_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaok8gKyvUb"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip/bulldog_filter1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip/bulldog_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um-nuTB-_Rp1",
        "outputId": "f7fdd336-42dc-4e5b-9d63-8f952bd5cd59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from transformers import CLIPModel\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:"
      ],
      "metadata": {
        "id": "nrEh7ntajEry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pBlF055BBqm",
        "outputId": "edeae3f9-423a-4f7a-e85f-591c51f20390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between the images: 0.8701601028442383\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "inputs1 = corgi1[1].unsqueeze(0).to(device)  # 假设image1是PIL图像或类似的\n",
        "inputs2 = corgi1[2].unsqueeze(0).to(device)  # 假设image2是PIL图像或类似的\n",
        "\n",
        "with torch.no_grad():\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    features2 = model.get_image_features(inputs2)\n",
        "\n",
        "similarity = F.cosine_similarity(features1, features2).item()\n",
        "print(\"Similarity between the images:\", similarity)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX1xyS2g-QEt"
      },
      "outputs": [],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def similar_pair(i, class_filter, class_tensor):\n",
        "  similarity = 0\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > similarity:\n",
        "        similarity = res\n",
        "        index = j\n",
        "\n",
        "    pair1 = class_filter[i]\n",
        "    pair2 = class_tensor[index]\n",
        "    image_pair = (pair1, pair2)\n",
        "\n",
        "    return image_pair\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXMRhWn6wi1N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def similar_pair(class_filter, class_tensor):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "\n",
        "        inputs1 = torch.tensor(class_filter).to(device)\n",
        "        features1 = model.get_image_features(inputs1)\n",
        "\n",
        "        inputs2 = torch.tensor(class_tensor).to(device)\n",
        "        features2 = model.get_image_features(inputs2)\n",
        "\n",
        "        similarities = F.cosine_similarity(features1.unsqueeze(1), features2.unsqueeze(0), dim=2)\n",
        "\n",
        "        # 获取每个输入图像最相似的图像的索引\n",
        "        max_indices = torch.argmax(similarities, dim=1)\n",
        "\n",
        "        # 获取最相似的图像对\n",
        "        pairs1 = class_filter\n",
        "        pairs2 = class_tensor[max_indices]\n",
        "\n",
        "        # 构建元组，前面是两对tensor，后面是label\n",
        "        image_pairs = list(zip(pairs1, pairs2))\n",
        "        image_pair_labels = [(pair, class_name) for pair in image_pairs]\n",
        "\n",
        "        return image_pair_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "lnjYcrI13fFj",
        "outputId": "083a4611-8e23-47be-854c-f1fc3ded8ec5"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.33 GiB is free. Process 17113 has 14.44 GiB memory in use. Of the allocated memory 13.62 GiB is allocated by PyTorch, and 455.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-949dc1e56e1f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorgi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfeatures2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mget_image_features\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         vision_outputs = self.vision_model(\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_layrnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 )\n\u001b[1;32m    635\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m                 layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    637\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.702\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.33 GiB is free. Process 17113 has 14.44 GiB memory in use. Of the allocated memory 13.62 GiB is allocated by PyTorch, and 455.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "inputs1 = torch.tensor(corgi_filter1).to(device)\n",
        "features1 = model.get_image_features(inputs1)\n",
        "\n",
        "inputs2 = torch.tensor(corgi1).to(device)\n",
        "features2 = model.get_image_features(inputs2)\n",
        "\n",
        "similarities = F.cosine_similarity(features1.unsqueeze(1), features2.unsqueeze(0), dim=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "W4KmCdocQh8h",
        "outputId": "e13fefbb-984b-49b1-f046-a8624f28b62f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [42:01<00:00, 26.27s/it]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (96, 2) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4f8ac56d134>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcorgi_pairs1_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorgi_pairs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 保存为 .npy 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (96, 2) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs1 = []\n",
        "for i in tqdm(range(len(corgi_filter1))):\n",
        "    pair = similar_pair(i, corgi_filter1, corgi1, 'corgi')\n",
        "    corgi_pairs1.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PRdG5HFlcK"
      },
      "outputs": [],
      "source": [
        "corgi_pairs1_np = np.array(corgi_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/corgi_pairs1.npy', corgi_pairs1_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoN6G33F179",
        "outputId": "757f442b-39b0-4fe1-bd47-942accdf33ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:51:09<00:00, 24.93s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(corgi_filter2))):\n",
        "    pair = similar_pair(i, corgi_filter2, corgi2)\n",
        "    corgi_pairs2.append(pair)\n",
        "\n",
        "\n",
        "corgi_pairs2_np = np.array(corgi_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/corgi_pairs2.npy', corgi_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3npWg1PeZTnN"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip/labrador_filter1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip/labrador_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkONXq1cJ6w",
        "outputId": "c30efc7a-f0eb-4ff0-9bb7-3648769d00db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [43:56<00:00, 27.47s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter1, labrador1)\n",
        "    labrador_pairs1.append(pair)\n",
        "\n",
        "labrador_pairs1_np = np.array(labrador_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/labrador_pairs1.npy', labrador_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygDEfA1mB4H",
        "outputId": "3c0ed118-1ac7-4b7d-9663-548d5e1ec22a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:47:25<00:00, 24.38s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter2, labrador2)\n",
        "    labrador_pairs2.append(pair)\n",
        "\n",
        "labrador_pairs2_np = np.array(labrador_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/labrador_pairs2.npy', labrador_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U_wWxOlbmzd"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip/bulldog_filter1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip/bulldog_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zPieI6Qh-j",
        "outputId": "44360656-afd9-4e0c-a455-dacefadc410c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [43:35<00:00, 27.25s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter1, bulldog1)\n",
        "    bulldog_pairs1.append(pair)\n",
        "\n",
        "bulldog_pairs1_np = np.array(bulldog_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_pairs1.npy', bulldog_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUl4yFAKFDQ",
        "outputId": "330073fa-688f-40b8-e4e3-59627b5a22cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:48:55<00:00, 24.60s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter2, bulldog2)\n",
        "    bulldog_pairs2.append(pair)\n",
        "\n",
        "bulldog_pairs2_np = np.array(bulldog_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_pairs2.npy', bulldog_pairs2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGn-ES32mk_J"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip/dachshund_filter1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip/dachshund_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKWFg-QXE7m",
        "outputId": "b3900f48-d665-422b-a36d-0e1b91bff093"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:41<00:00, 26.06s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter1, dachshund1)\n",
        "    dachshund_pairs1.append(pair)\n",
        "\n",
        "dachshund_pairs1_np = np.array(dachshund_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_pairs1.npy', dachshund_pairs1_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmg9gwwAbAd",
        "outputId": "9da373a9-76bc-4573-a175-222273f4443d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:34:34<00:00, 22.51s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter2, dachshund2)\n",
        "    dachshund_pairs2.append(pair)\n",
        "\n",
        "dachshund_pairs2_np = np.array(dachshund_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_pairs2.npy', dachshund_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0U6fMo5WkK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKAgASqCmOKe"
      },
      "outputs": [],
      "source": [
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFrOE3RrLiG",
        "outputId": "59381f3b-7ae9-4890-825d-340f6270ac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PMu7dA7nNUM"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NrGu-LoTCz",
        "outputId": "2941f1f6-9d5a-4ae6-b1b8-7e86a7e6bfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2032"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0PdbNapNHB",
        "outputId": "54030c5e-e6fa-4299-e4f1-09c1a40ecede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "张量的形状： torch.Size([2032, 2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKslUAPyprb4",
        "outputId": "c6a75294-c4b4-4b19-f372-2a3842a347c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_easy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BAHgrw9bePe"
      },
      "source": [
        "convert all images into RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt50-fATZa32",
        "outputId": "ce1f6d76-1c38-4738-a51d-9cff9eff7433"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:07<00:00, 400.32it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.64it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.75it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.36it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.11it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.11it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.44it/s] \n",
            "100%|██████████| 3168/3168 [00:42<00:00, 73.81it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.81it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.29it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.98it/s] \n",
            "100%|██████████| 3168/3168 [00:41<00:00, 76.55it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.96it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.95it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.51it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.09it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:45<00:00, 69.65it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.34it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.47it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.75it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.43it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.11it/s] \n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:40<00:00, 78.95it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.40it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.98it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.39it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.18it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.05it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.91it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.46it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 80.48it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.66it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.47it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.05it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.02it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.07it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.99it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.61it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.41it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.99it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.86it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.81it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.70it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 83.88it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "所有图片转换完成！\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ip/spawrious224'\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        file_path = os.path.join(root, file)\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "            image.save(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRV3cb6FnoSX",
        "outputId": "c81a4785-7144-48f0-9653-fe0e26a6a245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bulldog', 'corgi', 'dachshund', 'labrador']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spawrious_easy.class_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swUTlzMZbAvm"
      },
      "source": [
        "find corgi images in env1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBlgf9kbPo1"
      },
      "source": [
        "find all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "MLAL0885BH2w",
        "outputId": "b23aef31-8b4b-429d-aad9-ff796f29b36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1826/12672 [02:35<15:20, 11.78it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e8a513c52f61>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspawrious_easy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bulldog\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbulldog_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corgi_images = []\n",
        "bulldog_images = []\n",
        "dachshund_images = []\n",
        "labrador_images = []\n",
        "\n",
        "\n",
        "for image, label in tqdm(env1):\n",
        "  if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images.append(image)\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images.append(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbcjhnlAXcZ",
        "outputId": "1f6b6fa3-702d-455e-815e-e80510a09565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3168\n",
            "3168\n",
            "3168\n",
            "3168\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi_images))\n",
        "print(len(bulldog_images))\n",
        "print(len(dachshund_images))\n",
        "print(len(labrador_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrz3aOyDbV9M"
      },
      "source": [
        "find all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFOg-czCymV",
        "outputId": "5b34ec3d-e0b2-4def-ea7e-51e8af9cf95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12672/12672 [1:20:01<00:00,  2.64it/s]\n"
          ]
        }
      ],
      "source": [
        "corgi_images2 = []\n",
        "bulldog_images2 = []\n",
        "dachshund_images2 = []\n",
        "labrador_images2 = []\n",
        "\n",
        "for image, label in tqdm(env2):\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images2.append(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKi8m9ibmRg"
      },
      "source": [
        "save all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGtK1RWUk7p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "def save_images(image_list, folder_path, label):\n",
        "    # 检查目标文件夹是否存在，不存在则创建\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 遍历图像列表，保存每张图像\n",
        "    for idx, tensor in enumerate(image_list):\n",
        "        image = TF.to_pil_image(tensor)                               # 将 tensor 转换为 PIL 图像\n",
        "        image_path = os.path.join(folder_path, f\"{label}_{idx}.png\")  # 定义图像的保存路径\n",
        "        image.save(image_path)                                        # 保存图像\n",
        "\n",
        "# Google Drive 挂载路径\n",
        "drive_path = \"/content/drive/MyDrive/ip/SpawriousImages\"\n",
        "\n",
        "# 分别保存每种类别的图像\n",
        "save_images(bulldog_images, os.path.join(drive_path, 'bulldog'), 'bulldog')\n",
        "save_images(dachshund_images, os.path.join(drive_path, 'dachshund'), 'dachshund')\n",
        "save_images(labrador_images, os.path.join(drive_path, 'labrador'), 'labrador')\n",
        "save_images(corgi_images, os.path.join(drive_path, 'corgi'), 'corgi')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ELr3P6bt2K"
      },
      "source": [
        "save all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFFo56kXnMc"
      },
      "outputs": [],
      "source": [
        "save_images(bulldog_images2, os.path.join(drive_path, 'bulldog2'), 'bulldog')\n",
        "save_images(dachshund_images2, os.path.join(drive_path, 'dachshund2'), 'dachshund')\n",
        "save_images(labrador_images2, os.path.join(drive_path, 'labrador2'), 'labrador')\n",
        "save_images(corgi_images2, os.path.join(drive_path, 'corgi2'), 'corgi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClB9-zM4fGNx",
        "outputId": "a7af8175-f2df-4362-d221-0e0215af6bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Dictionary: {'bulldog': 0, 'corgi': 1, 'dachshund': 2, 'labrador': 3}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_list = [\"bulldog\", \"corgi\", \"dachshund\", \"labrador\"]\n",
        "\n",
        "# 将列表转换为字典，键是标签，值是索引\n",
        "class_dict = {class_name: index for index, class_name in enumerate(class_list)}\n",
        "\n",
        "# 打印转换后的字典\n",
        "print(\"Class Dictionary:\", class_dict)\n",
        "class_dict['bulldog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GwhB5ObypD"
      },
      "source": [
        "create random pairs of bulldog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-q9MMaxtcQ",
        "outputId": "e613c57a-2c52-4e32-c420-daa56f69c1b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 697747.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/bulldog/bulldog_2213.png',\n",
              "  '/content/SpawriousImages/bulldog2/bulldog_2962.png'),\n",
              " 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder1_path = \"/content/SpawriousImages/bulldog\"\n",
        "folder2_path = \"/content/SpawriousImages/bulldog2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # Randomly pair\n",
        "    bulldog_image_pairs.append((image_pair, class_dict['bulldog']))\n",
        "\n",
        "bulldog_image_pairs[200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lJvdadb88y"
      },
      "source": [
        "create random pairs of corgi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8hN7jvyClr",
        "outputId": "95523183-db68-4d8e-dee9-6b4275c1ec7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 817519.62it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_208.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_3064.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/corgi\"\n",
        "folder2_path = \"/content/SpawriousImages/corgi2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "corgi_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, class_dict['corgi']))\n",
        "\n",
        "corgi_image_pairs[1093]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwyYjK7cDoq"
      },
      "source": [
        "create random pairs of dachshund"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4alSoc414EiM",
        "outputId": "de3c8564-b5d9-4dbd-87eb-f64d0cd25426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 800262.29it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/dachshund/dachshund_2053.png',\n",
              "  '/content/SpawriousImages/dachshund2/dachshund_1682.png'),\n",
              " 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/dachshund\"\n",
        "folder2_path = \"/content/SpawriousImages/dachshund2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "# 将文件名转换为完整的文件路径\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, class_dict['dachshund']))\n",
        "\n",
        "dachshund_image_pairs[100]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VW1QOicJPa"
      },
      "source": [
        "Create random pairs of labrador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcVbDd94K2U",
        "outputId": "ba1ae18c-d68b-4151-8c77-74a069314f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 733835.26it/s]\n"
          ]
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/labrador\"\n",
        "folder2_path = \"/content/SpawriousImages/labrador2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, class_dict['labrador']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fejvc8A3cM7p"
      },
      "source": [
        "merge all four classes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBx_U4Dw4Tpe",
        "outputId": "4f6c1004-2f97-4611-ded4-a06ede1873d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_2342.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_2470.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = labrador_image_pairs + dachshund_image_pairs + corgi_image_pairs + bulldog_image_pairs\n",
        "\n",
        "# 打乱合并后的列表\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "training_data[981]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1hM69h4ZxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 明确指定数组的数据类型为 object\n",
        "training_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# 指定保存文件的路径和文件名\n",
        "save_path = \"/content/training_data.npy\"\n",
        "\n",
        "# 将 NumPy 数组保存为 .npy 文件\n",
        "np.save(save_path, training_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCZHUx14Z3I",
        "outputId": "18ca66d3-0b33-41fa-de18-91c66657593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (25344, 2)\n",
            "Size: 50688\n",
            "[('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            " 3]\n",
            "('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            "/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加载 .npy 文件\n",
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# 查看数组的形状和大小\n",
        "print(\"Shape:\", array.shape)\n",
        "print(\"Size:\", array.size)\n",
        "\n",
        "\n",
        "print(array[1])\n",
        "print(array[1][0])\n",
        "print(array[1][0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check an example\n"
      ],
      "metadata": {
        "id": "70s-6zucXos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Axn7L7Sqruo",
        "outputId": "578daa98-81ed-4e89-deb7-97b93674d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png'),\n",
              "       3], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "array[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "942VqoXnP0OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image_paths = sample[0]\n",
        "        label = sample[1]\n",
        "        images = [Image.open(path) for path in image_paths]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ip/training_data.npy\"\n",
        "custom_dataset = CustomDataset(data_path, transform=transform)\n",
        "trainloader = DataLoader(custom_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezAlnNFwESe",
        "outputId": "6a163d37-acd1-48ae-ed06-a71bf0a914cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EI82mktkohs"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJN4vrei4Ag",
        "outputId": "a8a5a118-71f5-4f8a-e94e-12f6841a9b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "([tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]]), tensor([[[ 0.2967,  0.1426, -0.0116,  ..., -1.7240, -1.9467,  2.1462],\n",
            "         [ 0.4337,  0.5193,  0.0741,  ...,  2.1462,  1.9235,  1.9920],\n",
            "         [ 0.4337,  0.5193,  0.1426,  ...,  2.0777,  1.9920,  1.8550],\n",
            "         ...,\n",
            "         [ 2.1975,  1.8208,  1.6667,  ..., -1.6727, -1.5870, -1.5870],\n",
            "         [ 1.8893,  1.4440,  1.3755,  ...,  1.8893,  2.0434, -2.1179],\n",
            "         [ 1.5982,  1.4440,  1.3755,  ...,  1.8208,  1.8208,  1.9749]],\n",
            "\n",
            "        [[ 2.3060,  2.2360,  1.9909,  ...,  0.2052, -0.2675, -0.4951],\n",
            "         [-1.9307, -2.0182,  1.9909,  ..., -0.4251, -0.7402, -0.6527],\n",
            "         [-1.9307, -2.0182,  2.1485,  ..., -0.5826, -0.6527, -0.9678],\n",
            "         ...,\n",
            "         [-1.3179, -1.8606,  2.3761,  ..., -0.8452, -0.7752, -0.6176],\n",
            "         [-1.9482,  2.1485,  1.9209,  ..., -1.8606, -1.7031, -1.3880],\n",
            "         [ 2.3060,  2.0609,  1.9209,  ..., -2.0182, -2.0182, -1.8606]],\n",
            "\n",
            "        [[-0.8981, -1.0550, -1.2119,  ...,  1.5594,  1.0888,  0.8622],\n",
            "         [-0.6541, -0.7413, -1.2119,  ...,  1.0191,  0.6182,  0.7054],\n",
            "         [-0.6541, -0.7413, -1.0550,  ...,  0.7751,  0.7751,  0.4614],\n",
            "         ...,\n",
            "         [ 0.0605, -0.4798, -0.7064,  ...,  0.6182,  0.7576,  0.7576],\n",
            "         [-0.4798, -0.9330, -1.2467,  ..., -0.3927, -0.0790, -0.0092],\n",
            "         [-0.7064, -1.0201, -1.2467,  ..., -0.6367, -0.4798, -0.4798]]])], 1)\n"
          ]
        }
      ],
      "source": [
        "# 数据集的长度，一共有25344对图像\n",
        "print(len(custom_dataset))\n",
        "\n",
        "\n",
        "print(custom_dataset[3])\n",
        "\n",
        "# pairs\n",
        "#print(custom_dataset[3][0])\n",
        "\n",
        "# label\n",
        "#print(custom_dataset[3][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPLwSINk_IW"
      },
      "outputs": [],
      "source": [
        "batch_size= 10\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwbKV4Ay7Rq",
        "outputId": "98059a33-0549-48c3-a035-348232838ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]])\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(trainloader))\n",
        "first_data = first_batch[0][0]  # 获取第一个数据样本\n",
        "print(first_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ83k-aWJrgv"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhU_0iIXJqpZ",
        "outputId": "4e97126e-6c72-43b0-cc6f-3462131d3cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "2535\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n",
        "print(len(trainloader))\n",
        "print(type(trainloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIKQNL6rpCw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Erge4frq72"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZFFBiirq-R",
        "outputId": "3dc54f4b-67a6-4e40-e482-55c7405ba0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQM3HHBKFiE"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuuWRMBrrAY",
        "outputId": "15e1819c-fa7d-49ab-b944-d5f5110459b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "last_fc_layer = model.fc\n",
        "\n",
        "input_features = last_fc_layer.in_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqf7iroOwvq2",
        "outputId": "e133fb06-9868-4912-e836-80b9f9f293d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全连接层结构： Linear(in_features=512, out_features=4, bias=True)\n",
            "全连接层权重形状： torch.Size([4, 512])\n",
            "全连接层偏置形状： torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "fc_layer = model.fc\n",
        "\n",
        "print(\"全连接层结构：\", fc_layer)\n",
        "print(\"全连接层权重形状：\", fc_layer.weight.shape)\n",
        "print(\"全连接层偏置形状：\", fc_layer.bias.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1UnM4ToMPXv"
      },
      "source": [
        "Check:(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWh-kHp1vNb",
        "outputId": "dbac08e4-05f8-40f4-d882-200e045c7e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "tensor(1.5868, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, label = next(dataiter)\n",
        "\n",
        "#print(\"Inputs:\", images[0])       # 显示输入数据\n",
        "      # 只处理第一个 batch 后退出循环\n",
        "\n",
        "type(images[0])\n",
        "\n",
        "\n",
        "input_tensor = torch.cat((images[0], images[1]), dim=0)\n",
        "import torch\n",
        "\n",
        "\n",
        "labels = torch.cat((label, label), dim=0)\n",
        "#print(labels)\n",
        "\n",
        "outputs = model(input_tensor)\n",
        "#print(outputs)\n",
        "\n",
        "print(len(outputs))\n",
        "print(len(labels))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jMXI2Dukty",
        "outputId": "04a13456-1823-485e-a009-ce4c51837bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7cd3252a3d60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "test = torch.load('/content/drive/MyDrive/ip/testdata.pt')\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hSVD3wsqim"
      },
      "source": [
        "check an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOpFA1vlUXy",
        "outputId": "022b77ae-f4ec-46ef-c2a4-51696568a29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取第一个 batch\n",
        "first_batch = next(iter(trainloader))\n",
        "\n",
        "# 打印第一个 batch\n",
        "# print(first_batch)\n",
        "\n",
        "print(len(first_batch[0][1]))\n",
        "print(len(first_batch[0][0]))\n",
        "\n",
        "# batch_size个\n",
        "\n",
        "\n",
        "# for i, items in enumerate(trainloader, 0):\n",
        "#  print(i, items)\n",
        "#  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModifiedResNet\n"
      ],
      "metadata": {
        "id": "pgY9MuCX8xzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90F789NYgK0e",
        "outputId": "5bb34249-f47c-4a51-a974-57389a0b3e15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 86.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.final_layer = list(model.children())[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features_flattened = features.view( x.shape[0], -1)\n",
        "        final_output = self.final_layer(features_flattened)\n",
        "\n",
        "        return features, final_output\n",
        "\n",
        "\n",
        "modified_model = ModifiedResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JeRhqEhNW7D4",
        "outputId": "dd7122f6-a2e1-4418-f1cc-5d7d9edbef4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'first_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b4ede2f49613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.cat((first_batch[0][0], first_batch[0][1]), dim=0)\n",
        "labels = torch.cat((first_batch[1], first_batch[1]), dim=0)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(input_tensor.shape[0])\n",
        "print(labels.shape)\n",
        "#input_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train process"
      ],
      "metadata": {
        "id": "RTaK4QPx86Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdykKpAdrrCz",
        "outputId": "16ca98b5-5d29-4022-ac41-520c242bc1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "11it [07:23, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [11/198], Loss: 1.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:57, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [22/198], Loss: 0.6445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:22, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [33/198], Loss: 0.4303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:54, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [44/198], Loss: 0.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:29, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [55/198], Loss: 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:59, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [66/198], Loss: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:32, 41.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [77/198], Loss: 0.1903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:09, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [88/198], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [99/198], Loss: 0.1815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:02, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [110/198], Loss: 0.1576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:38, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [121/198], Loss: 0.1529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:14, 40.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [132/198], Loss: 0.1419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:45, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [143/198], Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:20, 41.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [154/198], Loss: 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:51, 41.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [165/198], Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:16, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [176/198], Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:39, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [187/198], Loss: 0.0940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:00, 40.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [198/198], Loss: 0.0900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "11it [07:30, 40.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [11/198], Loss: 0.0390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:50, 40.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [22/198], Loss: 0.0359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [33/198], Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:35, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [44/198], Loss: 0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [36:59, 40.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [55/198], Loss: 0.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:22, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [66/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [51:46, 40.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [77/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:10, 40.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [88/198], Loss: 0.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:06:34, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [99/198], Loss: 0.0300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:06, 41.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [110/198], Loss: 0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:21:36, 40.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [121/198], Loss: 0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:07, 40.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [132/198], Loss: 0.0299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:36:37, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [143/198], Loss: 0.0309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:09, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [154/198], Loss: 0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:51:42, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [165/198], Loss: 0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:14, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [176/198], Loss: 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:06:46, 41.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [187/198], Loss: 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:14, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [198/198], Loss: 0.0209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:15, 40.68s/it]\n",
            "11it [07:32, 40.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [11/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:58, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [22/198], Loss: 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:30, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [33/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:55, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [44/198], Loss: 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:20, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [55/198], Loss: 0.0084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:48, 40.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [66/198], Loss: 0.0086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:14, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [77/198], Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:48, 40.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [88/198], Loss: 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:16, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [99/198], Loss: 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:49, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [110/198], Loss: 0.0072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:17, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [121/198], Loss: 0.0077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:46, 40.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [132/198], Loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:18, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [143/198], Loss: 0.0064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:43, 40.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [154/198], Loss: 0.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:10, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [165/198], Loss: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:40, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [176/198], Loss: 0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:06, 40.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [187/198], Loss: 0.0068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:33, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [198/198], Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:34, 40.78s/it]\n",
            "11it [07:41, 41.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [11/198], Loss: 0.0058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:13, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [22/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:44, 40.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [33/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:16, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [44/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:40, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [55/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:09, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [66/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:35, 40.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [77/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:10, 41.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [88/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [99/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:13, 41.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [110/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:47, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [121/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:16, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [132/198], Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:43, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [143/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:16, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [154/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:45, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [165/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:13, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [176/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:50, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [187/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:26, 41.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [198/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:27, 41.05s/it]\n",
            "11it [07:41, 41.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [11/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:20, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [22/198], Loss: 0.0048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:58, 41.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [33/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:37, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [44/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [55/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:50, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [66/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:27, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [77/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:01:08, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [88/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:39, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [99/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:16, 41.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [110/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:52, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [121/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:20, 40.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [132/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:53, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [143/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:27, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [154/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:04, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [165/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:42, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [176/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:21, 41.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [187/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:56, 41.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [198/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:57, 41.50s/it]\n",
            "11it [07:44, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [11/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:25, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [22/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [33/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:34, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [44/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:05, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [55/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:32, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [66/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:05, 41.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [77/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:39, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [88/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:15, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [99/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:47, 40.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [110/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:19, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [121/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:55, 41.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [132/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:29, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [143/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:06, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [154/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:43, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [165/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:11, 40.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [176/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:42, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [187/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:24, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [198/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:25, 41.34s/it]\n",
            "11it [07:35, 40.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [11/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:06, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [22/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:47, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [33/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:19, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:57, 41.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [55/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:34, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [66/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:14, 41.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [77/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:47, 41.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [88/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:20, 41.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [99/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:04, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:41, 41.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [121/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:21, 41.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [132/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:39:00, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [143/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:33, 41.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [154/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:02, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [165/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:35, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [176/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:04, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [187/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:42, 41.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [198/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:43, 41.43s/it]\n",
            "11it [07:45, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [11/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:21, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [22/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [33/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:33, 41.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [55/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:46, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [66/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:22, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [77/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:51, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [88/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:14, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [99/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:46, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:22, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [121/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:58, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [132/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:33, 41.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [143/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:11, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [154/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:46, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [165/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [176/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:41, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [187/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "189it [2:10:05, 41.73s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "modified_model=modified_model.to(device)\n",
        "modified_model=modified_model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "            for j in range(batch_size):\n",
        "                y = items[1][j].to(device)           # Class label\n",
        "                images1 = items[0][0][j].to(device)  # First image\n",
        "                images2 = items[0][1][j].to(device)  # Second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                lam_loss = 0.0\n",
        "                for k in range(512):\n",
        "                    w = fc_layer.weight[y, k] ** 2\n",
        "                    dst = (f1[0, k, 0, 0] - f2[0, k, 0, 0]) ** 2\n",
        "                    lam_loss += w * dst\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i+1) %  11== 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/11))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/model_weights_output_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLMZjBCqaZ6"
      },
      "outputs": [],
      "source": [
        "training_data = torch.tensor(data)\n",
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIsQ3KbelCN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/ip/model_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For similar pairs:"
      ],
      "metadata": {
        "id": "WuiZXWkG9DYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dm1j-oLek0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset1(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        images = sample[0]\n",
        "        label = sample[1]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7wPaFtSpENP",
        "outputId": "75d8367f-7970-43cf-81d2-4da88790966d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip/dachshund_pairs2.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-51b849d757dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdachshund2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/dachshund_pairs2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdachshund1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/dachshund_pairs1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbulldog1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/bulldog_pairs1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/dachshund_pairs2.npy'"
          ]
        }
      ],
      "source": [
        "\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "training_data = torch.tensor(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBGtMHhpzKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dachshund_medium2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium2.npy')\n",
        "dachshund_medium1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium1.npy')\n",
        "bulldog_medium1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium1.npy')\n",
        "bulldog_medium2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium2.npy')\n",
        "corgi_medium1 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium1.npy')\n",
        "corgi_medium2 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium2.npy')\n",
        "labrador_medium2 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium2.npy')\n",
        "labrador_medium1 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium1.npy')\n",
        "\n",
        "labrador_medium = np.concatenate((labrador_medium1, labrador_medium2), axis=0)\n",
        "bulldog_medium = np.concatenate((bulldog_medium1, bulldog_medium2), axis=0)\n",
        "corgi_medium = np.concatenate((corgi_medium1, corgi_medium2), axis=0)\n",
        "dachshund_medium = np.concatenate((dachshund_medium1, dachshund_medium2), axis=0)\n",
        "\n",
        "data_medium = np.concatenate((labrador_medium, bulldog_medium, corgi_medium, dachshund_medium), axis=0)\n",
        "training_data_medium = torch.tensor(data_medium)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-y4fDJnxWmP"
      },
      "outputs": [],
      "source": [
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "lipfY6ZIuxro",
        "outputId": "7db4a854-68a4-4eb4-a2f8-3ce20db2e660"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-776625d398e5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 使用列表推导式将每个 data 转换为所需的形式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
          ]
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 将每个 data 转换为所需的形式\n",
        "training_data = [transform_data(data) for data in training_data]\n",
        "training_data[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T872dSn4qXrP",
        "outputId": "96f82541-3f55-454b-cf75-e35f6b475709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[-0.4739, -0.4911, -0.5082,  ..., -0.6623, -0.6452, -0.6452],\n",
              "          [-0.4911, -0.4739, -0.4568,  ..., -0.6623, -0.6623, -0.6452],\n",
              "          [-0.4397, -0.4054, -0.3883,  ..., -0.6623, -0.6794, -0.6452],\n",
              "          ...,\n",
              "          [-1.5528, -0.6452,  0.0056,  ...,  1.0331,  1.4783,  1.0844],\n",
              "          [-1.0733, -0.7822, -1.4672,  ...,  0.9646,  1.4783,  1.3070],\n",
              "          [-1.2103, -1.4500, -1.7583,  ...,  0.6049,  1.4783,  1.3413]],\n",
              " \n",
              "         [[ 0.6254,  0.6429,  0.6429,  ...,  0.3277,  0.3627,  0.3627],\n",
              "          [ 0.6604,  0.6779,  0.6429,  ...,  0.3277,  0.3277,  0.3102],\n",
              "          [ 0.6779,  0.6954,  0.6779,  ...,  0.3277,  0.3627,  0.3803],\n",
              "          ...,\n",
              "          [-0.7052,  0.2227,  0.5203,  ...,  0.5028,  0.9930,  0.4503],\n",
              "          [-0.3901,  0.0301, -0.5651,  ...,  0.2927,  0.9755,  0.7479],\n",
              "          [-0.7752, -0.9853, -1.2829,  ..., -0.0749,  0.9930,  0.8704]],\n",
              " \n",
              "         [[ 1.1934,  1.2457,  1.2457,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2631,  1.2805,  1.2631,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2980,  1.3154,  1.2980,  ...,  0.9145,  0.9319,  0.9668],\n",
              "          ...,\n",
              "          [-1.1596, -0.3578,  0.2348,  ...,  0.4788,  0.9842,  0.4962],\n",
              "          [-0.5495, -0.3230, -1.1421,  ...,  0.2871,  0.9319,  0.7576],\n",
              "          [-0.7936, -1.1596, -1.5604,  ..., -0.0790,  0.9842,  0.8971]]]),\n",
              " tensor([[[-0.5082, -0.5253, -0.4911,  ...,  1.5639,  1.8037,  1.8379],\n",
              "          [-0.4739, -0.4226, -0.4911,  ...,  1.6667,  1.8550,  1.8722],\n",
              "          [-0.4568, -0.4226, -0.4911,  ...,  1.8550,  1.8208,  1.8037],\n",
              "          ...,\n",
              "          [-1.0904, -0.5082, -0.3541,  ..., -0.5938, -0.7479, -0.3027],\n",
              "          [-1.5528, -1.7069, -1.3644,  ..., -0.6281, -0.5938, -0.6452],\n",
              "          [-1.3644, -1.4329, -1.5528,  ..., -0.2684, -0.4568, -0.9020]],\n",
              " \n",
              "         [[-1.1078, -1.1253, -1.0903,  ...,  1.2556,  1.6758,  1.8158],\n",
              "          [-1.1078, -1.0728, -1.1078,  ...,  1.4307,  1.8859,  1.9559],\n",
              "          [-1.0553, -1.0378, -1.0903,  ...,  1.9034,  1.9034,  1.8158],\n",
              "          ...,\n",
              "          [-1.3880, -1.0203, -1.0378,  ..., -1.0903, -1.2129, -0.8452],\n",
              "          [-1.6681, -1.8782, -1.6506,  ..., -1.1253, -1.1078, -1.2129],\n",
              "          [-1.5455, -1.4755, -1.5980,  ..., -0.7752, -0.9853, -1.4230]],\n",
              " \n",
              "         [[-0.8807, -0.8807, -0.8458,  ...,  1.2108,  1.6291,  1.8208],\n",
              "          [-0.8458, -0.8458, -0.8458,  ...,  1.3851,  1.8905,  1.9603],\n",
              "          [-0.8110, -0.7936, -0.8284,  ...,  1.9428,  1.9951,  1.8557],\n",
              "          ...,\n",
              "          [-0.9330, -0.7761, -0.6890,  ..., -0.7761, -0.9156, -0.5670],\n",
              "          [-1.4036, -1.5604, -1.3687,  ..., -0.8284, -0.8284, -0.9504],\n",
              "          [-1.3164, -1.2293, -1.3164,  ..., -0.5495, -0.7238, -1.1421]]])]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 使用列表推导式将每个 data 转换为所需的形式\n",
        "training_data_medium = [transform_data(data) for data in training_data_medium]\n",
        "training_data_medium[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTtNaRpmCpd",
        "outputId": "67e5a9f5-d381-4ea7-ae70-11eddc86f9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2032\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 定义每个类别的名称和数量\n",
        "labels = []\n",
        "\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(508):\n",
        "    labels.extend([3])  # 前508个为3\n",
        "for _ in range(508):\n",
        "    labels.extend([0])  # 508-508*2为0\n",
        "for _ in range(508):\n",
        "    labels.extend([1])  # 508*2-508*3为1\n",
        "for _ in range(508):\n",
        "    labels.extend([2])  # 508*3-508*4为2\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels))  # 应该打印出 2032\n",
        "labels[508]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8hS8AgE4pKyv",
        "outputId": "1b5c9101-8ab5-42c7-e376-979b45702f6d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bc38e2019804>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcombined_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 打印新的列表的长度，确保每个数据都有对应的标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train = list(zip(training_data, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train))  # 应该打印出 2032\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bjA_xicqu-q",
        "outputId": "7ee7ddcd-b828-458b-9b5a-9571b30cc089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train_medium = list(zip(training_data_medium, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train_medium))  # 2032"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHc6RZzlfZAD",
        "outputId": "02424fcf-0d35-4b41-dec9-fa1d00287c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([tensor([[[-0.4739, -0.4911, -0.5082,  ..., -0.6623, -0.6452, -0.6452],\n",
              "           [-0.4911, -0.4739, -0.4568,  ..., -0.6623, -0.6623, -0.6452],\n",
              "           [-0.4397, -0.4054, -0.3883,  ..., -0.6623, -0.6794, -0.6452],\n",
              "           ...,\n",
              "           [-1.5528, -0.6452,  0.0056,  ...,  1.0331,  1.4783,  1.0844],\n",
              "           [-1.0733, -0.7822, -1.4672,  ...,  0.9646,  1.4783,  1.3070],\n",
              "           [-1.2103, -1.4500, -1.7583,  ...,  0.6049,  1.4783,  1.3413]],\n",
              "  \n",
              "          [[ 0.6254,  0.6429,  0.6429,  ...,  0.3277,  0.3627,  0.3627],\n",
              "           [ 0.6604,  0.6779,  0.6429,  ...,  0.3277,  0.3277,  0.3102],\n",
              "           [ 0.6779,  0.6954,  0.6779,  ...,  0.3277,  0.3627,  0.3803],\n",
              "           ...,\n",
              "           [-0.7052,  0.2227,  0.5203,  ...,  0.5028,  0.9930,  0.4503],\n",
              "           [-0.3901,  0.0301, -0.5651,  ...,  0.2927,  0.9755,  0.7479],\n",
              "           [-0.7752, -0.9853, -1.2829,  ..., -0.0749,  0.9930,  0.8704]],\n",
              "  \n",
              "          [[ 1.1934,  1.2457,  1.2457,  ...,  0.9145,  0.9145,  0.9145],\n",
              "           [ 1.2631,  1.2805,  1.2631,  ...,  0.9145,  0.9145,  0.9145],\n",
              "           [ 1.2980,  1.3154,  1.2980,  ...,  0.9145,  0.9319,  0.9668],\n",
              "           ...,\n",
              "           [-1.1596, -0.3578,  0.2348,  ...,  0.4788,  0.9842,  0.4962],\n",
              "           [-0.5495, -0.3230, -1.1421,  ...,  0.2871,  0.9319,  0.7576],\n",
              "           [-0.7936, -1.1596, -1.5604,  ..., -0.0790,  0.9842,  0.8971]]]),\n",
              "  tensor([[[-0.5082, -0.5253, -0.4911,  ...,  1.5639,  1.8037,  1.8379],\n",
              "           [-0.4739, -0.4226, -0.4911,  ...,  1.6667,  1.8550,  1.8722],\n",
              "           [-0.4568, -0.4226, -0.4911,  ...,  1.8550,  1.8208,  1.8037],\n",
              "           ...,\n",
              "           [-1.0904, -0.5082, -0.3541,  ..., -0.5938, -0.7479, -0.3027],\n",
              "           [-1.5528, -1.7069, -1.3644,  ..., -0.6281, -0.5938, -0.6452],\n",
              "           [-1.3644, -1.4329, -1.5528,  ..., -0.2684, -0.4568, -0.9020]],\n",
              "  \n",
              "          [[-1.1078, -1.1253, -1.0903,  ...,  1.2556,  1.6758,  1.8158],\n",
              "           [-1.1078, -1.0728, -1.1078,  ...,  1.4307,  1.8859,  1.9559],\n",
              "           [-1.0553, -1.0378, -1.0903,  ...,  1.9034,  1.9034,  1.8158],\n",
              "           ...,\n",
              "           [-1.3880, -1.0203, -1.0378,  ..., -1.0903, -1.2129, -0.8452],\n",
              "           [-1.6681, -1.8782, -1.6506,  ..., -1.1253, -1.1078, -1.2129],\n",
              "           [-1.5455, -1.4755, -1.5980,  ..., -0.7752, -0.9853, -1.4230]],\n",
              "  \n",
              "          [[-0.8807, -0.8807, -0.8458,  ...,  1.2108,  1.6291,  1.8208],\n",
              "           [-0.8458, -0.8458, -0.8458,  ...,  1.3851,  1.8905,  1.9603],\n",
              "           [-0.8110, -0.7936, -0.8284,  ...,  1.9428,  1.9951,  1.8557],\n",
              "           ...,\n",
              "           [-0.9330, -0.7761, -0.6890,  ..., -0.7761, -0.9156, -0.5670],\n",
              "           [-1.4036, -1.5604, -1.3687,  ..., -0.8284, -0.8284, -0.9504],\n",
              "           [-1.3164, -1.2293, -1.3164,  ..., -0.5495, -0.7238, -1.1421]]])],\n",
              " 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_dataset1 = CustomDataset1(combined_train_medium)\n",
        "custom_dataset1[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zihO8aa0cjKh"
      },
      "outputs": [],
      "source": [
        "# 导入需要的库\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "trainloader1 = DataLoader(custom_dataset1, batch_size=127, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SGwJcfPBE2G",
        "outputId": "615f0ca0-cdf4-4d04-e071-d961f00db085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "print(f1.shape)\n",
        "f1_squared = torch.pow(f1, 2)\n",
        "print(f1_squared.shape)\n",
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5a5RVH2yT5G",
        "outputId": "abfb6b9f-5eaa-45c1-c502-2271b45a4617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8c9wMs83eX",
        "outputId": "07840e10-8594-44b7-f34f-7e43503a35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "print(f1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGEKEWSuorD",
        "outputId": "afba0682-8b0b-4dec-970d-c5a0db61e471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "fc_layer = modified_model.final_layer\n",
        "print(fc_layer.weight.shape)\n",
        "w = fc_layer.weight[1]**2\n",
        "\n",
        "print(w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJHhdBkAIYm",
        "outputId": "43302df3-c5e2-4a7f-c015-8df31114f15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6768, -0.0463, -0.0187,  0.4089],\n",
            "        [ 0.8044, -1.3712,  0.6512,  0.2529]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([0, 0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "image1 = torch.randn(3, 224, 224)  # 假设图片1的形状为 [3, 224, 224]\n",
        "image2 = torch.randn(3, 224, 224)  # 假设图片2的形状为 [3, 224, 224]\n",
        "\n",
        "input_tensor = torch.cat((image1.unsqueeze(0), image2.unsqueeze(0)), dim=0)\n",
        "input_tensor\n",
        "y=modified_model(input_tensor.to(device))[1]\n",
        "print(y)\n",
        "predicted = torch.argmax(y, dim=1)\n",
        "print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "qBmyZK2PrrEX",
        "outputId": "a48d7b20-0372-4175-de9a-03113d6a25a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [16/16], Loss: 0.4704, Accuracy: 72.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/50], Step [16/16], Loss: 0.2790, Accuracy: 86.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:46,  2.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50], Step [16/16], Loss: 0.1960, Accuracy: 90.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:44,  2.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/50], Step [16/16], Loss: 0.1366, Accuracy: 94.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50], Step [16/16], Loss: 0.0912, Accuracy: 97.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50], Step [16/16], Loss: 0.0560, Accuracy: 99.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/50], Step [16/16], Loss: 0.0341, Accuracy: 99.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50], Step [16/16], Loss: 0.0245, Accuracy: 99.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50], Step [16/16], Loss: 0.0219, Accuracy: 99.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:45,  2.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/50], Step [16/16], Loss: 0.0180, Accuracy: 99.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [00:16,  3.34s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1a91be8d0b00>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mlam_loss_all\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERM_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam_loss_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 50\n",
        "batch_size = 127\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader1 = DataLoader(custom_dataset1, batch_size=batch_size, shuffle=True)\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "modified_model=modified_model.to(device).train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "\n",
        "    for i, items in tqdm(enumerate(trainloader1, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "\n",
        "            for j in range(batch_size):\n",
        "\n",
        "                y = items[1][j].to(device)           # jth class label\n",
        "                images1 = items[0][0][j].to(device)  # jth first image\n",
        "                images2 = items[0][1][j].to(device)  # jth second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                w = fc_layer.weight[y] ** 2\n",
        "                diff = torch.squeeze(torch.pow(f1- f2, 2))\n",
        "                lam_loss = torch.sum(torch.mul(diff, w))\n",
        "\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i+1) %  16== 0:\n",
        "                accuracy = 100 * correct / total\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, len(trainloader1), running_loss/16, accuracy))\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/output_medium_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34hKBm823Sg",
        "outputId": "f9d0a3c3-6518-4353-8f52-10a04d3953f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[-0.1486,  0.1254, -0.1999,  ..., -0.8678, -0.5253, -0.5424],\n",
            "         [-0.1486,  0.0912, -0.4568,  ..., -1.5528, -1.1589, -0.9020],\n",
            "         [-0.1999, -0.3541, -0.8507,  ..., -1.8268, -1.6213, -1.4500],\n",
            "         ...,\n",
            "         [ 1.3070,  0.8276,  0.2453,  ...,  0.7248,  0.5536,  0.5878],\n",
            "         [ 0.0912,  0.1939, -0.0116,  ..., -0.7993,  0.1597,  0.5707],\n",
            "         [-0.4226, -0.1999,  0.2967,  ..., -1.0562, -0.6281, -0.5082]],\n",
            "\n",
            "        [[ 0.0301,  0.3627,  0.0476,  ..., -0.9153, -0.6001, -0.7227],\n",
            "         [ 0.1001,  0.3452, -0.2500,  ..., -1.5455, -1.1604, -0.9328],\n",
            "         [ 0.0826, -0.0224, -0.5476,  ..., -1.7731, -1.5980, -1.4930],\n",
            "         ...,\n",
            "         [ 0.2927, -0.1450, -0.8452,  ...,  0.2577,  0.1176,  0.1001],\n",
            "         [-0.8627, -0.7752, -0.9503,  ..., -1.1604, -0.2675,  0.1877],\n",
            "         [-0.9678, -0.8803, -0.3725,  ..., -1.2129, -0.9153, -0.8978]],\n",
            "\n",
            "        [[-0.4973, -0.1312, -0.3055,  ..., -1.4384, -1.2990, -1.2816],\n",
            "         [-0.4450, -0.3055, -0.7761,  ..., -1.7347, -1.6127, -1.4559],\n",
            "         [-0.5147, -0.7761, -1.2467,  ..., -1.8044, -1.7173, -1.6476],\n",
            "         ...,\n",
            "         [-0.1487, -0.5147, -1.1944,  ...,  0.2522,  0.1651,  0.0256],\n",
            "         [-1.1421, -1.0376, -1.2293,  ..., -1.1596, -0.2010,  0.1999],\n",
            "         [-1.1247, -1.0376, -0.6018,  ..., -1.1247, -0.7761, -0.8284]]]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')\n",
        "len(testdata_medium)\n",
        "print(testdata_medium[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAWgmfNd25rs",
        "outputId": "b3906110-526d-4aa5-9b50-f7c096965756"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/model_output_medium_epoch_50.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "tEy8VCn39eGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fOJujGudYhYa",
        "outputId": "adf9149e-6a38-4714-f41e-63987c8079f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/198 [01:11<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ba9b7773c4b2>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader_medium\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model = modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "# 将测试数据集转化为 DataLoader\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = modified_model(images)[1]\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v01aSR00LqpI",
        "outputId": "a500650e-6281-4fc4-f3b4-e62cc78fdf74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25344"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')\n",
        "len(testdata_medium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1ygIB_HDyY",
        "outputId": "12c8fef2-8817-435e-bd66-336564f8ea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [3:22:21<00:00, 61.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分类任务的准确率: 75.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "\n",
        "# 加载.pt文件\n",
        "\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = modified_model(images)[1]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28HS3FWGtR8s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset:\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index][0], self.data[index][1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_tensor(self):\n",
        "        tensor_data = []\n",
        "        for image, label in self.data:\n",
        "            tensor_data.append((torch.tensor(image), label))\n",
        "\n",
        "        return tensor_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hFvXsW8SrYFM",
        "outputId": "a7ffd795-e2a5-499c-b0be-f80562e9f7a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c8bbd58e4b7a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ip/training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtensor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),                     # 调整图像短边至 256 像素\n",
        "    transforms.CenterCrop(224),                 # 中心裁剪图像为 224x224\n",
        "    transforms.ToTensor(),                      # 转换图像为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像数据\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 加载自定义数据集\n",
        "dataset = CustomDataset(npy_file=\"/content/drive/MyDrive/ip/training_data.npy\", transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 创建 DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztB9GY4v4yo",
        "outputId": "3392943a-290f-4547-8cb4-cef983a10d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Type: <class '__main__.CustomDataset'>\n",
            "Dataset Dimension: (25344, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset_type = type(dataset)\n",
        "print(\"Dataset Type:\", dataset_type)\n",
        "\n",
        "# 获取数据集的维度\n",
        "dataset_dimension = dataset.data.shape\n",
        "print(\"Dataset Dimension:\", dataset_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EOBx1nCxuCsC",
        "outputId": "ac4a35e3-ae9c-450d-84a0-d76fc73641c0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unexpected type <class 'tuple'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d57b01628137>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 获取 DataLoader 中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 打印第一个批次的输入数据和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected type {type(img)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'tuple'>"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch 是一个列表，包含了一个批次的样本数据\n",
        "    # 在这里你可以自定义处理逻辑，将样本转换为张量形式\n",
        "\n",
        "    # 假设 batch 中的每个元素是一个元组，其中包含输入数据和对应的标签\n",
        "    inputs = [item[0] for item in batch]  # 提取输入数据\n",
        "    labels = [item[1] for item in batch]  # 提取标签\n",
        "\n",
        "    # 将输入数据和标签转换为张量形式\n",
        "    inputs_tensor = torch.tensor(inputs)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    return inputs_tensor, labels_tensor\n",
        "\n",
        "# 定义 DataLoader，指定 collate_fn 参数为自定义的 collate_fn 函数\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 获取 DataLoader 中的数据\n",
        "inputs, labels = next(iter(data_loader))\n",
        "\n",
        "# 打印第一个批次的输入数据和标签\n",
        "print(\"First Batch Inputs:\", inputs)\n",
        "print(\"First Batch Labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsUjsKgl-2i",
        "outputId": "012f56c5-3a7e-4912-ad02-2443ff0d8f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (25344, 2)\n",
            "Train Y shape: (25344,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for element in array:\n",
        "\n",
        "    sample, label = element\n",
        "\n",
        "    train_x.append(sample)\n",
        "    train_y.append(label)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHRm6Ylmz7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpL-8JSj55R",
        "outputId": "9512c9a5-a704-4b99-b006-6df0900056bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('corgi_2105.png', 'corgi_954.png'), 'corgi'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYXYu7OrxQc",
        "outputId": "bfdbc041-8821-4b96-9dc4-c915662440e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder contains 3168 images.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# 指定文件夹路径\n",
        "folder_path = '/content/drive/MyDrive/ip/SpawriousImages/bulldog'\n",
        "\n",
        "# 使用glob.glob获取所有图片文件的路径，并计算数量\n",
        "num_images = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
        "print(f'The folder contains {num_images} images.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFzy3YrH9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rx8CzfX9rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGjjkXis9rpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce:\n"
      ],
      "metadata": {
        "id": "r69Yy9KS9r3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFjpaL71qgR",
        "outputId": "25c3c22d-1295-431c-de66-aeedc0711426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3864667587  0.3897000789  0.3901163938  0.3981846882  0.3810416256  0.4013417522  0.0000000000  1.5313433409  5.6991815567  0             27.390903472 \n",
            "0.7663247189  0.7667719021  0.9904320379  0.9861878453  0.9788913001  0.9668508287  1.2625764451  0.1483003787  5.7843055725  100           0.6112645364 \n",
            "0.7623791675  0.7582872928  0.9927993687  0.9881610103  0.9869796804  0.9798737174  2.5251528901  0.0304591087  5.7843055725  200           0.6120824623 \n",
            "0.8103176169  0.8086029992  0.9964490037  0.9881610103  0.9929966463  0.9798737174  3.7877293352  0.0201038574  5.7843055725  300           0.6128335547 \n",
            "0.7342177944  0.7229676401  0.9921088972  0.9881610103  0.9876701519  0.9731649566  5.0503057802  0.0166535372  5.7843055725  400           0.6066111851 \n",
            "0.7267705662  0.7213891081  0.9958571710  0.9909234412  0.9922075360  0.9763220205  6.3128822253  0.0185868401  5.7843055725  500           0.6118927002 \n",
            "0.7765831525  0.7778216259  0.9984217794  0.9925019732  0.9967449201  0.9818468824  7.5754586703  0.0134620355  5.7843055725  600           0.6051793170 \n",
            "0.7576938252  0.7480268350  0.9978299467  0.9936858721  0.9957585323  0.9842146803  8.8380351154  0.0087729464  5.7843055725  700           0.6085211968 \n",
            "0.7600611560  0.7563141279  0.9984217794  0.9925019732  0.9962517262  0.9818468824  10.100611560  0.0123126021  5.7843055725  800           0.6048365140 \n",
            "0.7093115013  0.7091554854  0.9961530874  0.9885556433  0.9950680608  0.9818468824  11.363188005  0.0064040128  5.7843055725  900           0.6142849422 \n",
            "0.7815150917  0.7792028414  0.9968435589  0.9901341752  0.9906293154  0.9790844515  12.625764450  0.0093996652  5.7843055725  1000          0.6039929366 \n",
            "0.7462024068  0.7490134175  0.9994081673  0.9921073402  0.9986190570  0.9834254144  13.888340895  0.0092029764  5.7843055725  1100          0.6129468703 \n",
            "0.8009469323  0.7959747435  0.9992108897  0.9928966062  0.9991122509  0.9857932123  15.150917340  0.0058361374  5.7843055725  1200          0.6129310250 \n",
            "0.7381633458  0.7391475927  0.9972381140  0.9897395422  0.9964490037  0.9802683504  16.413493785  0.0065432409  5.7843055725  1300          0.6122647572 \n",
            "0.6935292957  0.6906077348  0.9981258631  0.9913180742  0.9978299467  0.9802683504  17.676070230  0.0046631041  5.7843055725  1400          0.6144099188 \n",
            "0.6489938844  0.6475927388  0.9986190570  0.9940805051  0.9951666995  0.9786898185  18.938646675  0.0084209092  5.7843055725  1500          0.6136151099 \n",
            "0.7438350760  0.7450670876  0.9994081673  0.9913180742  0.9993095285  0.9869771113  20.201223120  0.0082047096  5.7843055725  1600          0.6134618235 \n",
            "0.7649437759  0.7588792423  0.9970408365  0.9885556433  0.9971394752  0.9794790845  21.463799566  0.0020670449  5.7843055725  1700          0.6151823425 \n",
            "0.8479976327  0.8433307024  0.9973367528  0.9893449092  0.9966462813  0.9767166535  22.726376011  0.0058088228  5.7843055725  1800          0.6114165998 \n",
            "0.7854113237  0.7847277032  0.9984217794  0.9921073402  0.9957585323  0.9814522494  23.988952456  0.0053677419  5.7843055725  1900          0.6099036169 \n",
            "0.7859538370  0.7786108919  0.9989149734  0.9917127072  0.9975340304  0.9834254144  25.251528901  0.0037218446  5.7843055725  2000          0.6132613826 \n",
            "0.6918524364  0.6793606946  0.9976326692  0.9897395422  0.9973367528  0.9830307814  26.514105346  0.0072307730  5.7843055725  2100          0.6134376049 \n",
            "0.7332314066  0.7269139700  0.9992108897  0.9948697711  0.9986190570  0.9802683504  27.776681791  0.0073834352  5.7843055725  2200          0.6204751110 \n",
            "0.7945847307  0.7878847672  0.9979285855  0.9913180742  0.9969421977  0.9818468824  29.039258236  0.0084000665  5.7843055725  2300          0.6125090265 \n",
            "0.7764845137  0.7647987372  1.0000000000  0.9917127072  0.9999013612  0.9834254144  30.301834681  0.0061496431  5.7843055725  2400          0.6324354410 \n",
            "0.6687216413  0.6590370955  0.9953639771  0.9834254144  0.9920102584  0.9767166535  31.564411126  0.0049843378  5.7843055725  2500          0.6270753837 \n",
            "0.7318011442  0.7241515391  0.9984217794  0.9889502762  0.9978299467  0.9814522494  32.826987571  0.0057329830  5.7843055725  2600          0.6227247167 \n",
            "0.7836851450  0.7756511444  0.9999013612  0.9944751381  0.9992108897  0.9838200474  34.089564016  0.0009479631  5.7843055725  2700          0.6132366180 \n",
            "0.7607023081  0.7576953433  0.9985204182  0.9925019732  0.9973367528  0.9802683504  35.352140461  0.0028693231  5.7843055725  2800          0.6186019158 \n",
            "0.7607516275  0.7513812155  0.9984217794  0.9885556433  0.9939830341  0.9767166535  36.614716906  0.0079865522  5.7843055725  2900          0.6299188948 \n",
            "0.7857072401  0.7758484609  0.9998027224  0.9909234412  0.9995068061  0.9846093133  37.877293351  0.0030832417  5.7843055725  3000          0.6098960829 \n",
            "0.7091635431  0.6939621152  0.9978299467  0.9885556433  0.9969421977  0.9771112865  39.139869796  0.0061063865  5.7843055725  3100          0.6046432948 \n",
            "0.7215427106  0.7095501184  0.9965476425  0.9893449092  0.9955612547  0.9806629834  40.402446241  0.0045622018  5.7843055725  3200          0.6033505225 \n",
            "0.7802821069  0.7715074980  0.9998027224  0.9925019732  0.9990136122  0.9881610103  41.665022686  0.0067104823  5.7843055725  3300          0.6084430003 \n",
            "0.7143420793  0.7109313339  0.9959558098  0.9869771113  0.9970408365  0.9782951855  42.927599132  0.0011498852  5.7843055725  3400          0.6063428593 \n",
            "0.6730124285  0.6653512234  0.9973367528  0.9889502762  0.9950680608  0.9739542226  44.190175577  0.0085864400  5.7843055725  3500          0.6008972216 \n",
            "0.6958966266  0.6898184688  0.9998027224  0.9921073402  0.9996054449  0.9857932123  45.452752022  0.0064733884  5.7843055725  3600          0.6162673044 \n",
            "0.7082757940  0.7028413575  1.0000000000  0.9956590371  0.9999013612  0.9889502762  46.715328467  0.0012216950  5.7843055725  3700          0.6148056483 \n",
            "0.7186328664  0.7099447514  1.0000000000  0.9944751381  1.0000000000  0.9889502762  47.977904912  0.0000642128  5.7843055725  3800          0.6070259309 \n",
            "0.7200631288  0.7113259669  0.9997040836  0.9921073402  0.9998027224  0.9861878453  49.240481357  0.0027398469  5.7843055725  3900          0.6156265235 \n",
            "0.7058591438  0.7091554854  0.9995068061  0.9940805051  0.9994081673  0.9881610103  50.503057802  0.0021378895  5.7843055725  4000          0.6109139323 \n",
            "0.6887453147  0.6779794791  0.9994081673  0.9917127072  0.9993095285  0.9861878453  51.765634247  0.0059131746  5.7843055725  4100          0.6170952582 \n",
            "0.6611757743  0.6572612470  0.9973367528  0.9913180742  0.9970408365  0.9806629834  53.028210692  0.0104169882  5.7843055725  4200          0.6217965150 \n",
            "0.6604853028  0.6515390687  0.9982245019  0.9905288082  0.9955612547  0.9763220205  54.290787137  0.0042702924  5.7843055725  4300          0.6096786547 \n",
            "0.7143913987  0.7036306235  0.9992108897  0.9936858721  0.9978299467  0.9802683504  55.553363582  0.0065798409  5.7843055725  4400          0.6024882984 \n",
            "0.7114815545  0.7056037885  0.9999013612  0.9952644041  0.9997040836  0.9917127072  56.815940027  0.0049846871  5.7843055725  4500          0.6199430537 \n",
            "0.6791773525  0.6659431728  0.9992108897  0.9928966062  0.9990136122  0.9806629834  58.078516472  0.0005054018  5.7843055725  4600          0.6146416759 \n",
            "0.7630203196  0.7582872928  0.9999013612  0.9956590371  1.0000000000  0.9869771113  59.341092917  0.0010236725  5.7843055725  4700          0.6122219038 \n",
            "0.7570033537  0.7513812155  0.9999013612  0.9952644041  0.9999013612  0.9881610103  60.603669362  0.0000619924  5.7843055725  4800          0.6136543655 \n",
            "0.6861807063  0.6712707182  0.9983231407  0.9889502762  0.9973367528  0.9810576164  61.866245807  0.0034500310  5.7843055725  4900          0.6070861173 \n",
            "0.6905208128  0.6902131018  0.9999013612  0.9952644041  0.9989149734  0.9822415154  63.128822252  0.0057498560  5.7843055725  5000          0.6079993272 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647,\\\n",
        "        \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLCqJpRpZla",
        "outputId": "1a0e5102-ef83-43f2-d0eb-2034bc3093f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        71.1 +/- 0.0               71.1                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        69.1 +/- 0.0               69.1                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSJ6vNQiFYD",
        "outputId": "6a81e146-dd33-456a-c9e6-95da2b3fd601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_medium/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 107MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3137699744  0.3155090766  0.4236535806  0.4340962904  0.4138883409  0.4352801894  0.0000000000  1.5721870661  5.6991815567  0             121.17406868 \n",
            "0.6615210101  0.6598263615  0.9904320379  0.9889502762  0.9813572697  0.9790844515  1.2625764451  0.1269948081  5.7843055725  100           0.5992083979 \n",
            "0.6557999605  0.6521310182  0.9934898402  0.9928966062  0.9871769580  0.9810576164  2.5251528901  0.0242757843  5.7843055725  200           0.6010344815 \n",
            "0.7217893076  0.7209944751  0.9941803117  0.9901341752  0.9905306767  0.9822415154  3.7877293352  0.0248986174  5.7843055725  300           0.6032668781 \n",
            "0.6864766226  0.6795580110  0.9990136122  0.9976322021  0.9960544486  0.9857932123  5.0503057802  0.0148176499  5.7843055725  400           0.6020192647 \n",
            "0.7547346617  0.7531570639  0.9977313080  0.9940805051  0.9947721444  0.9857932123  6.3128822253  0.0099429032  5.7843055725  500           0.6023221374 \n",
            "0.6849477214  0.6823204420  0.9983231407  0.9960536701  0.9959558098  0.9822415154  7.5754586703  0.0127289780  5.7843055725  600           0.5986590838 \n",
            "0.6821365161  0.6754143646  0.9976326692  0.9940805051  0.9963503650  0.9853985793  8.8380351154  0.0070593210  5.7843055725  700           0.5992206550 \n",
            "0.7350562241  0.7342146803  0.9992108897  0.9964483031  0.9980272243  0.9877663773  10.100611560  0.0090081152  5.7843055725  800           0.5954315782 \n",
            "0.6724699152  0.6637726914  0.9995068061  0.9956590371  0.9983231407  0.9877663773  11.363188005  0.0071447303  5.7843055725  900           0.5991444755 \n",
            "0.7353521405  0.7310576164  0.9983231407  0.9964483031  0.9978299467  0.9873717443  12.625764450  0.0082690991  5.7843055725  1000          0.6007423878 \n",
            "0.7047247978  0.6971191792  0.9989149734  0.9952644041  0.9990136122  0.9861878453  13.888340895  0.0095554909  5.7843055725  1100          0.5999678946 \n",
            "0.7175478398  0.7115232833  0.9984217794  0.9956590371  0.9976326692  0.9850039463  15.150917340  0.0074848697  5.7843055725  1200          0.6209489059 \n",
            "0.6003156441  0.5935280189  0.9908265930  0.9846093133  0.9845137108  0.9739542226  16.413493785  0.0061670831  5.7843055725  1300          0.6227960443 \n",
            "0.7109883606  0.6983030781  0.9990136122  0.9932912391  0.9984217794  0.9877663773  17.676070230  0.0095289110  5.7843055725  1400          0.6323509693 \n",
            "0.7592227264  0.7523677979  0.9981258631  0.9956590371  0.9963503650  0.9846093133  18.938646675  0.0060454098  5.7843055725  1500          0.6389152265 \n",
            "0.7201617676  0.7127071823  0.9993095285  0.9956590371  0.9986190570  0.9889502762  20.201223120  0.0078355287  5.7843055725  1600          0.6430245256 \n",
            "0.7292858552  0.7211917916  0.9998027224  0.9956590371  0.9997040836  0.9925019732  21.463799566  0.0018214593  5.7843055725  1700          0.6293191934 \n",
            "0.7227756954  0.7123125493  0.9999013612  0.9968429361  0.9999013612  0.9893449092  22.726376011  0.0015204751  5.7843055725  1800          0.6129930377 \n",
            "0.6896823831  0.6892265193  0.9999013612  0.9964483031  0.9998027224  0.9897395422  23.988952456  0.0028037445  5.7843055725  1900          0.6100966716 \n",
            "0.7653383310  0.7582872928  0.9993095285  0.9964483031  0.9994081673  0.9932912391  25.251528901  0.0004546101  5.7843055725  2000          0.6023241353 \n",
            "0.7000887749  0.6896211523  0.9985204182  0.9936858721  0.9977313080  0.9865824783  26.514105346  0.0064458975  5.7843055725  2100          0.5988242507 \n",
            "0.6427303216  0.6410812944  0.9988163346  0.9968429361  0.9988163346  0.9873717443  27.776681791  0.0060048382  5.7843055725  2200          0.5992763162 \n",
            "0.7598638785  0.7527624309  1.0000000000  0.9988161010  0.9998027224  0.9905288082  29.039258236  0.0023152082  5.7843055725  2300          0.5971370530 \n",
            "0.6899289801  0.6874506709  0.9981258631  0.9913180742  0.9959558098  0.9873717443  30.301834681  0.0050733112  5.7843055725  2400          0.5996246147 \n",
            "0.7281515092  0.7239542226  0.9898402052  0.9767166535  0.9817518248  0.9723756906  31.564411126  0.0072616203  5.7843055725  2500          0.5943894243 \n",
            "0.7001380943  0.6992896606  0.9995068061  0.9956590371  0.9988163346  0.9881610103  32.826987571  0.0440309145  5.7843055725  2600          0.6050425506 \n",
            "0.7320970606  0.7237569061  0.9992108897  0.9956590371  0.9990136122  0.9905288082  34.089564016  0.0048803466  5.7843055725  2700          0.6109957647 \n",
            "0.6917044782  0.6831097080  0.9991122509  0.9932912391  0.9984217794  0.9846093133  35.352140461  0.0067349893  5.7843055725  2800          0.6111056709 \n",
            "0.7432432432  0.7421073402  1.0000000000  0.9984214680  0.9995068061  0.9893449092  36.614716906  0.0033565566  5.7843055725  2900          0.6050006723 \n",
            "0.6926415467  0.6876479874  0.9998027224  0.9952644041  0.9990136122  0.9857932123  37.877293351  0.0042016615  5.7843055725  3000          0.6177810144 \n",
            "0.7025547445  0.6949486977  0.9993095285  0.9976322021  0.9993095285  0.9897395422  39.139869796  0.0010211611  5.7843055725  3100          0.6140088010 \n",
            "0.7367330834  0.7367797948  0.9998027224  0.9972375691  0.9999013612  0.9893449092  40.402446241  0.0002262877  5.7843055725  3200          0.6185925364 \n",
            "0.7027027027  0.7020520916  1.0000000000  0.9976322021  1.0000000000  0.9913180742  41.665022686  0.0000888569  5.7843055725  3300          0.6096006036 \n",
            "0.6934306569  0.6850828729  0.9984217794  0.9952644041  0.9978299467  0.9865824783  42.927599132  0.0015141229  5.7843055725  3400          0.6194707274 \n",
            "0.7383113040  0.7346093133  0.9997040836  0.9972375691  0.9996054449  0.9901341752  44.190175577  0.0052019510  5.7843055725  3500          0.6134506059 \n",
            "0.7237127639  0.7231649566  1.0000000000  0.9980268350  0.9997040836  0.9865824783  45.452752022  0.0014862453  5.7843055725  3600          0.6209367180 \n",
            "0.7188794634  0.7131018153  1.0000000000  0.9972375691  1.0000000000  0.9921073402  46.715328467  0.0002694762  5.7843055725  3700          0.6362010550 \n",
            "0.7268692050  0.7259273875  0.9997040836  0.9940805051  0.9994081673  0.9897395422  47.977904912  0.0023738948  5.7843055725  3800          0.6051948500 \n",
            "0.7473367528  0.7415153907  0.9980272243  0.9940805051  0.9964490037  0.9838200474  49.240481357  0.0045498827  5.7843055725  3900          0.6058934021 \n",
            "0.7382126652  0.7344119968  0.9985204182  0.9968429361  0.9986190570  0.9869771113  50.503057802  0.0044438702  5.7843055725  4000          0.5994641709 \n",
            "0.6705464589  0.6643646409  0.9996054449  0.9925019732  0.9985204182  0.9850039463  51.765634247  0.0016873248  5.7843055725  4100          0.6027762508 \n",
            "0.7104458473  0.7071823204  0.9964490037  0.9877663773  0.9947721444  0.9822415154  53.028210692  0.0083639084  5.7843055725  4200          0.6098940921 \n",
            "0.7332807260  0.7302683504  1.0000000000  0.9972375691  1.0000000000  0.9905288082  54.290787137  0.0016600816  5.7843055725  4300          0.6013520265 \n",
            "0.7476326692  0.7407261247  0.9999013612  0.9948697711  0.9993095285  0.9897395422  55.553363582  0.0006339125  5.7843055725  4400          0.6025332189 \n",
            "0.7573979089  0.7525651144  0.9995068061  0.9980268350  0.9997040836  0.9877663773  56.815940027  0.0026876356  5.7843055725  4500          0.6076181936 \n",
            "0.6943677254  0.6925808998  0.9982245019  0.9936858721  0.9981258631  0.9842146803  58.078516472  0.0067190079  5.7843055725  4600          0.6034590435 \n",
            "0.7445255474  0.7391475927  0.9998027224  0.9976322021  0.9998027224  0.9909234412  59.341092917  0.0018836914  5.7843055725  4700          0.6027166390 \n",
            "0.7162655356  0.7067876875  1.0000000000  0.9964483031  0.9995068061  0.9885556433  60.603669362  0.0002436092  5.7843055725  4800          0.6082473326 \n",
            "0.7426020911  0.7385556433  0.9997040836  0.9948697711  0.9996054449  0.9905288082  61.866245807  0.0029796615  5.7843055725  4900          0.6071765113 \n",
            "0.7145393569  0.7097474349  0.9997040836  0.9944751381  0.9995068061  0.9897395422  63.128822252  0.0053898869  5.7843055725  5000          0.5998121667 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_medium/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuk-R16KzgOs",
        "outputId": "88244172-31ce-4811-8014-0c01efa9820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_hard/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 122MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             115.15087747 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.6141159964 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6257791138 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6224927640 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6194511318 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6173342490 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6224610925 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6156367707 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6182522154 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6168373513 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6274501014 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6201179457 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6196286297 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6265635109 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6200313568 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6176273632 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6281948471 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6170152378 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6204898381 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6164195275 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6218380213 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6168248272 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6204351020 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6241048074 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6225018644 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6205320001 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6193700123 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6194021606 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6208199739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6187628269 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6196645617 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6212025905 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6200934267 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6221250558 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6164404726 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6187021542 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6219896412 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6192560601 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6193850613 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6188530970 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6250334597 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6187652969 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6202621436 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6278406334 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6186798120 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6220876169 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6206880021 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6187240529 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6160216904 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6204047894 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6245353127 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_hard/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3W8kEpoNLl",
        "outputId": "3aafe63a-379d-4388-d85e-894fe453b5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/5 [00:00<?, ?it/s]\r                                                                                \rTotal records: 162\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.1 +/- 0.0               76.5 +/- 0.0               62.0 +/- 0.0               69.9                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        69.1 +/- 0.0               71.5 +/- 0.0               65.6 +/- 0.0               68.7                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtUrzrD4gOn",
        "outputId": "5a15d81f-aaee-46da-c1e9-64ebe124f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3447425528  0.3441199684  0.4174393371  0.4167324388  0.3603274808  0.3756906077  0.0000000000  1.5444172621  5.6991815567  0             92.626631498 \n",
            "0.8121424344  0.8239936859  0.9850069047  0.9790844515  0.9830341290  0.9818468824  1.2625764451  0.1916547985  5.7843055725  100           0.6161201310 \n",
            "0.7284474255  0.7334254144  0.9866837641  0.9790844515  0.9876701519  0.9822415154  2.5251528901  0.0378335118  5.7843055725  200           0.6242212915 \n",
            "0.7226277372  0.7243488556  0.9810613533  0.9629044988  0.9826395739  0.9763220205  3.7877293352  0.0316097732  5.7843055725  300           0.6324607801 \n",
            "0.7568553955  0.7604577743  0.9951666995  0.9865824783  0.9946735056  0.9861878453  5.0503057802  0.0218457361  5.7843055725  400           0.6257872558 \n",
            "0.7536003156  0.7574980268  0.9976326692  0.9877663773  0.9951666995  0.9897395422  6.3128822253  0.0149130280  5.7843055725  500           0.6235587239 \n",
            "0.7291378970  0.7357932123  0.9983231407  0.9893449092  0.9986190570  0.9936858721  7.5754586703  0.0117882919  5.7843055725  600           0.6279401875 \n",
            "0.7667192740  0.7693370166  0.9972381140  0.9869771113  0.9940816729  0.9889502762  8.8380351154  0.0145306918  5.7843055725  700           0.6247380352 \n",
            "0.7499506806  0.7573007103  0.9987176958  0.9901341752  0.9971394752  0.9913180742  10.100611560  0.0118083848  5.7843055725  800           0.6312047601 \n",
            "0.7436871178  0.7490134175  0.9961530874  0.9853985793  0.9956598935  0.9897395422  11.363188005  0.0109967921  5.7843055725  900           0.6202681732 \n",
            "0.7388044979  0.7474348856  0.9984217794  0.9905288082  0.9988163346  0.9932912391  12.625764450  0.0094502301  5.7843055725  1000          0.6276606607 \n",
            "0.7751035707  0.7717048145  0.9973367528  0.9822415154  0.9943775893  0.9869771113  13.888340895  0.0125363544  5.7843055725  1100          0.6285728884 \n",
            "0.7802327875  0.7839384373  0.9979285855  0.9877663773  0.9977313080  0.9889502762  15.150917340  0.0060999116  5.7843055725  1200          0.6247079110 \n",
            "0.7494081673  0.7580899763  0.9963503650  0.9881610103  0.9939830341  0.9850039463  16.413493785  0.0112833397  5.7843055725  1300          0.6322773695 \n",
            "0.7387551785  0.7470402526  0.9997040836  0.9932912391  0.9991122509  0.9925019732  17.676070230  0.0054056202  5.7843055725  1400          0.6218444490 \n",
            "0.7769283882  0.7778216259  0.9954626159  0.9830307814  0.9946735056  0.9869771113  18.938646675  0.0055534037  5.7843055725  1500          0.6221671605 \n",
            "0.7031958966  0.7073796369  0.9993095285  0.9861878453  0.9988163346  0.9936858721  20.201223120  0.0049165712  5.7843055725  1600          0.6286919904 \n",
            "0.7267705662  0.7241515391  0.9984217794  0.9885556433  0.9983231407  0.9905288082  21.463799566  0.0085521347  5.7843055725  1700          0.6241571999 \n",
            "0.6414973368  0.6497632202  0.9959558098  0.9869771113  0.9966462813  0.9869771113  22.726376011  0.0072744866  5.7843055725  1800          0.6317688847 \n",
            "0.7176464786  0.7237569061  0.9986190570  0.9889502762  0.9985204182  0.9885556433  23.988952456  0.0103979792  5.7843055725  1900          0.6230329943 \n",
            "0.7049713948  0.7058011050  0.9990136122  0.9877663773  0.9986190570  0.9897395422  25.251528901  0.0090116992  5.7843055725  2000          0.6276224732 \n",
            "0.7456105741  0.7494080505  0.9995068061  0.9940805051  0.9988163346  0.9925019732  26.514105346  0.0028007768  5.7843055725  2100          0.6244829988 \n",
            "0.7336752811  0.7395422257  0.9983231407  0.9909234412  0.9982245019  0.9897395422  27.776681791  0.0026261529  5.7843055725  2200          0.6262957954 \n",
            "0.7256362202  0.7332280979  0.9992108897  0.9901341752  0.9988163346  0.9925019732  29.039258236  0.0057956400  5.7843055725  2300          0.6327015185 \n",
            "0.7500986388  0.7533543804  0.9999013612  0.9913180742  0.9996054449  0.9917127072  30.301834681  0.0036455327  5.7843055725  2400          0.6239596629 \n",
            "0.7312586309  0.7320441989  0.9995068061  0.9921073402  0.9990136122  0.9901341752  31.564411126  0.0055238133  5.7843055725  2500          0.6324523091 \n",
            "0.6998421779  0.7042225730  0.9975340304  0.9850039463  0.9986190570  0.9897395422  32.826987571  0.0033805106  5.7843055725  2600          0.6255412984 \n",
            "0.7127638587  0.7168508287  0.9993095285  0.9905288082  0.9987176958  0.9928966062  34.089564016  0.0076531138  5.7843055725  2700          0.6293179131 \n",
            "0.7118761097  0.7156669298  0.9982245019  0.9897395422  0.9994081673  0.9913180742  35.352140461  0.0009840014  5.7843055725  2800          0.6253333163 \n",
            "0.6811008088  0.6838989740  0.9984217794  0.9897395422  0.9981258631  0.9877663773  36.614716906  0.0084054508  5.7843055725  2900          0.6237844157 \n",
            "0.6834188203  0.6831097080  0.9950680608  0.9798737174  0.9948707832  0.9857932123  37.877293351  0.0044238523  5.7843055725  3000          0.6262417722 \n",
            "0.6974748471  0.6994869771  0.9990136122  0.9921073402  0.9991122509  0.9897395422  39.139869796  0.0053147116  5.7843055725  3100          0.6270702934 \n",
            "0.7625764451  0.7665745856  0.9983231407  0.9857932123  0.9987176958  0.9913180742  40.402446241  0.0073252049  5.7843055725  3200          0.6314353418 \n",
            "0.7540935096  0.7634175217  0.9960544486  0.9826361484  0.9956598935  0.9861878453  41.665022686  0.0049057113  5.7843055725  3300          0.6251897311 \n",
            "0.7499506806  0.7535516969  0.9972381140  0.9834254144  0.9981258631  0.9917127072  42.927599132  0.0060753603  5.7843055725  3400          0.6289313126 \n",
            "0.7582363385  0.7586819258  0.9996054449  0.9909234412  0.9991122509  0.9893449092  44.190175577  0.0043921365  5.7843055725  3500          0.6250557089 \n",
            "0.7938942592  0.7989344909  0.9983231407  0.9881610103  0.9973367528  0.9913180742  45.452752022  0.0058474739  5.7843055725  3600          0.6268724537 \n",
            "0.7414677451  0.7472375691  0.9993095285  0.9909234412  0.9994081673  0.9921073402  46.715328467  0.0069936835  5.7843055725  3700          0.6215211320 \n",
            "0.7010258434  0.7063930545  0.9998027224  0.9925019732  0.9993095285  0.9928966062  47.977904912  0.0050067931  5.7843055725  3800          0.6244132352 \n",
            "0.7601104754  0.7582872928  0.9984217794  0.9869771113  0.9954626159  0.9873717443  49.240481357  0.0033604602  5.7843055725  3900          0.6313518667 \n",
            "0.7292365358  0.7352012628  1.0000000000  0.9960536701  1.0000000000  0.9917127072  50.503057802  0.0013490497  5.7843055725  4000          0.6236331105 \n",
            "0.7278062734  0.7357932123  0.9999013612  0.9917127072  0.9997040836  0.9921073402  51.765634247  0.0003818883  5.7843055725  4100          0.6287024641 \n",
            "0.7287926613  0.7336227309  0.9989149734  0.9853985793  0.9990136122  0.9913180742  53.028210692  0.0050014239  5.7843055725  4200          0.6291932082 \n",
            "0.7303215624  0.7377663773  0.9999013612  0.9889502762  0.9997040836  0.9901341752  54.290787137  0.0019504495  5.7843055725  4300          0.6304660201 \n",
            "0.7283487867  0.7322415154  1.0000000000  0.9921073402  0.9992108897  0.9921073402  55.553363582  0.0029379294  5.7843055725  4400          0.6251601553 \n",
            "0.7387058591  0.7399368587  0.9985204182  0.9885556433  0.9974353916  0.9913180742  56.815940027  0.0021374228  5.7843055725  4500          0.6251562452 \n",
            "0.6670447820  0.6708760852  0.9999013612  0.9932912391  0.9989149734  0.9897395422  58.078516472  0.0064164825  5.7843055725  4600          0.6286752725 \n",
            "0.7800848294  0.7833464878  0.9954626159  0.9830307814  0.9954626159  0.9885556433  59.341092917  0.0082279910  5.7843055725  4700          0.6250292301 \n",
            "0.6997435392  0.7042225730  0.9991122509  0.9925019732  0.9993095285  0.9925019732  60.603669362  0.0060093180  5.7843055725  4800          0.6258044958 \n",
            "0.7043795620  0.7111286504  0.9996054449  0.9917127072  0.9991122509  0.9928966062  61.866245807  0.0029612238  5.7843055725  4900          0.6235942554 \n",
            "0.7195699349  0.7170481452  0.9990136122  0.9909234412  0.9976326692  0.9877663773  63.128822252  0.0055418774  5.7843055725  5000          0.6231913924 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVSmQgNyig5",
        "outputId": "d6ede5dd-1397-4f48-f18f-ba33b2f2faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3572696784  0.3620757695  0.4539356875  0.4613259669  0.4520615506  0.4723756906  0.0000000000  1.6331243515  5.6991815567  0             55.661369085 \n",
            "0.4934405208  0.4964483031  0.9753403038  0.9688239937  0.9762280529  0.9723756906  1.2625764451  0.1566427394  5.7843055725  100           0.6162090135 \n",
            "0.5097159203  0.5185477506  0.9811599921  0.9775059195  0.9777076346  0.9668508287  2.5251528901  0.0377939333  5.7843055725  200           0.6225361347 \n",
            "0.5271256658  0.5380820837  0.9936871178  0.9881610103  0.9930952851  0.9861878453  3.7877293352  0.0288028434  5.7843055725  300           0.6236338639 \n",
            "0.4824422963  0.4968429361  0.9942789505  0.9877663773  0.9955612547  0.9909234412  5.0503057802  0.0388437792  5.7843055725  400           0.6268619251 \n",
            "0.5513908069  0.5586029992  0.9965476425  0.9869771113  0.9954626159  0.9869771113  6.3128822253  0.0148880032  5.7843055725  500           0.6201543760 \n",
            "0.4632570527  0.4727703236  0.9920102584  0.9794790845  0.9947721444  0.9857932123  7.5754586703  0.0180947598  5.7843055725  600           0.6200311804 \n",
            "0.3317715526  0.3326756117  0.9895442888  0.9767166535  0.9944762281  0.9893449092  8.8380351154  0.0098999443  5.7843055725  700           0.6183829451 \n",
            "0.4919609390  0.4948697711  0.9970408365  0.9865824783  0.9965476425  0.9857932123  10.100611560  0.0145966782  5.7843055725  800           0.6291699719 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUY2J85V-Ad",
        "outputId": "9e6fcdee-21bb-48d4-e2a2-b3f4f60d6298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.9 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.9 +/- 0.0               72.9                      \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.0 +/- 0.0               72.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output_M2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFubiAzerSGY",
        "outputId": "f7a88181-e706-4af8-a327-0b1490d252a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                    | 0/13 [00:00<?, ?it/s]\r                                                                                \rTotal records: 53\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               76.5 +/- 0.0               76.6                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               71.5 +/- 0.0               74.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2WzQYG9FSV",
        "outputId": "66d56659-a265-45fe-fb14-15d19d5c51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: train_output\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             99.749756574 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.5983280587 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6206359911 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6142829299 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6070183587 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6080141449 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6082016397 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6092026901 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6103980064 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6360183382 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6049654841 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6108168197 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6118657756 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6163139319 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6108947682 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6053397083 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6072963905 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6118159246 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6154971886 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6100856686 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6081331706 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6135662699 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6160948730 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6087784386 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6098929572 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6067762327 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6125501800 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6110928893 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6085288739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6073611617 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6072861338 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6083596730 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6128425336 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6068048215 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6056645203 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6041939640 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6081425190 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6051037884 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6070308352 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6057835174 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6114358330 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6085151696 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6074985671 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6056443095 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6110575628 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6077594399 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6041522574 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6092551422 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6140078497 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6102016497 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6084288812 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0 \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyPsM8-qTs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/train_output /content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeSXi_BAsw2",
        "outputId": "f8a407f0-e5b5-4577-e522-74fb8eb078eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 102\n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        76.5 +/- 0.0               62.0 +/- 0.0               69.3                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.5 +/- 0.0               65.6 +/- 0.0               68.5                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxPRKSpd7tW",
        "outputId": "e0a98e3b-2119-4b5a-d89a-0b08cc774ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
            "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
            "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
            "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 78, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
            "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
            "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
            "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/stringpict.py\", line 15, in <module>\n",
            "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Colab执行train.py脚本\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py\\\n",
        "        --data_dir=./domainbed/data/MNIST/\\\n",
        "        --algorithm IGA\\\n",
        "        --dataset ColoredMNIST\\\n",
        "        --test_env 2\n",
        "\n",
        "#启动python3解释器，并且执行名为train.py的python脚本\n",
        "#--data_dir, --algorithm, --dataset, --text_env是train.py文件中的命令行参数，命令行参数用来制定程序或脚本执行书所需要的配置，选项或参数。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXA5s87_0FX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 读取图像\n",
        "img = cv2.imread('input_image.jpg')\n",
        "\n",
        "# 创建与输入图像相同大小的掩码\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "\n",
        "# 创建前景和背景模型\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "# 定义一个矩形ROI，用于指定图像中的前景对象\n",
        "rect = (50,50,450,290)\n",
        "\n",
        "# 使用GrabCut算法进行图像分割\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# 将掩码中的可能的前景和可能的背景区域设置为0和2\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# 将原始图像与掩码相乘以获取前景对象\n",
        "img = img*mask2[:,:,np.newaxis]\n",
        "\n",
        "# 显示结果\n",
        "cv2.imshow('Result', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8MAbsYPTOg",
        "outputId": "4e5ff9f9-5fbd-4dbc-8b46-79903673f419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=\"/env/python:/content/DomainBed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tbOpWGPat2",
        "outputId": "f18a4248-822b-47e9-ae93-45ef19092c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLo5O4wdhf9",
        "outputId": "2f40c461-8185-4792-f68e-3a0b676773ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a5269aa7743b791c64ed6649418c057a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 575962639\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/173bf54d6d078902e3c95d84cd058342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 177603528\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/35d2062ac241826e2573114eb184c10b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1731344775\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 7.625215427542097e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.00047223799345445756\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/30fd34e2f4f278867b6ff5b3217c9af4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1643360463\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/93cbbc15feea120dcb5ef40876e5d339\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1552394041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b85999a8f7f51d5d4618de70657b6458\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 872123425\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7c7b782b06a6e854e2a90f87af941fab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1532722295\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ad9ee36f7c977d2e63461bd67f281f65\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1348154927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c6917ed9721df5093c80bb496ec569e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1049203149\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 12\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e09d3ae124ba408cc7b777e802abfc3b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 820509365\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.0061945703598755e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0003150750110930775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ec6ad8a352a25d018524a0799865c9c7\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 305456027\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a12555295bb7c7f7b16f49fa46aa6d43\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 335001469\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3933a42f4a7daf484c66126f193511cd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1090282834\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e0caf4e9b7f63f5f2e9dfc9c2cbd706f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 707756686\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.7028930742148706e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00044832883881609976\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a8bfbb8d29ad30056577251d58640c92\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1803180728\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3e97244e0bba4eff7f3112b1a237b744\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 988398352\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.5948054187960416e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.2409030903340844e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c56965d1318c614519d8d1aeeec2acc0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1033766585\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/359830bd171b960b8f49828cf7daea45\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1062091682\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c71071003a4a8e03d31fbc73dc56b251\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1323517681\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c21df39fbbbbff9e17a2219b8a0bdb4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 899531956\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.1059719178287245e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0226894592810383e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/144f7e007023484daf0f1835e105fa02\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1174342691\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00028242988155030726\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.0915251755880437e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/60e1b946d5dfb28c75817cb3b0f37895\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 894262147\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 15\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.768725917122619e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.692204119563736e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9e4750f5e7cdef36d12c41b1a6b11d8b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 430670040\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/d407d5a24ac774b5d0e87374d7bb0dcc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 939727439\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9b1089b3fd6bf0f3ece44fc77e993b3e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 406951466\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/eb213ec0817439be32acdbd077992b09\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 471015569\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa8f08ae34d3dae732c41aa5d02c8316\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 534836152\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/48d90e374515bb88643f4e2e9410980b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1405017170\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.456280188921339e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.005463379786545902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/123c1a60dc113b3ef130905aab29cf61\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1450517853\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/6830b2706bf869ab62120c8ec8a3d902\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1428592723\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3826168925328977e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.615900325399353e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a928b33eb83a3c2cd3efa5ea3f1ea8d9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1629628786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/476612568012d54c53a90e62b696d7bb\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1884237580\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 19\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f87bb4114b1895f7916f2b4ffc4cb860\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 536959106\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 11\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.323285967621206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.046120234156778e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b796a096bf44125b17789f4408dca06b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1903818547\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2eee150674bdf7a82d8c51eb4b1ce04a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 23433006\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/abc93fad1fd1056001dbadf8a1ca9e19\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1664885690\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1d6201f69bb66d8b6e489eda38dccc2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1064525671\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/61034eaa8320196809d9f605b075ea24\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 95358269\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a2a7ca35a2f50073f1242eb91762424c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1823278137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/09c50cd0748144c2769d47af395d8a2f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 809856719\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4134e9367b6221b835b22b88489a951d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 164181522\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dff4b52c83c4125df3323fd2db2b9f81\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 275388093\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b91c3a1a306c19c073d526f06d69ba03\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 216618918\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2c1b55962114ca954a4293b359288011\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 441369813\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5f9a4b767b89224a4075aee4b86b6256\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2034037337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002383446436179699\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 6.431270010222042e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/8b64798c53a5a1bba405d5c75dbf27e9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 693005437\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4b0c702dd74c39ad2ca842e5f3fc8ffc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1721323264\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5c18fb7899bf0c12dc359ebe9c1081d6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 244140596\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a44e96d250f70e7917800a5786e1f2fe\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 338717337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7d28429d6d35cc9f06f22e3a55845051\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1588968328\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002748180350891229\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.9000025480760227e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/991425b1146b1f446d84b36c087a6ef2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 895393786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/23a434a5febeed79a9ed9afeeb610ea9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1005706515\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e31aa2e37b983f5aa514b6243bb897e4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 539823350\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/97caedc9c298c79240b7148e65bd4864\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 848241137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/37de55f16c6cadbf954bb9c28018c6c9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1441525987\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1b86d2e19fa131d32841fa95fc15428\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1025341559\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.079846025444368e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.634713155314057e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84459224cbcb079b22304c4ca0337b15\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 658930196\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/840cda333a109b446d2d0be1aec01f44\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 797173368\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/0db98c8fc5bbd3ad85f5198cd2a9e242\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1690752950\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/00bb81be3e5faa7fa0e06a3d1b9fc214\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 640543768\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 35\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.203148467315319e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.5941595326730853e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a3cf6270845a5d9f19504a02c74d48d8\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 527331476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b719be2f2334c73ca22825242a857d83\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 794168150\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84dc1acf1587fab8013f239b8ee2a854\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 140411788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3b7e19147f067cefd3e300112c5744d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 889114309\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2bd0763b666af3a8b7180488e49f5df1\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1600026954\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ee01751ed5822f49800f2dff6d39011c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 652031788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a1fc347c08f7519f1a9885e2e4e1cc5a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2028568414\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3967520349d463cc0f4b42aa0e5a3cdc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2011109722\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a068a437f435df1e975b81101ea52090\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 887238287\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dcded23bc701bc64d1143bea8426fa7a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 874017095\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b338ef7ae36014cea7290002c49cdeab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 397958724\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7fcd0102087c6411f477f01e6e94adcd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1653294381\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f5541915a154a7ea2d59d32511dca70e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1008122992\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f4402201077fefda135d3f266680fb9d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1974935474\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fef9439cc09895fc8d5ed384d557aa2e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1905078720\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/21ce002219dcf5223be83527bc032575\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 16214241\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fae278ee4d6005566e976812d300076e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1838315136\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/15aef282c233ccf23bb82500660e4a85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1806374394\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/95dcaf3d7552b20d324e650e8344e391\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2139648535\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b59d08c5158891d095647c260599df72\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 863415268\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/396a66c0e9a33f42933162e9e157a7f6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1028178153\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/40a2ab0a6403041f72bcd672cd9685a6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2114559099\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dd31f52ac86bba2d9ad1ffdeee34c342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2029184004\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9cb8aefc8442b126f9c05a7cce526779\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 902654909\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/398e724ba11d5f6f2445d5b356ace1b0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1764407478\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4256491a7b9ddea5fd4f3b9404ed7948\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1041059927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa922f8e301f7a452a7d7802449b8900\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1622227716\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/bc89363eaa59127ca10cf772d2c57263\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1192519524\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/56102dff2a7005ef5db4c5933673ea85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 152054124\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 21\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00011281359420053416\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 5.000446907120253e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3f28d0e95f209ff5df269857a136372\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 472711008\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4514b27fbe9c296ab91cd05de3734f5e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1704833476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00015197093111758464\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0329604555494109e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9222fb7e414cd07468f4347ff233885d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 463949901\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4d35045a63b1eff681e8a628d2988b23\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 37332015\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.1375153221880086e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 6.326696718610415e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f936c2b44cc3dab85a923d914871cc4a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1141715041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c08bd5bdc0e4a927433e11e6f552089e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1353102125\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/205162f67cb34c386d1288cf23a3e73f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1743459794\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Launched 360 jobs!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.sweep launch\\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224\\\n",
        "       --output_dir=/content/MyDrive/ip/sweep_output\\\n",
        "       --command_launcher local\\\n",
        "       --algorithms ERM\\\n",
        "       --datasets SpawriousO2O_easy\\\n",
        "       --skip_confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr393evgOlTE",
        "outputId": "ace5ca35-edc0-49e3-ff67-4f086f769414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in directory: /content/domainbed/data\n",
            "MNIST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 指定要查看的目录路径\n",
        "data_dir = '/content/domainbed/data'  # 这里替换为你下载数据的目录路径\n",
        "\n",
        "# 列出指定目录下的文件和文件夹\n",
        "files_and_folders = os.listdir(data_dir)\n",
        "\n",
        "# 输出文件和文件夹列表\n",
        "print(\"Files and folders in directory:\", data_dir)\n",
        "for item in files_and_folders:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLTQ7T-5lgV"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peRMyZEz54u3",
        "outputId": "4d3a351e-775f-465a-a50d-86f28087b753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnjVjGVkZAQy"
      },
      "source": [
        "将所有图片转换成rgb形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZYfhASF-6u"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hzsjtd9Fn2k"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/ip/spawrious224/\"\n",
        "hparams = {\"data_augmentation\": True}\n",
        "test_envs = 0\n",
        "spawrious_o2o_easy = SpawriousO2O_easy(root_dir, test_envs, hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ByCqk5tsF2L8",
        "outputId": "bee03919-976b-48c0-fa21-5842a7b81a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'build_type1_combination' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-d9a268ae9e32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_type1_combination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_type1_combination' is not defined"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_o2o_easy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "8bwrHD3Qsnwv",
        "outputId": "2062da6d-58a0-4ecd-e19d-3fbc65dac0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [01:48<00:00, 29.17it/s]\n",
            "  4%|▍         | 136/3168 [00:32<12:02,  4.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-115b0497dc50>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0munloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk43pd2wZJ0M"
      },
      "source": [
        "寻找corgi类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUk9545INv",
        "outputId": "1c907d20-5c53-4e72-a511-78a91db9bbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corgi_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2441.png', 'drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2.png'), 'corgi')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "\n",
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/corgi/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "\n",
        "corgi_image_pairs = []\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, 'corgi'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "\n",
        "# 将 corgi_image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(corgi_image_pairs, f)\n",
        "\n",
        "print(\"Corgi_image pairs saved successfully.\")\n",
        "print(corgi_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeA1A4ALZNYR"
      },
      "source": [
        "寻找bulldog类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyT3OSv5IQT",
        "outputId": "585e03c4-a5f5-45a1-c88f-c595dffa4f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Bulldog_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/bulldog/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    bulldog_image_pairs.append((image_pair, 'bulldog'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(bulldog_image_pairs, f)\n",
        "\n",
        "print(\"Bulldog_image pairs saved successfully.\")\n",
        "print(bulldog_image_pairs[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZakjqAa0mfd",
        "outputId": "cb31c59b-f8c1-4cdc-c285-42c4174ee333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulldog\n"
          ]
        }
      ],
      "source": [
        "print(bulldog_image_pairs[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5rsjqJZRZA"
      },
      "source": [
        "寻找dachshund类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECFZVVm5ISR",
        "outputId": "4ae21f17-ad08-4abf-b6b4-32a0599c1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Dachshund_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/dachshund/jungle_dachshund_2902.png', 'drive/MyDrive/ip/spawrious224/0/dirt/dachshund/dirt_dachshund_343.png'), 'dachshund')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/dachshund/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, 'dachshund'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(dachshund_image_pairs, f)\n",
        "\n",
        "print(\"Dachshund_image pairs saved successfully.\")\n",
        "print(dachshund_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rg9-OhsZW5L"
      },
      "source": [
        "寻找labrador类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJlI-7ZYi36",
        "outputId": "46c742ff-2dfa-4b2b-b784-b0159d897f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "labrador_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_1201.png', 'drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_563.png'), 'labrador')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/labrador/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, 'labrador'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(labrador_image_pairs, f)\n",
        "\n",
        "print(\"labrador_image pairs saved successfully.\")\n",
        "print(labrador_image_pairs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZrnXz155UP",
        "outputId": "53e9bcbf-5edf-4b44-ca94-7e3105e3d6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_84.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1530.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_767.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1743.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2387.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_760.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_277.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_726.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2953.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_108.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3163.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2315.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2777.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1187.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_453.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_15.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2413.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_561.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_924.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_232.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1990.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1076.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_72.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1741.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2743.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_239.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_325.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1091.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_570.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_358.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_892.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3150.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2448.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3015.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_186.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1691.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1509.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_642.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1888.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_150.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2282.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3003.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1379.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2980.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2456.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2364.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2308.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_248.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2026.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2679.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_307.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2849.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1887.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3136.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2786.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3000.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_470.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2965.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_791.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2599.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3161.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1707.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1886.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_830.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2378.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_916.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_768.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2295.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2137.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1126.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2966.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1845.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_232.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2885.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1513.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2699.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1051.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_159.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2067.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2853.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_98.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2226.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1131.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1441.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2613.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2625.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_877.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_424.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2505.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2908.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_535.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1043.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_663.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1536.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1818.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1616.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2796.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_376.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1318.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_261.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1939.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1933.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2282.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1356.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_6.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_222.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2452.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2738.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1883.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2041.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_895.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3084.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_167.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2461.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2204.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1463.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2982.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_541.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1523.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2483.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1299.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_867.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2379.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_1309.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2053.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2740.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_920.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_2389.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2985.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_2435.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_803.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1697.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_291.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1006.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1563.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1796.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1753.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2466.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_935.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2864.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1505.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_772.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1364.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3008.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2936.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_364.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1347.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_797.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1124.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1574.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1934.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2514.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_52.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1388.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2320.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2129.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_3076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1084.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_329.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2630.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_2588.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2372.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_730.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2140.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2166.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3046.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1634.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1942.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_839.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_473.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_420.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_30.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2847.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2576.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2185.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_923.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1769.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_508.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_486.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_3099.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1973.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_244.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2066.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3054.png'), 'bulldog')]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 打开 .pkl 文件\n",
        "file_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 查看文件中的数据\n",
        "print(data[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaxZX0939Vu",
        "outputId": "88087c2c-bcfe-4b6a-a3f4-22a7b0ea6311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png',\n",
              "  'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'),\n",
              " 'bulldog')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 定义一个函数来加载单个 .pkl 文件\n",
        "def load_pkl(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 定义多个 .pkl 文件夹的路径\n",
        "file1='drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "file2='drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "file3='drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "file4='drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "file_paths = [file1, file2, file3, file4]\n",
        "\n",
        "# 合并\n",
        "merged_data = []\n",
        "for file_path in file_paths:\n",
        "    data = load_pkl(file_path)\n",
        "    merged_data.extend(data)\n",
        "\n",
        "\n",
        "merged_data[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG4ZrbJW7gNT"
      },
      "source": [
        "定义图像变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fnPAS-3b7ff1",
        "outputId": "3a41426e-6d81-4bfb-b9cb-59838d2ff4ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 62094/152064 [15:29<22:26, 66.80it/s]    \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c26271761609>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtransformed_image_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 定义图像变换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整大小为 224x224\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 对 merged_data 中所有图片路径应用变换\n",
        "transformed_data = []\n",
        "for image_pair, category in tqdm(merged_data):\n",
        "    transformed_image_pair = (transform(Image.open(image_pair[0])), transform(Image.open(image_pair[1])))\n",
        "    transformed_data.append((transformed_image_pair, category))\n",
        "\n",
        "# 输出变换后的数据\n",
        "print(transformed_data[1])\n",
        "\n",
        "\n",
        "dataloader = DataLoader(transformed_data, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsDg8lb7Lo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "# 定义自定义数据集类\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义 ResNet18 模型\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)  # 修改最后一层全连接层，输出为2类（假设是二分类任务）\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 准备数据集\n",
        "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', ...]  # 假设这里是你的图像数据集路径列表\n",
        "transform = transforms.Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "dataset = CustomDataset(image_paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch_images in enumerate(dataloader):\n",
        "        inputs = batch_images\n",
        "        labels = torch.randint(0, 2, (batch_images.size(0),))  # 假设这里是随机生成的标签\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # 每 10 个 mini-batch 输出一次损失值\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR2Se1J7LrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCvom3K7LtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dSlXY-7LvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar0YMs7R7LxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW2CdWBYwpu",
        "outputId": "c5e3a98e-6ec4-445d-b016-181739cbdc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image size is 224 pixels wide by 224 pixels high.\n"
          ]
        }
      ],
      "source": [
        "# 替换下面的路径为你图像的实际路径\n",
        "image_path = '/content/drive/My Drive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png'\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# 获取图像的大小\n",
        "width, height = img.size\n",
        "\n",
        "# 打印图像的大小\n",
        "print(f'The image size is {width} pixels wide by {height} pixels high.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiRyFGtY8iJ",
        "outputId": "5bc07ce5-0670-4e35-910a-e2d5bbc58c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'spawrious224_rgb': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56vrZ45Ywri"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 提取特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 定义图像预处理步骤\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整图像大小为 ResNet18 模型的输入大小\n",
        "    transforms.ToTensor(),  # 将图像转换为 Tensor 格式\n",
        "])\n",
        "\n",
        "# 加载 RGB 图像并进行预处理\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 添加 batch 维度，变成一个大小为 (1, C, H, W) 的 Tensor\n",
        "\n",
        "# 将图像输入到 ResNet18 模型中，并提取全局平均池化层的输出\n",
        "with torch.no_grad():\n",
        "    features = feature_extractor(input_batch)\n",
        "\n",
        "# 将特征转换为一个向量（reshape 为 (1, num_features)）\n",
        "global_avg_pooling_output = features.view(features.size(0), -1)\n",
        "\n",
        "# 输出向量的大小\n",
        "print(\"Global Average Pooling Output Shape:\", global_avg_pooling_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHUMXcfxBRH",
        "outputId": "5023f978-9943-4b52-db95-3917306e8d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape: torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH72AAHsxBTv",
        "outputId": "a309654e-c496-4611-d74e-d199df8e5239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape (with pooling): torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp4djmqsxBWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ7JRGRmxBYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sOryq0lgGL",
        "outputId": "aef2dd6a-3c69-42b0-e04c-713082b138eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
            "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
            "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
            "        ...,\n",
            "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
            "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
            "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]],\n",
            "       requires_grad=True)\n",
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# 加载预训练的 ResNet-18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 截取特征提取器部分（不包括最后的全连接层）\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "weights=model.fc.weight\n",
        "print(weights)\n",
        "print(len(weights))\n",
        "\n",
        "\n",
        "\n",
        "# 加载并预处理上传的两张图片数据\n",
        "image1_path = 'path/to/your/first/image.jpg'\n",
        "image2_path = 'path/to/your/second/image.jpg'\n",
        "image1 = preprocess_image(image1_path)\n",
        "image2 = preprocess_image(image2_path)\n",
        "\n",
        "# 提取图片的特征向量\n",
        "with torch.no_grad():\n",
        "    feature1 = feature_extractor(image1)\n",
        "    feature2 = feature_extractor(image2)\n",
        "\n",
        "# 对提取的特征向量进行全局平均池化操作\n",
        "global_avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "feature1_vector = global_avg_pool(feature1).squeeze()\n",
        "feature2_vector = global_avg_pool(feature2).squeeze()\n",
        "\n",
        "# 打印两个特征向量\n",
        "print(\"Feature vector for image 1:\", feature1_vector)\n",
        "print(\"Feature vector for image 2:\", feature2_vector)\n",
        "\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#定义损失函数\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "\n",
        "        # 自定义损失函数的计算过程，这里假设是平方误差损失\n",
        "        loss = torch.mean((output - target)**2)\n",
        "        return loss\n",
        "\n",
        "#定义损失函数\n",
        "def loss():\n",
        "  lam_loss_all=0\n",
        "  for i in range(batch_size):\n",
        "\toriginal=Feature map[i]\n",
        "\tpair=Feature map[10+i]\n",
        "        y_1=y[i]\n",
        "        w=Classification head weight[y_1]**2\n",
        "\tdistance=(original-pair)**2\n",
        "        lam_loss=0\n",
        "        For k 1to 2048:\n",
        "              lam_loss+=w[I]*distance[I]\n",
        "\tlam_loss_all+=lam_loss\n",
        "\n",
        "lam_loss_all/=10\n",
        "\n",
        "loss=erm_loss+lambda*lam_loss_all\n",
        "\n",
        "#开始训练\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # 解压当前 batch 中的图片对\n",
        "        images1, images2 = batch\n",
        "\n",
        "        # 前向传播\n",
        "        outputs1 = model(images1)\n",
        "        outputs2 = model(images2)\n",
        "\n",
        "        feature1 = feature_extractor(images1)\n",
        "        feature2 = feature_extractor(images2)\n",
        "\n",
        "        # 计算损失\n",
        "        loss = loss_fn(outputs1, outputs2)\n",
        "\n",
        "        # 反向传播与参数更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 打印当前损失\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# 定义优化器，并将所有参数添加到优化器中\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 训练过程中的损失计算示例\n",
        "# 假设 inputs 是模型的输入数据，targets 是真实标签\n",
        "#outputs = model(inputs)\n",
        "\n",
        "\n",
        "#loss = criterion(outputs, targets)\n",
        "\n",
        "# 反向传播与参数更新\n",
        "#optimizer.zero_grad()\n",
        "#loss.backward()\n",
        "#optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8AYk6QV59s0",
        "outputId": "1d1fd7af-edde-41d9-f342-9d9d3297ec39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "images = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png\")\n",
        "inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "image_features = model.get_image_features(**inputs)\n",
        "image_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRBhDp1-EQK",
        "outputId": "db7e1d1e-4b2b-46dc-db74-248de8d8e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8947], grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_6.png\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "other_features = model.get_image_features(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "similarity = torch.cosine_similarity(image_features, other_features, dim=1)\n",
        "print(similarity)\n",
        "\n",
        "#similar_images.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNpx89JdYAW"
      },
      "outputs": [],
      "source": [
        "# tensor --> numpy array\n",
        "# 10*768 --> 10*10\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "pairwise_cos=cosine_similarity(all_features_image0, all_features_image0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzY4-Bg9amE0",
        "outputId": "2c8648e7-753e-4e45-f242-874989629e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The path of the file is: /content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 要查找的文件名\n",
        "filename = 'train.py'\n",
        "\n",
        "# 使用 os.walk() 函数遍历文件系统，查找文件\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        print(\"The path of the file is:\", file_path)\n",
        "        break\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4ydb8Tf1ZL"
      },
      "outputs": [],
      "source": [
        "import domainbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHz6ikvEbKB4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# 将当前工作目录添加到模块搜索路径中\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXILhm1Z5Lu",
        "outputId": "bc18d9c5-2477-4aec-db5a-4a9f44a6515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    from domainbed import datasets\n",
            "ModuleNotFoundError: No module named 'domainbed'\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/DomainBed/domainbed/scripts')\n",
        "\n",
        "\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py  --data_dir=./domainbed/data/mnist_data/MNIST/MNIST/raw\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHZs22kIHITz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEui0DbG2T-"
      },
      "outputs": [],
      "source": [
        "import domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ccrCEUpIe3U",
        "outputId": "973b3d5a-7e54-40c2-c79f-c33db6b566b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import domainbed.scripts.train\n",
        "print(domainbed.scripts.train.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_8DJU6GQkP",
        "outputId": "647d4860-e9ce-4939-ed22-e6fbcbf2c271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6nF9hh2B20I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed/domainbed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpBUtnGDDP_T",
        "outputId": "e0bdf4c4-f6a2-4ee1-c05c-469b1ac9223c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "domainbed 模块已经上传到 Colab 环境中。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 列出当前目录下的文件和文件夹\n",
        "files_and_folders = os.listdir()\n",
        "\n",
        "# 检查是否有 domainbed 相关的文件或者文件夹存在\n",
        "if 'DomainBed' in files_and_folders:\n",
        "    print(\"domainbed 模块已经上传到 Colab 环境中。\")\n",
        "else:\n",
        "    print(\"domainbed 模块未上传到 Colab 环境中，请上传该模块。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "U73FCwSYCtHs",
        "outputId": "9eedd15b-ca7a-44e8-9c8a-62b6fc3c7c1e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'DomainBed.scripts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-671f19c45cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDomainBed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DomainBed.scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import DomainBed.scripts.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104WHdolBMr9",
        "outputId": "9532160a-2771-495f-edbe-236058077489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/DomainBed/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-wDOYOGcrBd",
        "outputId": "1c155a51-cb25-4d33-cef8-b9d66beba886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CODE_OF_CONDUCT.md  CONTRIBUTING.md  domainbed\tLICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tpA8g5crEd",
        "outputId": "4c37650f-6c66-41ca-a43b-a054019e7395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed\n"
          ]
        }
      ],
      "source": [
        "%cd domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpMP-JYcrG8",
        "outputId": "a5671b8c-1378-43db-800d-025f0fd06a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/DomainBed/domainbed/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9j-jXU4qnV",
        "outputId": "9a47a5e4-38bc-4ad0-9e0a-116112baebe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c2d66b9d68e869eab2d7fb0ceb797bc93c5a2eba8da460ac75e6fa1222eaeafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Pwi1MG4s0Q"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLqCJYk6Z-H"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(\"local\", \"Example App\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoTkcfW9crKX",
        "outputId": "51c83067-2d6c-4cfe-ab10-a058f03451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = sc.parallelize(range(1, 100))\n",
        "t = 50\n",
        "B = A.filter(lambda x: x < t)\n",
        "B.cache()\n",
        "t = 10\n",
        "\n",
        "C = B.filter(lambda x: x > t)\n",
        "\n",
        "print(C.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722a2LCPcrMx",
        "outputId": "dc6f003d-0d78-4ad2-94f9-3dddb67f9ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product: 233\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "def dot_product(rdd1, rdd2):\n",
        "  zipped_rdd = rdd1.zip(rdd2)\n",
        "  dot_product = zipped_rdd.map(lambda x: x[0]*x[1]).reduce(lambda x,y:x+y)\n",
        "  return dot_product\n",
        "\n",
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "result = dot_product(r1, r2)\n",
        "print(\"Dot product:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pdehnc-7kN6",
        "outputId": "0bfc6140-a0ec-4ffd-895c-cef3f0637ee2"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e471822f655>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the total dot product by summing up the partial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtotal_dot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot product:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_dot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "# Induce a different partitioning\n",
        "r2 = r2.flatMap(lambda x: [] if x == 1 else [x])\\\n",
        "       .flatMap(lambda x: [9, 9] if x == 9 else [x])\n",
        "\n",
        "def compute_dot_product(partition):\n",
        "    partial_sum = 0\n",
        "    for x, y in partition:\n",
        "        partial_sum += x * y\n",
        "    yield partial_sum\n",
        "\n",
        "dot_product_rdd = r1.zip(r2).mapPartitions(compute_dot_product)\n",
        "\n",
        "# Compute the total dot product by summing up the partial results\n",
        "total_dot_product = dot_product_rdd.reduce(lambda x, y: x + y)\n",
        "\n",
        "print(\"Dot product:\", total_dot_product)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}