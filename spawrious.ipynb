{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzVjng0cq4V",
        "outputId": "e5812ec0-7d14-48e3-b513-587b105c2f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1263, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 1263 (delta 3), reused 4 (delta 0), pack-reused 1252\u001b[K\n",
            "Receiving objects: 100% (1263/1263), 1.06 MiB | 27.01 MiB/s, done.\n",
            "Resolving deltas: 100% (734/734), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HApsEKnU5rM2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxCp4JTdivj",
        "outputId": "81b298d2-327e-44c4-c8b9-dc979b7586d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjylGMPbTZEl",
        "outputId": "82949566-dd05-4f39-da45-e44bc43955d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa_F2E_wzly"
      },
      "source": [
        "Convert images to /content/...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_g-N8vfERdY",
        "outputId": "90030c5d-5bee-45e2-ada2-c1e474762e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=2afd9cd3df0614d4d858a7324b267b23be54136beb2445b0519f9f8481308773\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wilds\n",
        "# 安装wilds模块\n",
        "# 使用wilds可以帮助研究人员更好地评估他们的机器学习算法在实际应用中的性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r_kfReEsJhNO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NQUkwkKPp6Us"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from download import download_spawrious"
      ],
      "metadata": {
        "id": "QcFueQOivecG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o-gdbwEqDy2A"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/ip1\"\n",
        "# 制定下载数据集所需要的目录\n",
        "\n",
        "download_spawrious(data_dir)\n",
        "# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\n",
        "# 调用其他函数下载其他数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MG-PvtDxJOTD"
      },
      "outputs": [],
      "source": [
        "# 创建 SpawriousO2O_easy 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "\n",
        "spawrious_easy = SpawriousO2O_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousO2O_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousO2O_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5Us1_27TKM0G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9efqXNB2K5Pe",
        "outputId": "85b2ba53-f02c-4cf9-be7d-43a0ef69d737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IZdwtDLlbsq"
      },
      "outputs": [],
      "source": [
        "env1 = spawrious_easy[1]\n",
        "env2 = spawrious_easy[2]\n",
        "test = spawrious_easy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avZK4NVnUZxW"
      },
      "outputs": [],
      "source": [
        "env1_medium = spawrious_medium[1]\n",
        "env2_medium = spawrious_medium[2]\n",
        "test_medium = spawrious_medium[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAxRKr-oNWHg",
        "outputId": "dd561c40-cde2-43a4-b055-77d6c855dc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12672\n",
            "12672\n",
            "25344\n"
          ]
        }
      ],
      "source": [
        "env1_hard = spawrious_hard[1]\n",
        "env2_hard = spawrious_hard[2]\n",
        "test_hard = spawrious_hard[0]\n",
        "\n",
        "print(len(env1_hard))\n",
        "print(len(env2_hard))\n",
        "print(len(test_hard))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs19CK7hOHN"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/ip/testdata_medium.pt'\n",
        "torch.save(test_medium, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZFQQiRyNN71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVYsqDeDtlGw"
      },
      "outputs": [],
      "source": [
        "torch.save(test, '/content/drive/MyDrive/ip/testdata.pt')\n",
        "torch.save(test_medium, '/content/drive/MyDrive/ip/testdata_medium.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWtjDTrG4ho"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:\n"
      ],
      "metadata": {
        "id": "JKGmsTaZZV_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "FTvxrF-j-BTL",
        "outputId": "b735972b-f06c-4850-9fa3-a219e8222eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_tensor = env1_hard[3072][0]\n",
        "label = env1_hard[3072][1]\n",
        "\n",
        "image_array = image_tensor.numpy()\n",
        "image_array_rgb = np.transpose(image_array, (1, 2, 0))\n",
        "plt.imshow(image_array_rgb)\n",
        "plt.axis('off')  # 关闭坐标轴\n",
        "plt.show()\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGkMyccsmA3i"
      },
      "outputs": [],
      "source": [
        "bulldog_filter1 = []\n",
        "bulldog_filter2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_filter_medium1 = []\n",
        "bulldog_filter_medium2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_medium2.append(env2_medium[i][0])\n"
      ],
      "metadata": {
        "id": "EIMPsQZtZcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJo9hZ3jOOW5"
      },
      "outputs": [],
      "source": [
        "bulldog_filter_hard1 = []\n",
        "bulldog_filter_hard2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkefLJvgPCDC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "bulldog_filter_hard1_np = np.array(bulldog_filter_hard1)\n",
        "bulldog_filter_hard2_np = np.array(bulldog_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_hard1.npy', bulldog_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_hard2.npy', bulldog_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6X3shuzsRIJ",
        "outputId": "098caad2-2f6e-499d-f699-30f27e262393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(bulldog_filter1))\n",
        "print(len(bulldog_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VpDUX6-toEF"
      },
      "outputs": [],
      "source": [
        "bulldog1 = []\n",
        "bulldog2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog1.append(env1[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_medium1 = []\n",
        "bulldog_medium2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "f9TleOcUiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OUywRWdO3_U"
      },
      "outputs": [],
      "source": [
        "bulldog_hard1 = []\n",
        "bulldog_hard2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog1_np = np.array(bulldog1)\n",
        "bulldog2_np = np.array(bulldog2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog1.npy', bulldog1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog2.npy', bulldog2_np)\n"
      ],
      "metadata": {
        "id": "s7dmYtZ__Gw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "bulldog_hard1_np = np.array(bulldog_hard1)\n",
        "bulldog_hard2_np = np.array(bulldog_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_hard1.npy', bulldog_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_hard2.npy', bulldog_hard2_np)"
      ],
      "metadata": {
        "id": "zsxCOp-X_cUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37zsNDs_zV8E"
      },
      "outputs": [],
      "source": [
        "dachshund_filter1 = []\n",
        "dachshund_filter2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_filter_medium1 = []\n",
        "dachshund_filter_medium2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "sWIoCKWbiw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgctYFvYQPNW"
      },
      "outputs": [],
      "source": [
        "dachshund_filter_hard1 = []\n",
        "dachshund_filter_hard2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnYhdMOyQ2NP"
      },
      "outputs": [],
      "source": [
        "\n",
        "dachshund_filter_hard1_np = np.array(dachshund_filter_hard1)\n",
        "dachshund_filter_hard2_np = np.array(dachshund_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_hard1.npy', dachshund_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_hard2.npy', dachshund_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws4bfU992EmT",
        "outputId": "b75ffdd1-078e-40fb-a4a3-5ec61c16cbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(dachshund_filter1))\n",
        "print(len(dachshund_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-neQ3YR2Ewg"
      },
      "outputs": [],
      "source": [
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3072, 3072+3072):\n",
        "  dachshund1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756, 2756+2756):\n",
        "  dachshund2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5lNhT5LRJSp",
        "outputId": "c48bce8a-fad8-4bc1-95fb-11c506cbca70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3072/3072 [00:35<00:00, 86.73it/s]\n",
            "100%|██████████| 2756/2756 [00:31<00:00, 86.50it/s]\n"
          ]
        }
      ],
      "source": [
        "dachshund_hard1 = []\n",
        "dachshund_hard2 = []\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "for i in tqdm(range(3072, 3072+3072)):\n",
        "  dachshund_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756, 2756+2756)):\n",
        "  dachshund_hard2.append(env2_hard[i][0])\n",
        "\n",
        "dachshund_hard1_np = np.array(dachshund_hard1)\n",
        "dachshund_hard2_np = np.array(dachshund_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_hard1.npy', dachshund_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_hard2.npy', dachshund_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdAXRNhPiawJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "dachshund_hard1_np = np.array(dachshund_hard1)\n",
        "dachshund_hard2_np = np.array(dachshund_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_hard1.npy', dachshund_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_hard2.npy', dachshund_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_NDN7bK2e9X",
        "outputId": "630894c8-faad-465a-bf28-3495307f8f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(dachshund1))\n",
        "print(len(dachshund2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaW3o4hj2e_5"
      },
      "outputs": [],
      "source": [
        "dachshund_filter1_np = np.array(dachshund_filter1)\n",
        "dachshund_filter2_np = np.array(dachshund_filter2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter1.npy', dachshund_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter2.npy', dachshund_filter2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmGrmbhU2fB5"
      },
      "outputs": [],
      "source": [
        "dachshund1_np = np.array(dachshund1)\n",
        "dachshund2_np = np.array(dachshund2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund1.npy', dachshund1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund2.npy', dachshund2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftTNGcd2m0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNUdbmZ2m45"
      },
      "outputs": [],
      "source": [
        "labrador_filter1 = []\n",
        "labrador_filter2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "errs4ycoihsi"
      },
      "outputs": [],
      "source": [
        "labrador_filter_hard1 = []\n",
        "labrador_filter_hard2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter_hard2.append(env2_hard[i][0])\n",
        "\n",
        "labrador_filter_hard1_np = np.array(labrador_filter_hard1)\n",
        "labrador_filter_hard2_np = np.array(labrador_filter_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_hard1.npy', labrador_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_hard2.npy', labrador_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsjBViSE2m6-",
        "outputId": "bb91fe47-e1d1-42b9-db22-5c3c08c00031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador_filter1))\n",
        "print(len(labrador_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwSyffW2m9D"
      },
      "outputs": [],
      "source": [
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3072*2, 3072*3):\n",
        "  labrador1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756*2, 2756*3):\n",
        "  labrador2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdFYxleUj3ce",
        "outputId": "1d30c2b4-c7e9-4731-f37e-55ac397235bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3072/3072 [00:35<00:00, 86.22it/s]\n",
            "100%|██████████| 2756/2756 [00:31<00:00, 86.62it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_hard1 = []\n",
        "labrador_hard2 = []\n",
        "for i in tqdm(range(3072*2, 3072*3)):\n",
        "  labrador_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756*2, 2756*3)):\n",
        "  labrador_hard2.append(env2_hard[i][0])\n",
        "\n",
        "labrador_hard1_np = np.array(labrador_hard1)\n",
        "labrador_hard2_np = np.array(labrador_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_hard1.npy', labrador_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_hard2.npy', labrador_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbOg21uK0C1L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "labrador_hard1_np = np.array(labrador_hard1)\n",
        "labrador_hard2_np = np.array(labrador_hard2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_hard1.npy', labrador_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_hard2.npy', labrador_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H77kpkdb2m-9",
        "outputId": "9e5c7121-82f3-41a1-ba52-7dbfb7b57dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador1))\n",
        "print(len(labrador2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsH4R2d0DbW4"
      },
      "outputs": [],
      "source": [
        "labrador_filter1_np = np.array(labrador_filter1)\n",
        "labrador_filter2_np = np.array(labrador_filter2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter1.npy', labrador_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter2.npy', labrador_filter2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej9GfiA6DbdD"
      },
      "outputs": [],
      "source": [
        "labrador1_np = np.array(labrador1)\n",
        "labrador2_np = np.array(labrador2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador1.npy', labrador1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador2.npy', labrador2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQtiHE4WDbfZ"
      },
      "outputs": [],
      "source": [
        "corgi_filter1 = []\n",
        "corgi_filter2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter1.append(env1[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter2.append(env2[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-mdt_fa0PXD"
      },
      "outputs": [],
      "source": [
        "corgi_filter_hard1 = []\n",
        "corgi_filter_hard2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3FRKNaS0ws6"
      },
      "outputs": [],
      "source": [
        "corgi_filter_hard1_np = np.array(corgi_filter_hard1)\n",
        "corgi_filter_hard2_np = np.array(corgi_filter_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_hard1.npy', corgi_filter_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_hard2.npy', corgi_filter_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO4h8kzKDbhh",
        "outputId": "a4d17910-79ee-410a-a11a-a126cbdda56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "print(len(labrador_filter1))\n",
        "print(len(labrador_filter2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7IptW5pIsFD"
      },
      "outputs": [],
      "source": [
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3072*3, 3072*4):\n",
        "  corgi1.append(env1[i][0])\n",
        "\n",
        "for i in range(2756*3, 2756*4):\n",
        "  corgi2.append(env2[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDJY8xv73gIe",
        "outputId": "f35ee848-5487-43a7-f29f-873b93574454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3072/3072 [00:36<00:00, 85.00it/s]\n",
            "100%|██████████| 2756/2756 [00:32<00:00, 84.55it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "corgi_hard1 = []\n",
        "corgi_hard2 = []\n",
        "for i in tqdm(range(3072*3, 3072*4)):\n",
        "  corgi_hard1.append(env1_hard[i][0])\n",
        "\n",
        "for i in tqdm(range(2756*3, 2756*4)):\n",
        "  corgi_hard2.append(env2_hard[i][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOYWgQ7GsbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ugpaEp_Lcc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi_hard1_np = np.array(corgi_hard1)\n",
        "corgi_hard2_np = np.array(corgi_hard2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_hard1.npy', corgi_hard1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_hard2.npy', corgi_hard2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWjce4R9I5y7",
        "outputId": "fbfb7598-5bfd-4dad-acb1-3296fafd4036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3072\n",
            "2756\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi1))\n",
        "print(len(corgi2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qep-GkqRI51d"
      },
      "outputs": [],
      "source": [
        "corgi_filter1_np = np.array(corgi_filter1)\n",
        "corgi_filter2_np = np.array(corgi_filter2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter1.npy', corgi_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter2.npy', corgi_filter2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IePUzIhvI53q"
      },
      "outputs": [],
      "source": [
        "corgi1_np = np.array(corgi1)\n",
        "corgi2_np = np.array(corgi2)\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/corgi1.npy', corgi1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi2.npy', corgi2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSt-PjHa0vxU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49q4nMcrOk7q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQyAlC-VAall",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "9c411aab-f581-4f71-8865-80e4db1c502c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/corgi1.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-aa7d1ffa76a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorgi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorgi2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorgi_filter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_filter1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorgi_filter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_filter2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/corgi1.npy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi2.npy')\n",
        "corgi_filter1 = np.load('/content/drive/MyDrive/ip1/corgi_filter1.npy')\n",
        "corgi_filter2 = np.load('/content/drive/MyDrive/ip1/corgi_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "_S__AIVuAhL3",
        "outputId": "2b222afe-a6ce-42d8-fac1-844aa08c25bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/corgi_hard1.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9657e63546cf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorgi_hard1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_hard1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorgi_hard2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_hard2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorgi_filter_hard1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_filter_hard1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorgi_filter_hard2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/corgi_filter_hard2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/corgi_hard1.npy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "corgi_hard1 = np.load('/content/drive/MyDrive/ip1/corgi_hard1.npy')\n",
        "corgi_hard2 = np.load('/content/drive/MyDrive/ip1/corgi_hard2.npy')\n",
        "corgi_filter_hard1 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard1.npy')\n",
        "corgi_filter_hard2 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard2.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZwOYqQjbC7l"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip1/labrador_filter1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip1/labrador_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504i9eqpyujC"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip1/dachshund_filter1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip1/dachshund_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaok8gKyvUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "8e9cffc6-d966-4420-8db4-66243db8856c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/bulldog1.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-8d45764dbfee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbulldog1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/bulldog1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbulldog2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/bulldog2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbulldog_filter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/bulldog_filter1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbulldog_filter2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/bulldog_filter2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/bulldog1.npy'"
          ]
        }
      ],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip1/bulldog_filter1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip1/bulldog_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um-nuTB-_Rp1",
        "outputId": "95e434fb-a281-4bc4-8891-60581394cfe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from transformers import CLIPModel\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:"
      ],
      "metadata": {
        "id": "nrEh7ntajEry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX1xyS2g-QEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "a326f8e44d3948738ef67f40424427de",
            "9b6fd8c8272d4f9185d841e4cf821782",
            "8d7a57be40b7419888bd08b9e9036a5b",
            "226c307812624cca937995e1fbf6031a",
            "0d11dfe2e7fd4c77990bdc28fcb1f803",
            "d01164c326fa4bf6a7298b20855b56bd",
            "2d6a04b97f63471994347bdec2a9da5c",
            "688d08d3ccf94b31a6e03ce40ade5c2f",
            "7f10fc168417498d9d98031e2912e3af",
            "af0e062d40c44e73af0002d43c4c7562",
            "3113ff8b5b6d4e299d1ae31e10a11265",
            "d1fe129c93ad4a38bf8f64a3615ab80f",
            "88e7c7313c7c46049b88107d20d67df2",
            "55ec36cb9db145a4b35e4fe16c3deec1",
            "06bcb9b149d842949a9c6695e8c276e9",
            "7fc97a393d124e8c9b711354b0c4f82f",
            "87eb0863992c4831aa99bd54c2f0f120",
            "fcf4db48c18b421397fa69b2e71c5757",
            "6ff3ffe7d6464a12b6a27406a404af34",
            "a3699f51a6bf4b12b15eb7b92bbca226",
            "3dd513184a22439c95d906a1bfed78d5",
            "c7d46964f8a648cf916d5473ac6ac792"
          ]
        },
        "outputId": "7494b1dd-544c-4760-a308-6e8af77e6be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a326f8e44d3948738ef67f40424427de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1fe129c93ad4a38bf8f64a3615ab80f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def similar_pair(i, class_filter, class_tensor):\n",
        "  similarity = 0\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > similarity:\n",
        "        similarity = res\n",
        "        index = j\n",
        "\n",
        "    pair1 = class_filter[i]\n",
        "    pair2 = class_tensor[index]\n",
        "    image_pair = (pair1, pair2)\n",
        "\n",
        "    return image_pair\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "8pBlF055BBqm",
        "outputId": "d77e6ce2-da2d-4394-85b3-26f870d54d21"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-c7d2e4f58b1d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfeatures1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfeatures2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXMRhWn6wi1N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def similar_pair(class_filter, class_tensor):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "\n",
        "        inputs1 = torch.tensor(class_filter).to(device)\n",
        "        features1 = model.get_image_features(inputs1)\n",
        "\n",
        "        inputs2 = torch.tensor(class_tensor).to(device)\n",
        "        features2 = model.get_image_features(inputs2)\n",
        "\n",
        "        similarities = F.cosine_similarity(features1.unsqueeze(1), features2.unsqueeze(0), dim=2)\n",
        "\n",
        "        # 获取每个输入图像最相似的图像的索引\n",
        "        max_indices = torch.argmax(similarities, dim=1)\n",
        "\n",
        "        # 获取最相似的图像对\n",
        "        pairs1 = class_filter\n",
        "        pairs2 = class_tensor[max_indices]\n",
        "\n",
        "        # 构建元组，前面是两对tensor，后面是label\n",
        "        image_pairs = list(zip(pairs1, pairs2))\n",
        "        image_pair_labels = [(pair, class_name) for pair in image_pairs]\n",
        "\n",
        "        return image_pair_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lnjYcrI13fFj",
        "outputId": "e7191633-9649-4c2f-d863-232aae672b2b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 58.00 MiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-949dc1e56e1f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorgi_filter1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorgi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mget_image_features\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         vision_outputs = self.vision_model(\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_layrnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 )\n\u001b[1;32m    637\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m                 layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    639\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.702\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 58.00 MiB. GPU "
          ]
        }
      ],
      "source": [
        "inputs1 = torch.tensor(corgi_filter1).to(device)\n",
        "features1 = model.get_image_features(inputs1)\n",
        "\n",
        "inputs2 = torch.tensor(corgi1).to(device)\n",
        "features2 = model.get_image_features(inputs2)\n",
        "\n",
        "similarities = F.cosine_similarity(features1.unsqueeze(1), features2.unsqueeze(0), dim=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "W4KmCdocQh8h",
        "outputId": "e13fefbb-984b-49b1-f046-a8624f28b62f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [42:01<00:00, 26.27s/it]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (96, 2) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4f8ac56d134>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcorgi_pairs1_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorgi_pairs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 保存为 .npy 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (96, 2) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs1 = []\n",
        "for i in tqdm(range(len(corgi_filter1))):\n",
        "    pair = similar_pair(i, corgi_filter1, corgi1, 'corgi')\n",
        "    corgi_pairs1.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PRdG5HFlcK"
      },
      "outputs": [],
      "source": [
        "corgi_pairs1_np = np.array(corgi_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/corgi_pairs1.npy', corgi_pairs1_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoN6G33F179",
        "outputId": "757f442b-39b0-4fe1-bd47-942accdf33ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:51:09<00:00, 24.93s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(corgi_filter2))):\n",
        "    pair = similar_pair(i, corgi_filter2, corgi2)\n",
        "    corgi_pairs2.append(pair)\n",
        "\n",
        "\n",
        "corgi_pairs2_np = np.array(corgi_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/corgi_pairs2.npy', corgi_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3npWg1PeZTnN"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip/labrador_filter1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip/labrador_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkONXq1cJ6w",
        "outputId": "c30efc7a-f0eb-4ff0-9bb7-3648769d00db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [43:56<00:00, 27.47s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter1, labrador1)\n",
        "    labrador_pairs1.append(pair)\n",
        "\n",
        "labrador_pairs1_np = np.array(labrador_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/labrador_pairs1.npy', labrador_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygDEfA1mB4H",
        "outputId": "3c0ed118-1ac7-4b7d-9663-548d5e1ec22a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:47:25<00:00, 24.38s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter2, labrador2)\n",
        "    labrador_pairs2.append(pair)\n",
        "\n",
        "labrador_pairs2_np = np.array(labrador_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/labrador_pairs2.npy', labrador_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U_wWxOlbmzd"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip/bulldog_filter1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip/bulldog_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zPieI6Qh-j",
        "outputId": "44360656-afd9-4e0c-a455-dacefadc410c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [43:35<00:00, 27.25s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter1, bulldog1)\n",
        "    bulldog_pairs1.append(pair)\n",
        "\n",
        "bulldog_pairs1_np = np.array(bulldog_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_pairs1.npy', bulldog_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUl4yFAKFDQ",
        "outputId": "330073fa-688f-40b8-e4e3-59627b5a22cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:48:55<00:00, 24.60s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter2, bulldog2)\n",
        "    bulldog_pairs2.append(pair)\n",
        "\n",
        "bulldog_pairs2_np = np.array(bulldog_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/bulldog_pairs2.npy', bulldog_pairs2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGn-ES32mk_J"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip/dachshund_filter1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip/dachshund_filter2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKWFg-QXE7m",
        "outputId": "b3900f48-d665-422b-a36d-0e1b91bff093"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:41<00:00, 26.06s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter1, dachshund1)\n",
        "    dachshund_pairs1.append(pair)\n",
        "\n",
        "dachshund_pairs1_np = np.array(dachshund_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_pairs1.npy', dachshund_pairs1_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmg9gwwAbAd",
        "outputId": "9da373a9-76bc-4573-a175-222273f4443d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:34:34<00:00, 22.51s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter2, dachshund2)\n",
        "    dachshund_pairs2.append(pair)\n",
        "\n",
        "dachshund_pairs2_np = np.array(dachshund_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip/dachshund_pairs2.npy', dachshund_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0U6fMo5WkK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKAgASqCmOKe"
      },
      "outputs": [],
      "source": [
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFrOE3RrLiG",
        "outputId": "59381f3b-7ae9-4890-825d-340f6270ac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PMu7dA7nNUM"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NrGu-LoTCz",
        "outputId": "2941f1f6-9d5a-4ae6-b1b8-7e86a7e6bfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2032"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0PdbNapNHB",
        "outputId": "54030c5e-e6fa-4299-e4f1-09c1a40ecede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "张量的形状： torch.Size([2032, 2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKslUAPyprb4",
        "outputId": "c6a75294-c4b4-4b19-f372-2a3842a347c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_easy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BAHgrw9bePe"
      },
      "source": [
        "convert all images into RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt50-fATZa32",
        "outputId": "ce1f6d76-1c38-4738-a51d-9cff9eff7433"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:07<00:00, 400.32it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.64it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.75it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.36it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.11it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.11it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.44it/s] \n",
            "100%|██████████| 3168/3168 [00:42<00:00, 73.81it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.81it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.29it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.98it/s] \n",
            "100%|██████████| 3168/3168 [00:41<00:00, 76.55it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.96it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.95it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.51it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.09it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:45<00:00, 69.65it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.34it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.47it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.75it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.43it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.11it/s] \n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:40<00:00, 78.95it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.40it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.98it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.39it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.18it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.05it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.91it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.46it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 80.48it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.66it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.47it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.05it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.02it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.07it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.99it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.61it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.41it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.99it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.86it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.81it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.70it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 83.88it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "所有图片转换完成！\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ip/spawrious224'\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        file_path = os.path.join(root, file)\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "            image.save(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRV3cb6FnoSX",
        "outputId": "c81a4785-7144-48f0-9653-fe0e26a6a245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bulldog', 'corgi', 'dachshund', 'labrador']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spawrious_easy.class_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swUTlzMZbAvm"
      },
      "source": [
        "find corgi images in env1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBlgf9kbPo1"
      },
      "source": [
        "find all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "MLAL0885BH2w",
        "outputId": "b23aef31-8b4b-429d-aad9-ff796f29b36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1826/12672 [02:35<15:20, 11.78it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e8a513c52f61>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspawrious_easy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bulldog\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbulldog_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corgi_images = []\n",
        "bulldog_images = []\n",
        "dachshund_images = []\n",
        "labrador_images = []\n",
        "\n",
        "\n",
        "for image, label in tqdm(env1):\n",
        "  if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images.append(image)\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images.append(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbcjhnlAXcZ",
        "outputId": "1f6b6fa3-702d-455e-815e-e80510a09565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3168\n",
            "3168\n",
            "3168\n",
            "3168\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi_images))\n",
        "print(len(bulldog_images))\n",
        "print(len(dachshund_images))\n",
        "print(len(labrador_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrz3aOyDbV9M"
      },
      "source": [
        "find all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFOg-czCymV",
        "outputId": "5b34ec3d-e0b2-4def-ea7e-51e8af9cf95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12672/12672 [1:20:01<00:00,  2.64it/s]\n"
          ]
        }
      ],
      "source": [
        "corgi_images2 = []\n",
        "bulldog_images2 = []\n",
        "dachshund_images2 = []\n",
        "labrador_images2 = []\n",
        "\n",
        "for image, label in tqdm(env2):\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images2.append(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKi8m9ibmRg"
      },
      "source": [
        "save all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGtK1RWUk7p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "def save_images(image_list, folder_path, label):\n",
        "    # 检查目标文件夹是否存在，不存在则创建\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 遍历图像列表，保存每张图像\n",
        "    for idx, tensor in enumerate(image_list):\n",
        "        image = TF.to_pil_image(tensor)                               # 将 tensor 转换为 PIL 图像\n",
        "        image_path = os.path.join(folder_path, f\"{label}_{idx}.png\")  # 定义图像的保存路径\n",
        "        image.save(image_path)                                        # 保存图像\n",
        "\n",
        "# Google Drive 挂载路径\n",
        "drive_path = \"/content/drive/MyDrive/ip/SpawriousImages\"\n",
        "\n",
        "# 分别保存每种类别的图像\n",
        "save_images(bulldog_images, os.path.join(drive_path, 'bulldog'), 'bulldog')\n",
        "save_images(dachshund_images, os.path.join(drive_path, 'dachshund'), 'dachshund')\n",
        "save_images(labrador_images, os.path.join(drive_path, 'labrador'), 'labrador')\n",
        "save_images(corgi_images, os.path.join(drive_path, 'corgi'), 'corgi')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ELr3P6bt2K"
      },
      "source": [
        "save all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFFo56kXnMc"
      },
      "outputs": [],
      "source": [
        "save_images(bulldog_images2, os.path.join(drive_path, 'bulldog2'), 'bulldog')\n",
        "save_images(dachshund_images2, os.path.join(drive_path, 'dachshund2'), 'dachshund')\n",
        "save_images(labrador_images2, os.path.join(drive_path, 'labrador2'), 'labrador')\n",
        "save_images(corgi_images2, os.path.join(drive_path, 'corgi2'), 'corgi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClB9-zM4fGNx",
        "outputId": "a7af8175-f2df-4362-d221-0e0215af6bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Dictionary: {'bulldog': 0, 'corgi': 1, 'dachshund': 2, 'labrador': 3}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_list = [\"bulldog\", \"corgi\", \"dachshund\", \"labrador\"]\n",
        "\n",
        "# 将列表转换为字典，键是标签，值是索引\n",
        "class_dict = {class_name: index for index, class_name in enumerate(class_list)}\n",
        "\n",
        "# 打印转换后的字典\n",
        "print(\"Class Dictionary:\", class_dict)\n",
        "class_dict['bulldog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GwhB5ObypD"
      },
      "source": [
        "create random pairs of bulldog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-q9MMaxtcQ",
        "outputId": "e613c57a-2c52-4e32-c420-daa56f69c1b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 697747.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/bulldog/bulldog_2213.png',\n",
              "  '/content/SpawriousImages/bulldog2/bulldog_2962.png'),\n",
              " 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder1_path = \"/content/SpawriousImages/bulldog\"\n",
        "folder2_path = \"/content/SpawriousImages/bulldog2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # Randomly pair\n",
        "    bulldog_image_pairs.append((image_pair, class_dict['bulldog']))\n",
        "\n",
        "bulldog_image_pairs[200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lJvdadb88y"
      },
      "source": [
        "create random pairs of corgi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8hN7jvyClr",
        "outputId": "95523183-db68-4d8e-dee9-6b4275c1ec7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 817519.62it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_208.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_3064.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/corgi\"\n",
        "folder2_path = \"/content/SpawriousImages/corgi2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "corgi_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, class_dict['corgi']))\n",
        "\n",
        "corgi_image_pairs[1093]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwyYjK7cDoq"
      },
      "source": [
        "create random pairs of dachshund"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4alSoc414EiM",
        "outputId": "de3c8564-b5d9-4dbd-87eb-f64d0cd25426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 800262.29it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/dachshund/dachshund_2053.png',\n",
              "  '/content/SpawriousImages/dachshund2/dachshund_1682.png'),\n",
              " 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/dachshund\"\n",
        "folder2_path = \"/content/SpawriousImages/dachshund2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "# 将文件名转换为完整的文件路径\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, class_dict['dachshund']))\n",
        "\n",
        "dachshund_image_pairs[100]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VW1QOicJPa"
      },
      "source": [
        "Create random pairs of labrador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcVbDd94K2U",
        "outputId": "ba1ae18c-d68b-4151-8c77-74a069314f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 733835.26it/s]\n"
          ]
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/labrador\"\n",
        "folder2_path = \"/content/SpawriousImages/labrador2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, class_dict['labrador']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fejvc8A3cM7p"
      },
      "source": [
        "merge all four classes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBx_U4Dw4Tpe",
        "outputId": "4f6c1004-2f97-4611-ded4-a06ede1873d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_2342.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_2470.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = labrador_image_pairs + dachshund_image_pairs + corgi_image_pairs + bulldog_image_pairs\n",
        "\n",
        "# 打乱合并后的列表\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "training_data[981]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1hM69h4ZxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 明确指定数组的数据类型为 object\n",
        "training_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# 指定保存文件的路径和文件名\n",
        "save_path = \"/content/training_data.npy\"\n",
        "\n",
        "# 将 NumPy 数组保存为 .npy 文件\n",
        "np.save(save_path, training_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCZHUx14Z3I",
        "outputId": "18ca66d3-0b33-41fa-de18-91c66657593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (25344, 2)\n",
            "Size: 50688\n",
            "[('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            " 3]\n",
            "('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            "/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加载 .npy 文件\n",
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# 查看数组的形状和大小\n",
        "print(\"Shape:\", array.shape)\n",
        "print(\"Size:\", array.size)\n",
        "\n",
        "\n",
        "print(array[1])\n",
        "print(array[1][0])\n",
        "print(array[1][0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check an example\n"
      ],
      "metadata": {
        "id": "70s-6zucXos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Axn7L7Sqruo",
        "outputId": "578daa98-81ed-4e89-deb7-97b93674d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png'),\n",
              "       3], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "array[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "942VqoXnP0OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image_paths = sample[0]\n",
        "        label = sample[1]\n",
        "        images = [Image.open(path) for path in image_paths]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ip/training_data.npy\"\n",
        "custom_dataset = CustomDataset(data_path, transform=transform)\n",
        "trainloader = DataLoader(custom_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezAlnNFwESe",
        "outputId": "6a163d37-acd1-48ae-ed06-a71bf0a914cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EI82mktkohs"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJN4vrei4Ag",
        "outputId": "a8a5a118-71f5-4f8a-e94e-12f6841a9b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "([tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]]), tensor([[[ 0.2967,  0.1426, -0.0116,  ..., -1.7240, -1.9467,  2.1462],\n",
            "         [ 0.4337,  0.5193,  0.0741,  ...,  2.1462,  1.9235,  1.9920],\n",
            "         [ 0.4337,  0.5193,  0.1426,  ...,  2.0777,  1.9920,  1.8550],\n",
            "         ...,\n",
            "         [ 2.1975,  1.8208,  1.6667,  ..., -1.6727, -1.5870, -1.5870],\n",
            "         [ 1.8893,  1.4440,  1.3755,  ...,  1.8893,  2.0434, -2.1179],\n",
            "         [ 1.5982,  1.4440,  1.3755,  ...,  1.8208,  1.8208,  1.9749]],\n",
            "\n",
            "        [[ 2.3060,  2.2360,  1.9909,  ...,  0.2052, -0.2675, -0.4951],\n",
            "         [-1.9307, -2.0182,  1.9909,  ..., -0.4251, -0.7402, -0.6527],\n",
            "         [-1.9307, -2.0182,  2.1485,  ..., -0.5826, -0.6527, -0.9678],\n",
            "         ...,\n",
            "         [-1.3179, -1.8606,  2.3761,  ..., -0.8452, -0.7752, -0.6176],\n",
            "         [-1.9482,  2.1485,  1.9209,  ..., -1.8606, -1.7031, -1.3880],\n",
            "         [ 2.3060,  2.0609,  1.9209,  ..., -2.0182, -2.0182, -1.8606]],\n",
            "\n",
            "        [[-0.8981, -1.0550, -1.2119,  ...,  1.5594,  1.0888,  0.8622],\n",
            "         [-0.6541, -0.7413, -1.2119,  ...,  1.0191,  0.6182,  0.7054],\n",
            "         [-0.6541, -0.7413, -1.0550,  ...,  0.7751,  0.7751,  0.4614],\n",
            "         ...,\n",
            "         [ 0.0605, -0.4798, -0.7064,  ...,  0.6182,  0.7576,  0.7576],\n",
            "         [-0.4798, -0.9330, -1.2467,  ..., -0.3927, -0.0790, -0.0092],\n",
            "         [-0.7064, -1.0201, -1.2467,  ..., -0.6367, -0.4798, -0.4798]]])], 1)\n"
          ]
        }
      ],
      "source": [
        "# 数据集的长度，一共有25344对图像\n",
        "print(len(custom_dataset))\n",
        "\n",
        "\n",
        "print(custom_dataset[3])\n",
        "\n",
        "# pairs\n",
        "#print(custom_dataset[3][0])\n",
        "\n",
        "# label\n",
        "#print(custom_dataset[3][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPLwSINk_IW"
      },
      "outputs": [],
      "source": [
        "batch_size= 10\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwbKV4Ay7Rq",
        "outputId": "98059a33-0549-48c3-a035-348232838ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]])\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(trainloader))\n",
        "first_data = first_batch[0][0]  # 获取第一个数据样本\n",
        "print(first_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ83k-aWJrgv"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhU_0iIXJqpZ",
        "outputId": "4e97126e-6c72-43b0-cc6f-3462131d3cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "2535\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n",
        "print(len(trainloader))\n",
        "print(type(trainloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIKQNL6rpCw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Erge4frq72"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZFFBiirq-R",
        "outputId": "3dc54f4b-67a6-4e40-e482-55c7405ba0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQM3HHBKFiE"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuuWRMBrrAY",
        "outputId": "15e1819c-fa7d-49ab-b944-d5f5110459b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "last_fc_layer = model.fc\n",
        "\n",
        "input_features = last_fc_layer.in_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqf7iroOwvq2",
        "outputId": "e133fb06-9868-4912-e836-80b9f9f293d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全连接层结构： Linear(in_features=512, out_features=4, bias=True)\n",
            "全连接层权重形状： torch.Size([4, 512])\n",
            "全连接层偏置形状： torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "fc_layer = model.fc\n",
        "\n",
        "print(\"全连接层结构：\", fc_layer)\n",
        "print(\"全连接层权重形状：\", fc_layer.weight.shape)\n",
        "print(\"全连接层偏置形状：\", fc_layer.bias.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1UnM4ToMPXv"
      },
      "source": [
        "Check:(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWh-kHp1vNb",
        "outputId": "dbac08e4-05f8-40f4-d882-200e045c7e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "tensor(1.5868, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, label = next(dataiter)\n",
        "\n",
        "#print(\"Inputs:\", images[0])       # 显示输入数据\n",
        "      # 只处理第一个 batch 后退出循环\n",
        "\n",
        "type(images[0])\n",
        "\n",
        "\n",
        "input_tensor = torch.cat((images[0], images[1]), dim=0)\n",
        "import torch\n",
        "\n",
        "\n",
        "labels = torch.cat((label, label), dim=0)\n",
        "#print(labels)\n",
        "\n",
        "outputs = model(input_tensor)\n",
        "#print(outputs)\n",
        "\n",
        "print(len(outputs))\n",
        "print(len(labels))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jMXI2Dukty",
        "outputId": "04a13456-1823-485e-a009-ce4c51837bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7cd3252a3d60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "test = torch.load('/content/drive/MyDrive/ip/testdata.pt')\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hSVD3wsqim"
      },
      "source": [
        "check an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOpFA1vlUXy",
        "outputId": "022b77ae-f4ec-46ef-c2a4-51696568a29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取第一个 batch\n",
        "first_batch = next(iter(trainloader))\n",
        "\n",
        "# 打印第一个 batch\n",
        "# print(first_batch)\n",
        "\n",
        "print(len(first_batch[0][1]))\n",
        "print(len(first_batch[0][0]))\n",
        "\n",
        "# batch_size个\n",
        "\n",
        "\n",
        "# for i, items in enumerate(trainloader, 0):\n",
        "#  print(i, items)\n",
        "#  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModifiedResNet\n"
      ],
      "metadata": {
        "id": "pgY9MuCX8xzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90F789NYgK0e",
        "outputId": "5bb34249-f47c-4a51-a974-57389a0b3e15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 86.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.final_layer = list(model.children())[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features_flattened = features.view( x.shape[0], -1)\n",
        "        final_output = self.final_layer(features_flattened)\n",
        "\n",
        "        return features, final_output\n",
        "\n",
        "\n",
        "modified_model = ModifiedResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JeRhqEhNW7D4",
        "outputId": "dd7122f6-a2e1-4418-f1cc-5d7d9edbef4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'first_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b4ede2f49613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.cat((first_batch[0][0], first_batch[0][1]), dim=0)\n",
        "labels = torch.cat((first_batch[1], first_batch[1]), dim=0)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(input_tensor.shape[0])\n",
        "print(labels.shape)\n",
        "#input_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train process"
      ],
      "metadata": {
        "id": "RTaK4QPx86Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdykKpAdrrCz",
        "outputId": "16ca98b5-5d29-4022-ac41-520c242bc1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "11it [07:23, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [11/198], Loss: 1.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:57, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [22/198], Loss: 0.6445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:22, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [33/198], Loss: 0.4303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:54, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [44/198], Loss: 0.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:29, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [55/198], Loss: 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:59, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [66/198], Loss: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:32, 41.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [77/198], Loss: 0.1903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:09, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [88/198], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [99/198], Loss: 0.1815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:02, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [110/198], Loss: 0.1576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:38, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [121/198], Loss: 0.1529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:14, 40.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [132/198], Loss: 0.1419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:45, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [143/198], Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:20, 41.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [154/198], Loss: 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:51, 41.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [165/198], Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:16, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [176/198], Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:39, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [187/198], Loss: 0.0940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:00, 40.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [198/198], Loss: 0.0900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "11it [07:30, 40.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [11/198], Loss: 0.0390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:50, 40.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [22/198], Loss: 0.0359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [33/198], Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:35, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [44/198], Loss: 0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [36:59, 40.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [55/198], Loss: 0.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:22, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [66/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [51:46, 40.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [77/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:10, 40.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [88/198], Loss: 0.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:06:34, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [99/198], Loss: 0.0300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:06, 41.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [110/198], Loss: 0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:21:36, 40.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [121/198], Loss: 0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:07, 40.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [132/198], Loss: 0.0299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:36:37, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [143/198], Loss: 0.0309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:09, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [154/198], Loss: 0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:51:42, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [165/198], Loss: 0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:14, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [176/198], Loss: 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:06:46, 41.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [187/198], Loss: 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:14, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [198/198], Loss: 0.0209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:15, 40.68s/it]\n",
            "11it [07:32, 40.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [11/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:58, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [22/198], Loss: 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:30, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [33/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:55, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [44/198], Loss: 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:20, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [55/198], Loss: 0.0084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:48, 40.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [66/198], Loss: 0.0086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:14, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [77/198], Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:48, 40.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [88/198], Loss: 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:16, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [99/198], Loss: 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:49, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [110/198], Loss: 0.0072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:17, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [121/198], Loss: 0.0077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:46, 40.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [132/198], Loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:18, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [143/198], Loss: 0.0064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:43, 40.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [154/198], Loss: 0.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:10, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [165/198], Loss: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:40, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [176/198], Loss: 0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:06, 40.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [187/198], Loss: 0.0068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:33, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [198/198], Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:34, 40.78s/it]\n",
            "11it [07:41, 41.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [11/198], Loss: 0.0058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:13, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [22/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:44, 40.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [33/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:16, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [44/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:40, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [55/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:09, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [66/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:35, 40.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [77/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:10, 41.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [88/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [99/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:13, 41.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [110/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:47, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [121/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:16, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [132/198], Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:43, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [143/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:16, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [154/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:45, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [165/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:13, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [176/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:50, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [187/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:26, 41.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [198/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:27, 41.05s/it]\n",
            "11it [07:41, 41.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [11/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:20, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [22/198], Loss: 0.0048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:58, 41.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [33/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:37, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [44/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [55/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:50, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [66/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:27, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [77/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:01:08, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [88/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:39, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [99/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:16, 41.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [110/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:52, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [121/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:20, 40.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [132/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:53, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [143/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:27, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [154/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:04, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [165/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:42, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [176/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:21, 41.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [187/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:56, 41.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [198/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:57, 41.50s/it]\n",
            "11it [07:44, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [11/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:25, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [22/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [33/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:34, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [44/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:05, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [55/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:32, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [66/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:05, 41.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [77/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:39, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [88/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:15, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [99/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:47, 40.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [110/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:19, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [121/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:55, 41.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [132/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:29, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [143/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:06, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [154/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:43, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [165/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:11, 40.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [176/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:42, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [187/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:24, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [198/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:25, 41.34s/it]\n",
            "11it [07:35, 40.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [11/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:06, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [22/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:47, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [33/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:19, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:57, 41.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [55/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:34, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [66/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:14, 41.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [77/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:47, 41.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [88/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:20, 41.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [99/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:04, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:41, 41.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [121/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:21, 41.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [132/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:39:00, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [143/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:33, 41.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [154/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:02, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [165/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:35, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [176/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:04, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [187/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:42, 41.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [198/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:43, 41.43s/it]\n",
            "11it [07:45, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [11/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:21, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [22/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [33/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:33, 41.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [55/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:46, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [66/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:22, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [77/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:51, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [88/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:14, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [99/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:46, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:22, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [121/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:58, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [132/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:33, 41.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [143/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:11, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [154/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:46, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [165/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [176/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:41, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [187/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "189it [2:10:05, 41.73s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "modified_model=modified_model.to(device)\n",
        "modified_model=modified_model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "            for j in range(batch_size):\n",
        "                y = items[1][j].to(device)           # Class label\n",
        "                images1 = items[0][0][j].to(device)  # First image\n",
        "                images2 = items[0][1][j].to(device)  # Second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                lam_loss = 0.0\n",
        "                for k in range(512):\n",
        "                    w = fc_layer.weight[y, k] ** 2\n",
        "                    dst = (f1[0, k, 0, 0] - f2[0, k, 0, 0]) ** 2\n",
        "                    lam_loss += w * dst\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i+1) %  11== 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/11))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/model_weights_output_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLMZjBCqaZ6"
      },
      "outputs": [],
      "source": [
        "training_data = torch.tensor(data)\n",
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIsQ3KbelCN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/ip/model_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For similar pairs:"
      ],
      "metadata": {
        "id": "WuiZXWkG9DYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dm1j-oLek0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset1(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        images = sample[0]\n",
        "        label = sample[1]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7wPaFtSpENP",
        "outputId": "75d8367f-7970-43cf-81d2-4da88790966d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip/dachshund_pairs2.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-51b849d757dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdachshund2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/dachshund_pairs2.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdachshund1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/dachshund_pairs1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbulldog1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip/bulldog_pairs1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/dachshund_pairs2.npy'"
          ]
        }
      ],
      "source": [
        "\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "training_data = torch.tensor(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBGtMHhpzKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dachshund_medium2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium2.npy')\n",
        "dachshund_medium1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium1.npy')\n",
        "bulldog_medium1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium1.npy')\n",
        "bulldog_medium2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium2.npy')\n",
        "corgi_medium1 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium1.npy')\n",
        "corgi_medium2 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium2.npy')\n",
        "labrador_medium2 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium2.npy')\n",
        "labrador_medium1 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium1.npy')\n",
        "\n",
        "labrador_medium = np.concatenate((labrador_medium1, labrador_medium2), axis=0)\n",
        "bulldog_medium = np.concatenate((bulldog_medium1, bulldog_medium2), axis=0)\n",
        "corgi_medium = np.concatenate((corgi_medium1, corgi_medium2), axis=0)\n",
        "dachshund_medium = np.concatenate((dachshund_medium1, dachshund_medium2), axis=0)\n",
        "\n",
        "data_medium = np.concatenate((labrador_medium, bulldog_medium, corgi_medium, dachshund_medium), axis=0)\n",
        "training_data_medium = torch.tensor(data_medium)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-y4fDJnxWmP"
      },
      "outputs": [],
      "source": [
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "lipfY6ZIuxro",
        "outputId": "7db4a854-68a4-4eb4-a2f8-3ce20db2e660"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-776625d398e5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 使用列表推导式将每个 data 转换为所需的形式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
          ]
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 将每个 data 转换为所需的形式\n",
        "training_data = [transform_data(data) for data in training_data]\n",
        "training_data[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T872dSn4qXrP",
        "outputId": "96f82541-3f55-454b-cf75-e35f6b475709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[-0.4739, -0.4911, -0.5082,  ..., -0.6623, -0.6452, -0.6452],\n",
              "          [-0.4911, -0.4739, -0.4568,  ..., -0.6623, -0.6623, -0.6452],\n",
              "          [-0.4397, -0.4054, -0.3883,  ..., -0.6623, -0.6794, -0.6452],\n",
              "          ...,\n",
              "          [-1.5528, -0.6452,  0.0056,  ...,  1.0331,  1.4783,  1.0844],\n",
              "          [-1.0733, -0.7822, -1.4672,  ...,  0.9646,  1.4783,  1.3070],\n",
              "          [-1.2103, -1.4500, -1.7583,  ...,  0.6049,  1.4783,  1.3413]],\n",
              " \n",
              "         [[ 0.6254,  0.6429,  0.6429,  ...,  0.3277,  0.3627,  0.3627],\n",
              "          [ 0.6604,  0.6779,  0.6429,  ...,  0.3277,  0.3277,  0.3102],\n",
              "          [ 0.6779,  0.6954,  0.6779,  ...,  0.3277,  0.3627,  0.3803],\n",
              "          ...,\n",
              "          [-0.7052,  0.2227,  0.5203,  ...,  0.5028,  0.9930,  0.4503],\n",
              "          [-0.3901,  0.0301, -0.5651,  ...,  0.2927,  0.9755,  0.7479],\n",
              "          [-0.7752, -0.9853, -1.2829,  ..., -0.0749,  0.9930,  0.8704]],\n",
              " \n",
              "         [[ 1.1934,  1.2457,  1.2457,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2631,  1.2805,  1.2631,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2980,  1.3154,  1.2980,  ...,  0.9145,  0.9319,  0.9668],\n",
              "          ...,\n",
              "          [-1.1596, -0.3578,  0.2348,  ...,  0.4788,  0.9842,  0.4962],\n",
              "          [-0.5495, -0.3230, -1.1421,  ...,  0.2871,  0.9319,  0.7576],\n",
              "          [-0.7936, -1.1596, -1.5604,  ..., -0.0790,  0.9842,  0.8971]]]),\n",
              " tensor([[[-0.5082, -0.5253, -0.4911,  ...,  1.5639,  1.8037,  1.8379],\n",
              "          [-0.4739, -0.4226, -0.4911,  ...,  1.6667,  1.8550,  1.8722],\n",
              "          [-0.4568, -0.4226, -0.4911,  ...,  1.8550,  1.8208,  1.8037],\n",
              "          ...,\n",
              "          [-1.0904, -0.5082, -0.3541,  ..., -0.5938, -0.7479, -0.3027],\n",
              "          [-1.5528, -1.7069, -1.3644,  ..., -0.6281, -0.5938, -0.6452],\n",
              "          [-1.3644, -1.4329, -1.5528,  ..., -0.2684, -0.4568, -0.9020]],\n",
              " \n",
              "         [[-1.1078, -1.1253, -1.0903,  ...,  1.2556,  1.6758,  1.8158],\n",
              "          [-1.1078, -1.0728, -1.1078,  ...,  1.4307,  1.8859,  1.9559],\n",
              "          [-1.0553, -1.0378, -1.0903,  ...,  1.9034,  1.9034,  1.8158],\n",
              "          ...,\n",
              "          [-1.3880, -1.0203, -1.0378,  ..., -1.0903, -1.2129, -0.8452],\n",
              "          [-1.6681, -1.8782, -1.6506,  ..., -1.1253, -1.1078, -1.2129],\n",
              "          [-1.5455, -1.4755, -1.5980,  ..., -0.7752, -0.9853, -1.4230]],\n",
              " \n",
              "         [[-0.8807, -0.8807, -0.8458,  ...,  1.2108,  1.6291,  1.8208],\n",
              "          [-0.8458, -0.8458, -0.8458,  ...,  1.3851,  1.8905,  1.9603],\n",
              "          [-0.8110, -0.7936, -0.8284,  ...,  1.9428,  1.9951,  1.8557],\n",
              "          ...,\n",
              "          [-0.9330, -0.7761, -0.6890,  ..., -0.7761, -0.9156, -0.5670],\n",
              "          [-1.4036, -1.5604, -1.3687,  ..., -0.8284, -0.8284, -0.9504],\n",
              "          [-1.3164, -1.2293, -1.3164,  ..., -0.5495, -0.7238, -1.1421]]])]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 使用列表推导式将每个 data 转换为所需的形式\n",
        "training_data_medium = [transform_data(data) for data in training_data_medium]\n",
        "training_data_medium[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTtNaRpmCpd",
        "outputId": "67e5a9f5-d381-4ea7-ae70-11eddc86f9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2032\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 定义每个类别的名称和数量\n",
        "labels = []\n",
        "\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(508):\n",
        "    labels.extend([3])  # 前508个为3\n",
        "for _ in range(508):\n",
        "    labels.extend([0])  # 508-508*2为0\n",
        "for _ in range(508):\n",
        "    labels.extend([1])  # 508*2-508*3为1\n",
        "for _ in range(508):\n",
        "    labels.extend([2])  # 508*3-508*4为2\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels))  # 应该打印出 2032\n",
        "labels[508]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8hS8AgE4pKyv",
        "outputId": "1b5c9101-8ab5-42c7-e376-979b45702f6d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bc38e2019804>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcombined_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 打印新的列表的长度，确保每个数据都有对应的标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train = list(zip(training_data, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train))  # 应该打印出 2032\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bjA_xicqu-q",
        "outputId": "7ee7ddcd-b828-458b-9b5a-9571b30cc089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train_medium = list(zip(training_data_medium, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train_medium))  # 2032"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHc6RZzlfZAD",
        "outputId": "02424fcf-0d35-4b41-dec9-fa1d00287c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([tensor([[[-0.4739, -0.4911, -0.5082,  ..., -0.6623, -0.6452, -0.6452],\n",
              "           [-0.4911, -0.4739, -0.4568,  ..., -0.6623, -0.6623, -0.6452],\n",
              "           [-0.4397, -0.4054, -0.3883,  ..., -0.6623, -0.6794, -0.6452],\n",
              "           ...,\n",
              "           [-1.5528, -0.6452,  0.0056,  ...,  1.0331,  1.4783,  1.0844],\n",
              "           [-1.0733, -0.7822, -1.4672,  ...,  0.9646,  1.4783,  1.3070],\n",
              "           [-1.2103, -1.4500, -1.7583,  ...,  0.6049,  1.4783,  1.3413]],\n",
              "  \n",
              "          [[ 0.6254,  0.6429,  0.6429,  ...,  0.3277,  0.3627,  0.3627],\n",
              "           [ 0.6604,  0.6779,  0.6429,  ...,  0.3277,  0.3277,  0.3102],\n",
              "           [ 0.6779,  0.6954,  0.6779,  ...,  0.3277,  0.3627,  0.3803],\n",
              "           ...,\n",
              "           [-0.7052,  0.2227,  0.5203,  ...,  0.5028,  0.9930,  0.4503],\n",
              "           [-0.3901,  0.0301, -0.5651,  ...,  0.2927,  0.9755,  0.7479],\n",
              "           [-0.7752, -0.9853, -1.2829,  ..., -0.0749,  0.9930,  0.8704]],\n",
              "  \n",
              "          [[ 1.1934,  1.2457,  1.2457,  ...,  0.9145,  0.9145,  0.9145],\n",
              "           [ 1.2631,  1.2805,  1.2631,  ...,  0.9145,  0.9145,  0.9145],\n",
              "           [ 1.2980,  1.3154,  1.2980,  ...,  0.9145,  0.9319,  0.9668],\n",
              "           ...,\n",
              "           [-1.1596, -0.3578,  0.2348,  ...,  0.4788,  0.9842,  0.4962],\n",
              "           [-0.5495, -0.3230, -1.1421,  ...,  0.2871,  0.9319,  0.7576],\n",
              "           [-0.7936, -1.1596, -1.5604,  ..., -0.0790,  0.9842,  0.8971]]]),\n",
              "  tensor([[[-0.5082, -0.5253, -0.4911,  ...,  1.5639,  1.8037,  1.8379],\n",
              "           [-0.4739, -0.4226, -0.4911,  ...,  1.6667,  1.8550,  1.8722],\n",
              "           [-0.4568, -0.4226, -0.4911,  ...,  1.8550,  1.8208,  1.8037],\n",
              "           ...,\n",
              "           [-1.0904, -0.5082, -0.3541,  ..., -0.5938, -0.7479, -0.3027],\n",
              "           [-1.5528, -1.7069, -1.3644,  ..., -0.6281, -0.5938, -0.6452],\n",
              "           [-1.3644, -1.4329, -1.5528,  ..., -0.2684, -0.4568, -0.9020]],\n",
              "  \n",
              "          [[-1.1078, -1.1253, -1.0903,  ...,  1.2556,  1.6758,  1.8158],\n",
              "           [-1.1078, -1.0728, -1.1078,  ...,  1.4307,  1.8859,  1.9559],\n",
              "           [-1.0553, -1.0378, -1.0903,  ...,  1.9034,  1.9034,  1.8158],\n",
              "           ...,\n",
              "           [-1.3880, -1.0203, -1.0378,  ..., -1.0903, -1.2129, -0.8452],\n",
              "           [-1.6681, -1.8782, -1.6506,  ..., -1.1253, -1.1078, -1.2129],\n",
              "           [-1.5455, -1.4755, -1.5980,  ..., -0.7752, -0.9853, -1.4230]],\n",
              "  \n",
              "          [[-0.8807, -0.8807, -0.8458,  ...,  1.2108,  1.6291,  1.8208],\n",
              "           [-0.8458, -0.8458, -0.8458,  ...,  1.3851,  1.8905,  1.9603],\n",
              "           [-0.8110, -0.7936, -0.8284,  ...,  1.9428,  1.9951,  1.8557],\n",
              "           ...,\n",
              "           [-0.9330, -0.7761, -0.6890,  ..., -0.7761, -0.9156, -0.5670],\n",
              "           [-1.4036, -1.5604, -1.3687,  ..., -0.8284, -0.8284, -0.9504],\n",
              "           [-1.3164, -1.2293, -1.3164,  ..., -0.5495, -0.7238, -1.1421]]])],\n",
              " 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_dataset1 = CustomDataset1(combined_train_medium)\n",
        "custom_dataset1[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zihO8aa0cjKh"
      },
      "outputs": [],
      "source": [
        "# 导入需要的库\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "trainloader1 = DataLoader(custom_dataset1, batch_size=127, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SGwJcfPBE2G",
        "outputId": "615f0ca0-cdf4-4d04-e071-d961f00db085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "print(f1.shape)\n",
        "f1_squared = torch.pow(f1, 2)\n",
        "print(f1_squared.shape)\n",
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5a5RVH2yT5G",
        "outputId": "abfb6b9f-5eaa-45c1-c502-2271b45a4617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8c9wMs83eX",
        "outputId": "07840e10-8594-44b7-f34f-7e43503a35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "print(f1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGEKEWSuorD",
        "outputId": "afba0682-8b0b-4dec-970d-c5a0db61e471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "fc_layer = modified_model.final_layer\n",
        "print(fc_layer.weight.shape)\n",
        "w = fc_layer.weight[1]**2\n",
        "\n",
        "print(w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJHhdBkAIYm",
        "outputId": "43302df3-c5e2-4a7f-c015-8df31114f15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6768, -0.0463, -0.0187,  0.4089],\n",
            "        [ 0.8044, -1.3712,  0.6512,  0.2529]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([0, 0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "image1 = torch.randn(3, 224, 224)  # 假设图片1的形状为 [3, 224, 224]\n",
        "image2 = torch.randn(3, 224, 224)  # 假设图片2的形状为 [3, 224, 224]\n",
        "\n",
        "input_tensor = torch.cat((image1.unsqueeze(0), image2.unsqueeze(0)), dim=0)\n",
        "input_tensor\n",
        "y=modified_model(input_tensor.to(device))[1]\n",
        "print(y)\n",
        "predicted = torch.argmax(y, dim=1)\n",
        "print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "qBmyZK2PrrEX",
        "outputId": "a48d7b20-0372-4175-de9a-03113d6a25a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [16/16], Loss: 0.4704, Accuracy: 72.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/50], Step [16/16], Loss: 0.2790, Accuracy: 86.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:46,  2.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50], Step [16/16], Loss: 0.1960, Accuracy: 90.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:44,  2.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/50], Step [16/16], Loss: 0.1366, Accuracy: 94.34%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50], Step [16/16], Loss: 0.0912, Accuracy: 97.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50], Step [16/16], Loss: 0.0560, Accuracy: 99.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/50], Step [16/16], Loss: 0.0341, Accuracy: 99.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:46,  2.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50], Step [16/16], Loss: 0.0245, Accuracy: 99.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [00:45,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50], Step [16/16], Loss: 0.0219, Accuracy: 99.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "16it [00:45,  2.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/50], Step [16/16], Loss: 0.0180, Accuracy: 99.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [00:16,  3.34s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1a91be8d0b00>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mlam_loss_all\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERM_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam_loss_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 50\n",
        "batch_size = 127\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader1 = DataLoader(custom_dataset1, batch_size=batch_size, shuffle=True)\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "modified_model=modified_model.to(device).train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "\n",
        "    for i, items in tqdm(enumerate(trainloader1, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "\n",
        "            for j in range(batch_size):\n",
        "\n",
        "                y = items[1][j].to(device)           # jth class label\n",
        "                images1 = items[0][0][j].to(device)  # jth first image\n",
        "                images2 = items[0][1][j].to(device)  # jth second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                w = fc_layer.weight[y] ** 2\n",
        "                diff = torch.squeeze(torch.pow(f1- f2, 2))\n",
        "                lam_loss = torch.sum(torch.mul(diff, w))\n",
        "\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i+1) %  16== 0:\n",
        "                accuracy = 100 * correct / total\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, len(trainloader1), running_loss/16, accuracy))\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/output_medium_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34hKBm823Sg",
        "outputId": "f9d0a3c3-6518-4353-8f52-10a04d3953f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[-0.1486,  0.1254, -0.1999,  ..., -0.8678, -0.5253, -0.5424],\n",
            "         [-0.1486,  0.0912, -0.4568,  ..., -1.5528, -1.1589, -0.9020],\n",
            "         [-0.1999, -0.3541, -0.8507,  ..., -1.8268, -1.6213, -1.4500],\n",
            "         ...,\n",
            "         [ 1.3070,  0.8276,  0.2453,  ...,  0.7248,  0.5536,  0.5878],\n",
            "         [ 0.0912,  0.1939, -0.0116,  ..., -0.7993,  0.1597,  0.5707],\n",
            "         [-0.4226, -0.1999,  0.2967,  ..., -1.0562, -0.6281, -0.5082]],\n",
            "\n",
            "        [[ 0.0301,  0.3627,  0.0476,  ..., -0.9153, -0.6001, -0.7227],\n",
            "         [ 0.1001,  0.3452, -0.2500,  ..., -1.5455, -1.1604, -0.9328],\n",
            "         [ 0.0826, -0.0224, -0.5476,  ..., -1.7731, -1.5980, -1.4930],\n",
            "         ...,\n",
            "         [ 0.2927, -0.1450, -0.8452,  ...,  0.2577,  0.1176,  0.1001],\n",
            "         [-0.8627, -0.7752, -0.9503,  ..., -1.1604, -0.2675,  0.1877],\n",
            "         [-0.9678, -0.8803, -0.3725,  ..., -1.2129, -0.9153, -0.8978]],\n",
            "\n",
            "        [[-0.4973, -0.1312, -0.3055,  ..., -1.4384, -1.2990, -1.2816],\n",
            "         [-0.4450, -0.3055, -0.7761,  ..., -1.7347, -1.6127, -1.4559],\n",
            "         [-0.5147, -0.7761, -1.2467,  ..., -1.8044, -1.7173, -1.6476],\n",
            "         ...,\n",
            "         [-0.1487, -0.5147, -1.1944,  ...,  0.2522,  0.1651,  0.0256],\n",
            "         [-1.1421, -1.0376, -1.2293,  ..., -1.1596, -0.2010,  0.1999],\n",
            "         [-1.1247, -1.0376, -0.6018,  ..., -1.1247, -0.7761, -0.8284]]]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')\n",
        "len(testdata_medium)\n",
        "print(testdata_medium[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAWgmfNd25rs",
        "outputId": "b3906110-526d-4aa5-9b50-f7c096965756"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/model_output_medium_epoch_50.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "tEy8VCn39eGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fOJujGudYhYa",
        "outputId": "adf9149e-6a38-4714-f41e-63987c8079f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/198 [01:11<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ba9b7773c4b2>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader_medium\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model = modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "# 将测试数据集转化为 DataLoader\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = modified_model(images)[1]\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v01aSR00LqpI",
        "outputId": "a500650e-6281-4fc4-f3b4-e62cc78fdf74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25344"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')\n",
        "len(testdata_medium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1ygIB_HDyY",
        "outputId": "12c8fef2-8817-435e-bd66-336564f8ea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [3:22:21<00:00, 61.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分类任务的准确率: 75.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "\n",
        "# 加载.pt文件\n",
        "\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = modified_model(images)[1]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28HS3FWGtR8s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset:\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index][0], self.data[index][1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_tensor(self):\n",
        "        tensor_data = []\n",
        "        for image, label in self.data:\n",
        "            tensor_data.append((torch.tensor(image), label))\n",
        "\n",
        "        return tensor_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hFvXsW8SrYFM",
        "outputId": "a7ffd795-e2a5-499c-b0be-f80562e9f7a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c8bbd58e4b7a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ip/training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtensor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),                     # 调整图像短边至 256 像素\n",
        "    transforms.CenterCrop(224),                 # 中心裁剪图像为 224x224\n",
        "    transforms.ToTensor(),                      # 转换图像为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像数据\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 加载自定义数据集\n",
        "dataset = CustomDataset(npy_file=\"/content/drive/MyDrive/ip/training_data.npy\", transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 创建 DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztB9GY4v4yo",
        "outputId": "3392943a-290f-4547-8cb4-cef983a10d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Type: <class '__main__.CustomDataset'>\n",
            "Dataset Dimension: (25344, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset_type = type(dataset)\n",
        "print(\"Dataset Type:\", dataset_type)\n",
        "\n",
        "# 获取数据集的维度\n",
        "dataset_dimension = dataset.data.shape\n",
        "print(\"Dataset Dimension:\", dataset_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EOBx1nCxuCsC",
        "outputId": "ac4a35e3-ae9c-450d-84a0-d76fc73641c0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unexpected type <class 'tuple'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d57b01628137>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 获取 DataLoader 中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 打印第一个批次的输入数据和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected type {type(img)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'tuple'>"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch 是一个列表，包含了一个批次的样本数据\n",
        "    # 在这里你可以自定义处理逻辑，将样本转换为张量形式\n",
        "\n",
        "    # 假设 batch 中的每个元素是一个元组，其中包含输入数据和对应的标签\n",
        "    inputs = [item[0] for item in batch]  # 提取输入数据\n",
        "    labels = [item[1] for item in batch]  # 提取标签\n",
        "\n",
        "    # 将输入数据和标签转换为张量形式\n",
        "    inputs_tensor = torch.tensor(inputs)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    return inputs_tensor, labels_tensor\n",
        "\n",
        "# 定义 DataLoader，指定 collate_fn 参数为自定义的 collate_fn 函数\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 获取 DataLoader 中的数据\n",
        "inputs, labels = next(iter(data_loader))\n",
        "\n",
        "# 打印第一个批次的输入数据和标签\n",
        "print(\"First Batch Inputs:\", inputs)\n",
        "print(\"First Batch Labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsUjsKgl-2i",
        "outputId": "012f56c5-3a7e-4912-ad02-2443ff0d8f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (25344, 2)\n",
            "Train Y shape: (25344,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for element in array:\n",
        "\n",
        "    sample, label = element\n",
        "\n",
        "    train_x.append(sample)\n",
        "    train_y.append(label)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHRm6Ylmz7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpL-8JSj55R",
        "outputId": "9512c9a5-a704-4b99-b006-6df0900056bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('corgi_2105.png', 'corgi_954.png'), 'corgi'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYXYu7OrxQc",
        "outputId": "bfdbc041-8821-4b96-9dc4-c915662440e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder contains 3168 images.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# 指定文件夹路径\n",
        "folder_path = '/content/drive/MyDrive/ip/SpawriousImages/bulldog'\n",
        "\n",
        "# 使用glob.glob获取所有图片文件的路径，并计算数量\n",
        "num_images = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
        "print(f'The folder contains {num_images} images.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFzy3YrH9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rx8CzfX9rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGjjkXis9rpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce:\n"
      ],
      "metadata": {
        "id": "r69Yy9KS9r3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFjpaL71qgR",
        "outputId": "25c3c22d-1295-431c-de66-aeedc0711426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3864667587  0.3897000789  0.3901163938  0.3981846882  0.3810416256  0.4013417522  0.0000000000  1.5313433409  5.6991815567  0             27.390903472 \n",
            "0.7663247189  0.7667719021  0.9904320379  0.9861878453  0.9788913001  0.9668508287  1.2625764451  0.1483003787  5.7843055725  100           0.6112645364 \n",
            "0.7623791675  0.7582872928  0.9927993687  0.9881610103  0.9869796804  0.9798737174  2.5251528901  0.0304591087  5.7843055725  200           0.6120824623 \n",
            "0.8103176169  0.8086029992  0.9964490037  0.9881610103  0.9929966463  0.9798737174  3.7877293352  0.0201038574  5.7843055725  300           0.6128335547 \n",
            "0.7342177944  0.7229676401  0.9921088972  0.9881610103  0.9876701519  0.9731649566  5.0503057802  0.0166535372  5.7843055725  400           0.6066111851 \n",
            "0.7267705662  0.7213891081  0.9958571710  0.9909234412  0.9922075360  0.9763220205  6.3128822253  0.0185868401  5.7843055725  500           0.6118927002 \n",
            "0.7765831525  0.7778216259  0.9984217794  0.9925019732  0.9967449201  0.9818468824  7.5754586703  0.0134620355  5.7843055725  600           0.6051793170 \n",
            "0.7576938252  0.7480268350  0.9978299467  0.9936858721  0.9957585323  0.9842146803  8.8380351154  0.0087729464  5.7843055725  700           0.6085211968 \n",
            "0.7600611560  0.7563141279  0.9984217794  0.9925019732  0.9962517262  0.9818468824  10.100611560  0.0123126021  5.7843055725  800           0.6048365140 \n",
            "0.7093115013  0.7091554854  0.9961530874  0.9885556433  0.9950680608  0.9818468824  11.363188005  0.0064040128  5.7843055725  900           0.6142849422 \n",
            "0.7815150917  0.7792028414  0.9968435589  0.9901341752  0.9906293154  0.9790844515  12.625764450  0.0093996652  5.7843055725  1000          0.6039929366 \n",
            "0.7462024068  0.7490134175  0.9994081673  0.9921073402  0.9986190570  0.9834254144  13.888340895  0.0092029764  5.7843055725  1100          0.6129468703 \n",
            "0.8009469323  0.7959747435  0.9992108897  0.9928966062  0.9991122509  0.9857932123  15.150917340  0.0058361374  5.7843055725  1200          0.6129310250 \n",
            "0.7381633458  0.7391475927  0.9972381140  0.9897395422  0.9964490037  0.9802683504  16.413493785  0.0065432409  5.7843055725  1300          0.6122647572 \n",
            "0.6935292957  0.6906077348  0.9981258631  0.9913180742  0.9978299467  0.9802683504  17.676070230  0.0046631041  5.7843055725  1400          0.6144099188 \n",
            "0.6489938844  0.6475927388  0.9986190570  0.9940805051  0.9951666995  0.9786898185  18.938646675  0.0084209092  5.7843055725  1500          0.6136151099 \n",
            "0.7438350760  0.7450670876  0.9994081673  0.9913180742  0.9993095285  0.9869771113  20.201223120  0.0082047096  5.7843055725  1600          0.6134618235 \n",
            "0.7649437759  0.7588792423  0.9970408365  0.9885556433  0.9971394752  0.9794790845  21.463799566  0.0020670449  5.7843055725  1700          0.6151823425 \n",
            "0.8479976327  0.8433307024  0.9973367528  0.9893449092  0.9966462813  0.9767166535  22.726376011  0.0058088228  5.7843055725  1800          0.6114165998 \n",
            "0.7854113237  0.7847277032  0.9984217794  0.9921073402  0.9957585323  0.9814522494  23.988952456  0.0053677419  5.7843055725  1900          0.6099036169 \n",
            "0.7859538370  0.7786108919  0.9989149734  0.9917127072  0.9975340304  0.9834254144  25.251528901  0.0037218446  5.7843055725  2000          0.6132613826 \n",
            "0.6918524364  0.6793606946  0.9976326692  0.9897395422  0.9973367528  0.9830307814  26.514105346  0.0072307730  5.7843055725  2100          0.6134376049 \n",
            "0.7332314066  0.7269139700  0.9992108897  0.9948697711  0.9986190570  0.9802683504  27.776681791  0.0073834352  5.7843055725  2200          0.6204751110 \n",
            "0.7945847307  0.7878847672  0.9979285855  0.9913180742  0.9969421977  0.9818468824  29.039258236  0.0084000665  5.7843055725  2300          0.6125090265 \n",
            "0.7764845137  0.7647987372  1.0000000000  0.9917127072  0.9999013612  0.9834254144  30.301834681  0.0061496431  5.7843055725  2400          0.6324354410 \n",
            "0.6687216413  0.6590370955  0.9953639771  0.9834254144  0.9920102584  0.9767166535  31.564411126  0.0049843378  5.7843055725  2500          0.6270753837 \n",
            "0.7318011442  0.7241515391  0.9984217794  0.9889502762  0.9978299467  0.9814522494  32.826987571  0.0057329830  5.7843055725  2600          0.6227247167 \n",
            "0.7836851450  0.7756511444  0.9999013612  0.9944751381  0.9992108897  0.9838200474  34.089564016  0.0009479631  5.7843055725  2700          0.6132366180 \n",
            "0.7607023081  0.7576953433  0.9985204182  0.9925019732  0.9973367528  0.9802683504  35.352140461  0.0028693231  5.7843055725  2800          0.6186019158 \n",
            "0.7607516275  0.7513812155  0.9984217794  0.9885556433  0.9939830341  0.9767166535  36.614716906  0.0079865522  5.7843055725  2900          0.6299188948 \n",
            "0.7857072401  0.7758484609  0.9998027224  0.9909234412  0.9995068061  0.9846093133  37.877293351  0.0030832417  5.7843055725  3000          0.6098960829 \n",
            "0.7091635431  0.6939621152  0.9978299467  0.9885556433  0.9969421977  0.9771112865  39.139869796  0.0061063865  5.7843055725  3100          0.6046432948 \n",
            "0.7215427106  0.7095501184  0.9965476425  0.9893449092  0.9955612547  0.9806629834  40.402446241  0.0045622018  5.7843055725  3200          0.6033505225 \n",
            "0.7802821069  0.7715074980  0.9998027224  0.9925019732  0.9990136122  0.9881610103  41.665022686  0.0067104823  5.7843055725  3300          0.6084430003 \n",
            "0.7143420793  0.7109313339  0.9959558098  0.9869771113  0.9970408365  0.9782951855  42.927599132  0.0011498852  5.7843055725  3400          0.6063428593 \n",
            "0.6730124285  0.6653512234  0.9973367528  0.9889502762  0.9950680608  0.9739542226  44.190175577  0.0085864400  5.7843055725  3500          0.6008972216 \n",
            "0.6958966266  0.6898184688  0.9998027224  0.9921073402  0.9996054449  0.9857932123  45.452752022  0.0064733884  5.7843055725  3600          0.6162673044 \n",
            "0.7082757940  0.7028413575  1.0000000000  0.9956590371  0.9999013612  0.9889502762  46.715328467  0.0012216950  5.7843055725  3700          0.6148056483 \n",
            "0.7186328664  0.7099447514  1.0000000000  0.9944751381  1.0000000000  0.9889502762  47.977904912  0.0000642128  5.7843055725  3800          0.6070259309 \n",
            "0.7200631288  0.7113259669  0.9997040836  0.9921073402  0.9998027224  0.9861878453  49.240481357  0.0027398469  5.7843055725  3900          0.6156265235 \n",
            "0.7058591438  0.7091554854  0.9995068061  0.9940805051  0.9994081673  0.9881610103  50.503057802  0.0021378895  5.7843055725  4000          0.6109139323 \n",
            "0.6887453147  0.6779794791  0.9994081673  0.9917127072  0.9993095285  0.9861878453  51.765634247  0.0059131746  5.7843055725  4100          0.6170952582 \n",
            "0.6611757743  0.6572612470  0.9973367528  0.9913180742  0.9970408365  0.9806629834  53.028210692  0.0104169882  5.7843055725  4200          0.6217965150 \n",
            "0.6604853028  0.6515390687  0.9982245019  0.9905288082  0.9955612547  0.9763220205  54.290787137  0.0042702924  5.7843055725  4300          0.6096786547 \n",
            "0.7143913987  0.7036306235  0.9992108897  0.9936858721  0.9978299467  0.9802683504  55.553363582  0.0065798409  5.7843055725  4400          0.6024882984 \n",
            "0.7114815545  0.7056037885  0.9999013612  0.9952644041  0.9997040836  0.9917127072  56.815940027  0.0049846871  5.7843055725  4500          0.6199430537 \n",
            "0.6791773525  0.6659431728  0.9992108897  0.9928966062  0.9990136122  0.9806629834  58.078516472  0.0005054018  5.7843055725  4600          0.6146416759 \n",
            "0.7630203196  0.7582872928  0.9999013612  0.9956590371  1.0000000000  0.9869771113  59.341092917  0.0010236725  5.7843055725  4700          0.6122219038 \n",
            "0.7570033537  0.7513812155  0.9999013612  0.9952644041  0.9999013612  0.9881610103  60.603669362  0.0000619924  5.7843055725  4800          0.6136543655 \n",
            "0.6861807063  0.6712707182  0.9983231407  0.9889502762  0.9973367528  0.9810576164  61.866245807  0.0034500310  5.7843055725  4900          0.6070861173 \n",
            "0.6905208128  0.6902131018  0.9999013612  0.9952644041  0.9989149734  0.9822415154  63.128822252  0.0057498560  5.7843055725  5000          0.6079993272 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647,\\\n",
        "        \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLCqJpRpZla",
        "outputId": "1a0e5102-ef83-43f2-d0eb-2034bc3093f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        71.1 +/- 0.0               71.1                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        69.1 +/- 0.0               69.1                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSJ6vNQiFYD",
        "outputId": "6a81e146-dd33-456a-c9e6-95da2b3fd601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_medium/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 107MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3137699744  0.3155090766  0.4236535806  0.4340962904  0.4138883409  0.4352801894  0.0000000000  1.5721870661  5.6991815567  0             121.17406868 \n",
            "0.6615210101  0.6598263615  0.9904320379  0.9889502762  0.9813572697  0.9790844515  1.2625764451  0.1269948081  5.7843055725  100           0.5992083979 \n",
            "0.6557999605  0.6521310182  0.9934898402  0.9928966062  0.9871769580  0.9810576164  2.5251528901  0.0242757843  5.7843055725  200           0.6010344815 \n",
            "0.7217893076  0.7209944751  0.9941803117  0.9901341752  0.9905306767  0.9822415154  3.7877293352  0.0248986174  5.7843055725  300           0.6032668781 \n",
            "0.6864766226  0.6795580110  0.9990136122  0.9976322021  0.9960544486  0.9857932123  5.0503057802  0.0148176499  5.7843055725  400           0.6020192647 \n",
            "0.7547346617  0.7531570639  0.9977313080  0.9940805051  0.9947721444  0.9857932123  6.3128822253  0.0099429032  5.7843055725  500           0.6023221374 \n",
            "0.6849477214  0.6823204420  0.9983231407  0.9960536701  0.9959558098  0.9822415154  7.5754586703  0.0127289780  5.7843055725  600           0.5986590838 \n",
            "0.6821365161  0.6754143646  0.9976326692  0.9940805051  0.9963503650  0.9853985793  8.8380351154  0.0070593210  5.7843055725  700           0.5992206550 \n",
            "0.7350562241  0.7342146803  0.9992108897  0.9964483031  0.9980272243  0.9877663773  10.100611560  0.0090081152  5.7843055725  800           0.5954315782 \n",
            "0.6724699152  0.6637726914  0.9995068061  0.9956590371  0.9983231407  0.9877663773  11.363188005  0.0071447303  5.7843055725  900           0.5991444755 \n",
            "0.7353521405  0.7310576164  0.9983231407  0.9964483031  0.9978299467  0.9873717443  12.625764450  0.0082690991  5.7843055725  1000          0.6007423878 \n",
            "0.7047247978  0.6971191792  0.9989149734  0.9952644041  0.9990136122  0.9861878453  13.888340895  0.0095554909  5.7843055725  1100          0.5999678946 \n",
            "0.7175478398  0.7115232833  0.9984217794  0.9956590371  0.9976326692  0.9850039463  15.150917340  0.0074848697  5.7843055725  1200          0.6209489059 \n",
            "0.6003156441  0.5935280189  0.9908265930  0.9846093133  0.9845137108  0.9739542226  16.413493785  0.0061670831  5.7843055725  1300          0.6227960443 \n",
            "0.7109883606  0.6983030781  0.9990136122  0.9932912391  0.9984217794  0.9877663773  17.676070230  0.0095289110  5.7843055725  1400          0.6323509693 \n",
            "0.7592227264  0.7523677979  0.9981258631  0.9956590371  0.9963503650  0.9846093133  18.938646675  0.0060454098  5.7843055725  1500          0.6389152265 \n",
            "0.7201617676  0.7127071823  0.9993095285  0.9956590371  0.9986190570  0.9889502762  20.201223120  0.0078355287  5.7843055725  1600          0.6430245256 \n",
            "0.7292858552  0.7211917916  0.9998027224  0.9956590371  0.9997040836  0.9925019732  21.463799566  0.0018214593  5.7843055725  1700          0.6293191934 \n",
            "0.7227756954  0.7123125493  0.9999013612  0.9968429361  0.9999013612  0.9893449092  22.726376011  0.0015204751  5.7843055725  1800          0.6129930377 \n",
            "0.6896823831  0.6892265193  0.9999013612  0.9964483031  0.9998027224  0.9897395422  23.988952456  0.0028037445  5.7843055725  1900          0.6100966716 \n",
            "0.7653383310  0.7582872928  0.9993095285  0.9964483031  0.9994081673  0.9932912391  25.251528901  0.0004546101  5.7843055725  2000          0.6023241353 \n",
            "0.7000887749  0.6896211523  0.9985204182  0.9936858721  0.9977313080  0.9865824783  26.514105346  0.0064458975  5.7843055725  2100          0.5988242507 \n",
            "0.6427303216  0.6410812944  0.9988163346  0.9968429361  0.9988163346  0.9873717443  27.776681791  0.0060048382  5.7843055725  2200          0.5992763162 \n",
            "0.7598638785  0.7527624309  1.0000000000  0.9988161010  0.9998027224  0.9905288082  29.039258236  0.0023152082  5.7843055725  2300          0.5971370530 \n",
            "0.6899289801  0.6874506709  0.9981258631  0.9913180742  0.9959558098  0.9873717443  30.301834681  0.0050733112  5.7843055725  2400          0.5996246147 \n",
            "0.7281515092  0.7239542226  0.9898402052  0.9767166535  0.9817518248  0.9723756906  31.564411126  0.0072616203  5.7843055725  2500          0.5943894243 \n",
            "0.7001380943  0.6992896606  0.9995068061  0.9956590371  0.9988163346  0.9881610103  32.826987571  0.0440309145  5.7843055725  2600          0.6050425506 \n",
            "0.7320970606  0.7237569061  0.9992108897  0.9956590371  0.9990136122  0.9905288082  34.089564016  0.0048803466  5.7843055725  2700          0.6109957647 \n",
            "0.6917044782  0.6831097080  0.9991122509  0.9932912391  0.9984217794  0.9846093133  35.352140461  0.0067349893  5.7843055725  2800          0.6111056709 \n",
            "0.7432432432  0.7421073402  1.0000000000  0.9984214680  0.9995068061  0.9893449092  36.614716906  0.0033565566  5.7843055725  2900          0.6050006723 \n",
            "0.6926415467  0.6876479874  0.9998027224  0.9952644041  0.9990136122  0.9857932123  37.877293351  0.0042016615  5.7843055725  3000          0.6177810144 \n",
            "0.7025547445  0.6949486977  0.9993095285  0.9976322021  0.9993095285  0.9897395422  39.139869796  0.0010211611  5.7843055725  3100          0.6140088010 \n",
            "0.7367330834  0.7367797948  0.9998027224  0.9972375691  0.9999013612  0.9893449092  40.402446241  0.0002262877  5.7843055725  3200          0.6185925364 \n",
            "0.7027027027  0.7020520916  1.0000000000  0.9976322021  1.0000000000  0.9913180742  41.665022686  0.0000888569  5.7843055725  3300          0.6096006036 \n",
            "0.6934306569  0.6850828729  0.9984217794  0.9952644041  0.9978299467  0.9865824783  42.927599132  0.0015141229  5.7843055725  3400          0.6194707274 \n",
            "0.7383113040  0.7346093133  0.9997040836  0.9972375691  0.9996054449  0.9901341752  44.190175577  0.0052019510  5.7843055725  3500          0.6134506059 \n",
            "0.7237127639  0.7231649566  1.0000000000  0.9980268350  0.9997040836  0.9865824783  45.452752022  0.0014862453  5.7843055725  3600          0.6209367180 \n",
            "0.7188794634  0.7131018153  1.0000000000  0.9972375691  1.0000000000  0.9921073402  46.715328467  0.0002694762  5.7843055725  3700          0.6362010550 \n",
            "0.7268692050  0.7259273875  0.9997040836  0.9940805051  0.9994081673  0.9897395422  47.977904912  0.0023738948  5.7843055725  3800          0.6051948500 \n",
            "0.7473367528  0.7415153907  0.9980272243  0.9940805051  0.9964490037  0.9838200474  49.240481357  0.0045498827  5.7843055725  3900          0.6058934021 \n",
            "0.7382126652  0.7344119968  0.9985204182  0.9968429361  0.9986190570  0.9869771113  50.503057802  0.0044438702  5.7843055725  4000          0.5994641709 \n",
            "0.6705464589  0.6643646409  0.9996054449  0.9925019732  0.9985204182  0.9850039463  51.765634247  0.0016873248  5.7843055725  4100          0.6027762508 \n",
            "0.7104458473  0.7071823204  0.9964490037  0.9877663773  0.9947721444  0.9822415154  53.028210692  0.0083639084  5.7843055725  4200          0.6098940921 \n",
            "0.7332807260  0.7302683504  1.0000000000  0.9972375691  1.0000000000  0.9905288082  54.290787137  0.0016600816  5.7843055725  4300          0.6013520265 \n",
            "0.7476326692  0.7407261247  0.9999013612  0.9948697711  0.9993095285  0.9897395422  55.553363582  0.0006339125  5.7843055725  4400          0.6025332189 \n",
            "0.7573979089  0.7525651144  0.9995068061  0.9980268350  0.9997040836  0.9877663773  56.815940027  0.0026876356  5.7843055725  4500          0.6076181936 \n",
            "0.6943677254  0.6925808998  0.9982245019  0.9936858721  0.9981258631  0.9842146803  58.078516472  0.0067190079  5.7843055725  4600          0.6034590435 \n",
            "0.7445255474  0.7391475927  0.9998027224  0.9976322021  0.9998027224  0.9909234412  59.341092917  0.0018836914  5.7843055725  4700          0.6027166390 \n",
            "0.7162655356  0.7067876875  1.0000000000  0.9964483031  0.9995068061  0.9885556433  60.603669362  0.0002436092  5.7843055725  4800          0.6082473326 \n",
            "0.7426020911  0.7385556433  0.9997040836  0.9948697711  0.9996054449  0.9905288082  61.866245807  0.0029796615  5.7843055725  4900          0.6071765113 \n",
            "0.7145393569  0.7097474349  0.9997040836  0.9944751381  0.9995068061  0.9897395422  63.128822252  0.0053898869  5.7843055725  5000          0.5998121667 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_medium/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuk-R16KzgOs",
        "outputId": "88244172-31ce-4811-8014-0c01efa9820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_hard/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 122MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             115.15087747 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.6141159964 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6257791138 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6224927640 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6194511318 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6173342490 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6224610925 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6156367707 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6182522154 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6168373513 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6274501014 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6201179457 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6196286297 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6265635109 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6200313568 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6176273632 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6281948471 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6170152378 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6204898381 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6164195275 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6218380213 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6168248272 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6204351020 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6241048074 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6225018644 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6205320001 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6193700123 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6194021606 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6208199739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6187628269 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6196645617 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6212025905 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6200934267 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6221250558 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6164404726 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6187021542 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6219896412 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6192560601 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6193850613 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6188530970 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6250334597 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6187652969 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6202621436 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6278406334 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6186798120 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6220876169 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6206880021 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6187240529 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6160216904 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6204047894 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6245353127 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_hard/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3W8kEpoNLl",
        "outputId": "3aafe63a-379d-4388-d85e-894fe453b5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/5 [00:00<?, ?it/s]\r                                                                                \rTotal records: 162\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.1 +/- 0.0               76.5 +/- 0.0               62.0 +/- 0.0               69.9                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        69.1 +/- 0.0               71.5 +/- 0.0               65.6 +/- 0.0               68.7                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtUrzrD4gOn",
        "outputId": "5a15d81f-aaee-46da-c1e9-64ebe124f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3447425528  0.3441199684  0.4174393371  0.4167324388  0.3603274808  0.3756906077  0.0000000000  1.5444172621  5.6991815567  0             92.626631498 \n",
            "0.8121424344  0.8239936859  0.9850069047  0.9790844515  0.9830341290  0.9818468824  1.2625764451  0.1916547985  5.7843055725  100           0.6161201310 \n",
            "0.7284474255  0.7334254144  0.9866837641  0.9790844515  0.9876701519  0.9822415154  2.5251528901  0.0378335118  5.7843055725  200           0.6242212915 \n",
            "0.7226277372  0.7243488556  0.9810613533  0.9629044988  0.9826395739  0.9763220205  3.7877293352  0.0316097732  5.7843055725  300           0.6324607801 \n",
            "0.7568553955  0.7604577743  0.9951666995  0.9865824783  0.9946735056  0.9861878453  5.0503057802  0.0218457361  5.7843055725  400           0.6257872558 \n",
            "0.7536003156  0.7574980268  0.9976326692  0.9877663773  0.9951666995  0.9897395422  6.3128822253  0.0149130280  5.7843055725  500           0.6235587239 \n",
            "0.7291378970  0.7357932123  0.9983231407  0.9893449092  0.9986190570  0.9936858721  7.5754586703  0.0117882919  5.7843055725  600           0.6279401875 \n",
            "0.7667192740  0.7693370166  0.9972381140  0.9869771113  0.9940816729  0.9889502762  8.8380351154  0.0145306918  5.7843055725  700           0.6247380352 \n",
            "0.7499506806  0.7573007103  0.9987176958  0.9901341752  0.9971394752  0.9913180742  10.100611560  0.0118083848  5.7843055725  800           0.6312047601 \n",
            "0.7436871178  0.7490134175  0.9961530874  0.9853985793  0.9956598935  0.9897395422  11.363188005  0.0109967921  5.7843055725  900           0.6202681732 \n",
            "0.7388044979  0.7474348856  0.9984217794  0.9905288082  0.9988163346  0.9932912391  12.625764450  0.0094502301  5.7843055725  1000          0.6276606607 \n",
            "0.7751035707  0.7717048145  0.9973367528  0.9822415154  0.9943775893  0.9869771113  13.888340895  0.0125363544  5.7843055725  1100          0.6285728884 \n",
            "0.7802327875  0.7839384373  0.9979285855  0.9877663773  0.9977313080  0.9889502762  15.150917340  0.0060999116  5.7843055725  1200          0.6247079110 \n",
            "0.7494081673  0.7580899763  0.9963503650  0.9881610103  0.9939830341  0.9850039463  16.413493785  0.0112833397  5.7843055725  1300          0.6322773695 \n",
            "0.7387551785  0.7470402526  0.9997040836  0.9932912391  0.9991122509  0.9925019732  17.676070230  0.0054056202  5.7843055725  1400          0.6218444490 \n",
            "0.7769283882  0.7778216259  0.9954626159  0.9830307814  0.9946735056  0.9869771113  18.938646675  0.0055534037  5.7843055725  1500          0.6221671605 \n",
            "0.7031958966  0.7073796369  0.9993095285  0.9861878453  0.9988163346  0.9936858721  20.201223120  0.0049165712  5.7843055725  1600          0.6286919904 \n",
            "0.7267705662  0.7241515391  0.9984217794  0.9885556433  0.9983231407  0.9905288082  21.463799566  0.0085521347  5.7843055725  1700          0.6241571999 \n",
            "0.6414973368  0.6497632202  0.9959558098  0.9869771113  0.9966462813  0.9869771113  22.726376011  0.0072744866  5.7843055725  1800          0.6317688847 \n",
            "0.7176464786  0.7237569061  0.9986190570  0.9889502762  0.9985204182  0.9885556433  23.988952456  0.0103979792  5.7843055725  1900          0.6230329943 \n",
            "0.7049713948  0.7058011050  0.9990136122  0.9877663773  0.9986190570  0.9897395422  25.251528901  0.0090116992  5.7843055725  2000          0.6276224732 \n",
            "0.7456105741  0.7494080505  0.9995068061  0.9940805051  0.9988163346  0.9925019732  26.514105346  0.0028007768  5.7843055725  2100          0.6244829988 \n",
            "0.7336752811  0.7395422257  0.9983231407  0.9909234412  0.9982245019  0.9897395422  27.776681791  0.0026261529  5.7843055725  2200          0.6262957954 \n",
            "0.7256362202  0.7332280979  0.9992108897  0.9901341752  0.9988163346  0.9925019732  29.039258236  0.0057956400  5.7843055725  2300          0.6327015185 \n",
            "0.7500986388  0.7533543804  0.9999013612  0.9913180742  0.9996054449  0.9917127072  30.301834681  0.0036455327  5.7843055725  2400          0.6239596629 \n",
            "0.7312586309  0.7320441989  0.9995068061  0.9921073402  0.9990136122  0.9901341752  31.564411126  0.0055238133  5.7843055725  2500          0.6324523091 \n",
            "0.6998421779  0.7042225730  0.9975340304  0.9850039463  0.9986190570  0.9897395422  32.826987571  0.0033805106  5.7843055725  2600          0.6255412984 \n",
            "0.7127638587  0.7168508287  0.9993095285  0.9905288082  0.9987176958  0.9928966062  34.089564016  0.0076531138  5.7843055725  2700          0.6293179131 \n",
            "0.7118761097  0.7156669298  0.9982245019  0.9897395422  0.9994081673  0.9913180742  35.352140461  0.0009840014  5.7843055725  2800          0.6253333163 \n",
            "0.6811008088  0.6838989740  0.9984217794  0.9897395422  0.9981258631  0.9877663773  36.614716906  0.0084054508  5.7843055725  2900          0.6237844157 \n",
            "0.6834188203  0.6831097080  0.9950680608  0.9798737174  0.9948707832  0.9857932123  37.877293351  0.0044238523  5.7843055725  3000          0.6262417722 \n",
            "0.6974748471  0.6994869771  0.9990136122  0.9921073402  0.9991122509  0.9897395422  39.139869796  0.0053147116  5.7843055725  3100          0.6270702934 \n",
            "0.7625764451  0.7665745856  0.9983231407  0.9857932123  0.9987176958  0.9913180742  40.402446241  0.0073252049  5.7843055725  3200          0.6314353418 \n",
            "0.7540935096  0.7634175217  0.9960544486  0.9826361484  0.9956598935  0.9861878453  41.665022686  0.0049057113  5.7843055725  3300          0.6251897311 \n",
            "0.7499506806  0.7535516969  0.9972381140  0.9834254144  0.9981258631  0.9917127072  42.927599132  0.0060753603  5.7843055725  3400          0.6289313126 \n",
            "0.7582363385  0.7586819258  0.9996054449  0.9909234412  0.9991122509  0.9893449092  44.190175577  0.0043921365  5.7843055725  3500          0.6250557089 \n",
            "0.7938942592  0.7989344909  0.9983231407  0.9881610103  0.9973367528  0.9913180742  45.452752022  0.0058474739  5.7843055725  3600          0.6268724537 \n",
            "0.7414677451  0.7472375691  0.9993095285  0.9909234412  0.9994081673  0.9921073402  46.715328467  0.0069936835  5.7843055725  3700          0.6215211320 \n",
            "0.7010258434  0.7063930545  0.9998027224  0.9925019732  0.9993095285  0.9928966062  47.977904912  0.0050067931  5.7843055725  3800          0.6244132352 \n",
            "0.7601104754  0.7582872928  0.9984217794  0.9869771113  0.9954626159  0.9873717443  49.240481357  0.0033604602  5.7843055725  3900          0.6313518667 \n",
            "0.7292365358  0.7352012628  1.0000000000  0.9960536701  1.0000000000  0.9917127072  50.503057802  0.0013490497  5.7843055725  4000          0.6236331105 \n",
            "0.7278062734  0.7357932123  0.9999013612  0.9917127072  0.9997040836  0.9921073402  51.765634247  0.0003818883  5.7843055725  4100          0.6287024641 \n",
            "0.7287926613  0.7336227309  0.9989149734  0.9853985793  0.9990136122  0.9913180742  53.028210692  0.0050014239  5.7843055725  4200          0.6291932082 \n",
            "0.7303215624  0.7377663773  0.9999013612  0.9889502762  0.9997040836  0.9901341752  54.290787137  0.0019504495  5.7843055725  4300          0.6304660201 \n",
            "0.7283487867  0.7322415154  1.0000000000  0.9921073402  0.9992108897  0.9921073402  55.553363582  0.0029379294  5.7843055725  4400          0.6251601553 \n",
            "0.7387058591  0.7399368587  0.9985204182  0.9885556433  0.9974353916  0.9913180742  56.815940027  0.0021374228  5.7843055725  4500          0.6251562452 \n",
            "0.6670447820  0.6708760852  0.9999013612  0.9932912391  0.9989149734  0.9897395422  58.078516472  0.0064164825  5.7843055725  4600          0.6286752725 \n",
            "0.7800848294  0.7833464878  0.9954626159  0.9830307814  0.9954626159  0.9885556433  59.341092917  0.0082279910  5.7843055725  4700          0.6250292301 \n",
            "0.6997435392  0.7042225730  0.9991122509  0.9925019732  0.9993095285  0.9925019732  60.603669362  0.0060093180  5.7843055725  4800          0.6258044958 \n",
            "0.7043795620  0.7111286504  0.9996054449  0.9917127072  0.9991122509  0.9928966062  61.866245807  0.0029612238  5.7843055725  4900          0.6235942554 \n",
            "0.7195699349  0.7170481452  0.9990136122  0.9909234412  0.9976326692  0.9877663773  63.128822252  0.0055418774  5.7843055725  5000          0.6231913924 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVSmQgNyig5",
        "outputId": "d6ede5dd-1397-4f48-f18f-ba33b2f2faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3572696784  0.3620757695  0.4539356875  0.4613259669  0.4520615506  0.4723756906  0.0000000000  1.6331243515  5.6991815567  0             55.661369085 \n",
            "0.4934405208  0.4964483031  0.9753403038  0.9688239937  0.9762280529  0.9723756906  1.2625764451  0.1566427394  5.7843055725  100           0.6162090135 \n",
            "0.5097159203  0.5185477506  0.9811599921  0.9775059195  0.9777076346  0.9668508287  2.5251528901  0.0377939333  5.7843055725  200           0.6225361347 \n",
            "0.5271256658  0.5380820837  0.9936871178  0.9881610103  0.9930952851  0.9861878453  3.7877293352  0.0288028434  5.7843055725  300           0.6236338639 \n",
            "0.4824422963  0.4968429361  0.9942789505  0.9877663773  0.9955612547  0.9909234412  5.0503057802  0.0388437792  5.7843055725  400           0.6268619251 \n",
            "0.5513908069  0.5586029992  0.9965476425  0.9869771113  0.9954626159  0.9869771113  6.3128822253  0.0148880032  5.7843055725  500           0.6201543760 \n",
            "0.4632570527  0.4727703236  0.9920102584  0.9794790845  0.9947721444  0.9857932123  7.5754586703  0.0180947598  5.7843055725  600           0.6200311804 \n",
            "0.3317715526  0.3326756117  0.9895442888  0.9767166535  0.9944762281  0.9893449092  8.8380351154  0.0098999443  5.7843055725  700           0.6183829451 \n",
            "0.4919609390  0.4948697711  0.9970408365  0.9865824783  0.9965476425  0.9857932123  10.100611560  0.0145966782  5.7843055725  800           0.6291699719 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUY2J85V-Ad",
        "outputId": "9e6fcdee-21bb-48d4-e2a2-b3f4f60d6298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.9 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.9 +/- 0.0               72.9                      \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.0 +/- 0.0               72.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output_M2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFubiAzerSGY",
        "outputId": "f7a88181-e706-4af8-a327-0b1490d252a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                    | 0/13 [00:00<?, ?it/s]\r                                                                                \rTotal records: 53\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               76.5 +/- 0.0               76.6                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               71.5 +/- 0.0               74.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2WzQYG9FSV",
        "outputId": "66d56659-a265-45fe-fb14-15d19d5c51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: train_output\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             99.749756574 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.5983280587 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6206359911 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6142829299 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6070183587 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6080141449 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6082016397 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6092026901 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6103980064 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6360183382 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6049654841 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6108168197 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6118657756 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6163139319 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6108947682 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6053397083 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6072963905 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6118159246 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6154971886 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6100856686 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6081331706 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6135662699 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6160948730 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6087784386 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6098929572 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6067762327 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6125501800 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6110928893 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6085288739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6073611617 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6072861338 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6083596730 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6128425336 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6068048215 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6056645203 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6041939640 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6081425190 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6051037884 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6070308352 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6057835174 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6114358330 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6085151696 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6074985671 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6056443095 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6110575628 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6077594399 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6041522574 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6092551422 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6140078497 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6102016497 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6084288812 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0 \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyPsM8-qTs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/train_output /content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeSXi_BAsw2",
        "outputId": "f8a407f0-e5b5-4577-e522-74fb8eb078eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 102\n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        76.5 +/- 0.0               62.0 +/- 0.0               69.3                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.5 +/- 0.0               65.6 +/- 0.0               68.5                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxPRKSpd7tW",
        "outputId": "e0a98e3b-2119-4b5a-d89a-0b08cc774ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
            "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
            "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
            "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 78, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
            "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
            "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
            "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/stringpict.py\", line 15, in <module>\n",
            "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Colab执行train.py脚本\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py\\\n",
        "        --data_dir=./domainbed/data/MNIST/\\\n",
        "        --algorithm IGA\\\n",
        "        --dataset ColoredMNIST\\\n",
        "        --test_env 2\n",
        "\n",
        "#启动python3解释器，并且执行名为train.py的python脚本\n",
        "#--data_dir, --algorithm, --dataset, --text_env是train.py文件中的命令行参数，命令行参数用来制定程序或脚本执行书所需要的配置，选项或参数。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXA5s87_0FX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 读取图像\n",
        "img = cv2.imread('input_image.jpg')\n",
        "\n",
        "# 创建与输入图像相同大小的掩码\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "\n",
        "# 创建前景和背景模型\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "# 定义一个矩形ROI，用于指定图像中的前景对象\n",
        "rect = (50,50,450,290)\n",
        "\n",
        "# 使用GrabCut算法进行图像分割\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# 将掩码中的可能的前景和可能的背景区域设置为0和2\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# 将原始图像与掩码相乘以获取前景对象\n",
        "img = img*mask2[:,:,np.newaxis]\n",
        "\n",
        "# 显示结果\n",
        "cv2.imshow('Result', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8MAbsYPTOg",
        "outputId": "4e5ff9f9-5fbd-4dbc-8b46-79903673f419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=\"/env/python:/content/DomainBed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tbOpWGPat2",
        "outputId": "f18a4248-822b-47e9-ae93-45ef19092c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLo5O4wdhf9",
        "outputId": "2f40c461-8185-4792-f68e-3a0b676773ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a5269aa7743b791c64ed6649418c057a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 575962639\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/173bf54d6d078902e3c95d84cd058342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 177603528\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/35d2062ac241826e2573114eb184c10b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1731344775\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 7.625215427542097e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.00047223799345445756\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/30fd34e2f4f278867b6ff5b3217c9af4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1643360463\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/93cbbc15feea120dcb5ef40876e5d339\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1552394041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b85999a8f7f51d5d4618de70657b6458\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 872123425\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7c7b782b06a6e854e2a90f87af941fab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1532722295\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ad9ee36f7c977d2e63461bd67f281f65\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1348154927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c6917ed9721df5093c80bb496ec569e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1049203149\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 12\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e09d3ae124ba408cc7b777e802abfc3b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 820509365\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.0061945703598755e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0003150750110930775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ec6ad8a352a25d018524a0799865c9c7\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 305456027\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a12555295bb7c7f7b16f49fa46aa6d43\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 335001469\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3933a42f4a7daf484c66126f193511cd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1090282834\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e0caf4e9b7f63f5f2e9dfc9c2cbd706f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 707756686\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.7028930742148706e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00044832883881609976\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a8bfbb8d29ad30056577251d58640c92\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1803180728\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3e97244e0bba4eff7f3112b1a237b744\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 988398352\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.5948054187960416e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.2409030903340844e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c56965d1318c614519d8d1aeeec2acc0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1033766585\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/359830bd171b960b8f49828cf7daea45\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1062091682\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c71071003a4a8e03d31fbc73dc56b251\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1323517681\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c21df39fbbbbff9e17a2219b8a0bdb4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 899531956\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.1059719178287245e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0226894592810383e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/144f7e007023484daf0f1835e105fa02\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1174342691\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00028242988155030726\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.0915251755880437e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/60e1b946d5dfb28c75817cb3b0f37895\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 894262147\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 15\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.768725917122619e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.692204119563736e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9e4750f5e7cdef36d12c41b1a6b11d8b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 430670040\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/d407d5a24ac774b5d0e87374d7bb0dcc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 939727439\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9b1089b3fd6bf0f3ece44fc77e993b3e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 406951466\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/eb213ec0817439be32acdbd077992b09\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 471015569\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa8f08ae34d3dae732c41aa5d02c8316\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 534836152\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/48d90e374515bb88643f4e2e9410980b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1405017170\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.456280188921339e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.005463379786545902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/123c1a60dc113b3ef130905aab29cf61\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1450517853\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/6830b2706bf869ab62120c8ec8a3d902\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1428592723\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3826168925328977e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.615900325399353e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a928b33eb83a3c2cd3efa5ea3f1ea8d9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1629628786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/476612568012d54c53a90e62b696d7bb\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1884237580\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 19\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f87bb4114b1895f7916f2b4ffc4cb860\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 536959106\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 11\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.323285967621206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.046120234156778e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b796a096bf44125b17789f4408dca06b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1903818547\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2eee150674bdf7a82d8c51eb4b1ce04a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 23433006\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/abc93fad1fd1056001dbadf8a1ca9e19\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1664885690\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1d6201f69bb66d8b6e489eda38dccc2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1064525671\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/61034eaa8320196809d9f605b075ea24\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 95358269\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a2a7ca35a2f50073f1242eb91762424c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1823278137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/09c50cd0748144c2769d47af395d8a2f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 809856719\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4134e9367b6221b835b22b88489a951d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 164181522\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dff4b52c83c4125df3323fd2db2b9f81\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 275388093\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b91c3a1a306c19c073d526f06d69ba03\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 216618918\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2c1b55962114ca954a4293b359288011\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 441369813\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5f9a4b767b89224a4075aee4b86b6256\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2034037337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002383446436179699\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 6.431270010222042e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/8b64798c53a5a1bba405d5c75dbf27e9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 693005437\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4b0c702dd74c39ad2ca842e5f3fc8ffc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1721323264\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5c18fb7899bf0c12dc359ebe9c1081d6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 244140596\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a44e96d250f70e7917800a5786e1f2fe\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 338717337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7d28429d6d35cc9f06f22e3a55845051\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1588968328\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002748180350891229\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.9000025480760227e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/991425b1146b1f446d84b36c087a6ef2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 895393786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/23a434a5febeed79a9ed9afeeb610ea9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1005706515\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e31aa2e37b983f5aa514b6243bb897e4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 539823350\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/97caedc9c298c79240b7148e65bd4864\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 848241137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/37de55f16c6cadbf954bb9c28018c6c9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1441525987\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1b86d2e19fa131d32841fa95fc15428\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1025341559\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.079846025444368e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.634713155314057e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84459224cbcb079b22304c4ca0337b15\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 658930196\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/840cda333a109b446d2d0be1aec01f44\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 797173368\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/0db98c8fc5bbd3ad85f5198cd2a9e242\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1690752950\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/00bb81be3e5faa7fa0e06a3d1b9fc214\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 640543768\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 35\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.203148467315319e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.5941595326730853e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a3cf6270845a5d9f19504a02c74d48d8\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 527331476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b719be2f2334c73ca22825242a857d83\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 794168150\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84dc1acf1587fab8013f239b8ee2a854\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 140411788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3b7e19147f067cefd3e300112c5744d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 889114309\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2bd0763b666af3a8b7180488e49f5df1\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1600026954\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ee01751ed5822f49800f2dff6d39011c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 652031788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a1fc347c08f7519f1a9885e2e4e1cc5a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2028568414\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3967520349d463cc0f4b42aa0e5a3cdc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2011109722\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a068a437f435df1e975b81101ea52090\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 887238287\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dcded23bc701bc64d1143bea8426fa7a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 874017095\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b338ef7ae36014cea7290002c49cdeab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 397958724\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7fcd0102087c6411f477f01e6e94adcd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1653294381\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f5541915a154a7ea2d59d32511dca70e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1008122992\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f4402201077fefda135d3f266680fb9d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1974935474\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fef9439cc09895fc8d5ed384d557aa2e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1905078720\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/21ce002219dcf5223be83527bc032575\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 16214241\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fae278ee4d6005566e976812d300076e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1838315136\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/15aef282c233ccf23bb82500660e4a85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1806374394\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/95dcaf3d7552b20d324e650e8344e391\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2139648535\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b59d08c5158891d095647c260599df72\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 863415268\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/396a66c0e9a33f42933162e9e157a7f6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1028178153\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/40a2ab0a6403041f72bcd672cd9685a6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2114559099\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dd31f52ac86bba2d9ad1ffdeee34c342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2029184004\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9cb8aefc8442b126f9c05a7cce526779\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 902654909\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/398e724ba11d5f6f2445d5b356ace1b0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1764407478\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4256491a7b9ddea5fd4f3b9404ed7948\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1041059927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa922f8e301f7a452a7d7802449b8900\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1622227716\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/bc89363eaa59127ca10cf772d2c57263\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1192519524\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/56102dff2a7005ef5db4c5933673ea85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 152054124\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 21\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00011281359420053416\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 5.000446907120253e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3f28d0e95f209ff5df269857a136372\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 472711008\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4514b27fbe9c296ab91cd05de3734f5e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1704833476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00015197093111758464\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0329604555494109e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9222fb7e414cd07468f4347ff233885d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 463949901\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4d35045a63b1eff681e8a628d2988b23\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 37332015\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.1375153221880086e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 6.326696718610415e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f936c2b44cc3dab85a923d914871cc4a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1141715041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c08bd5bdc0e4a927433e11e6f552089e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1353102125\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/205162f67cb34c386d1288cf23a3e73f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1743459794\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Launched 360 jobs!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.sweep launch\\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224\\\n",
        "       --output_dir=/content/MyDrive/ip/sweep_output\\\n",
        "       --command_launcher local\\\n",
        "       --algorithms ERM\\\n",
        "       --datasets SpawriousO2O_easy\\\n",
        "       --skip_confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr393evgOlTE",
        "outputId": "ace5ca35-edc0-49e3-ff67-4f086f769414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in directory: /content/domainbed/data\n",
            "MNIST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 指定要查看的目录路径\n",
        "data_dir = '/content/domainbed/data'  # 这里替换为你下载数据的目录路径\n",
        "\n",
        "# 列出指定目录下的文件和文件夹\n",
        "files_and_folders = os.listdir(data_dir)\n",
        "\n",
        "# 输出文件和文件夹列表\n",
        "print(\"Files and folders in directory:\", data_dir)\n",
        "for item in files_and_folders:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLTQ7T-5lgV"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peRMyZEz54u3",
        "outputId": "4d3a351e-775f-465a-a50d-86f28087b753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnjVjGVkZAQy"
      },
      "source": [
        "将所有图片转换成rgb形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZYfhASF-6u"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hzsjtd9Fn2k"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/ip/spawrious224/\"\n",
        "hparams = {\"data_augmentation\": True}\n",
        "test_envs = 0\n",
        "spawrious_o2o_easy = SpawriousO2O_easy(root_dir, test_envs, hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ByCqk5tsF2L8",
        "outputId": "bee03919-976b-48c0-fa21-5842a7b81a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'build_type1_combination' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-d9a268ae9e32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_type1_combination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_type1_combination' is not defined"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_o2o_easy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "8bwrHD3Qsnwv",
        "outputId": "2062da6d-58a0-4ecd-e19d-3fbc65dac0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [01:48<00:00, 29.17it/s]\n",
            "  4%|▍         | 136/3168 [00:32<12:02,  4.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-115b0497dc50>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0munloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk43pd2wZJ0M"
      },
      "source": [
        "寻找corgi类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUk9545INv",
        "outputId": "1c907d20-5c53-4e72-a511-78a91db9bbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corgi_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2441.png', 'drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2.png'), 'corgi')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "\n",
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/corgi/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "\n",
        "corgi_image_pairs = []\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, 'corgi'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "\n",
        "# 将 corgi_image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(corgi_image_pairs, f)\n",
        "\n",
        "print(\"Corgi_image pairs saved successfully.\")\n",
        "print(corgi_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeA1A4ALZNYR"
      },
      "source": [
        "寻找bulldog类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyT3OSv5IQT",
        "outputId": "585e03c4-a5f5-45a1-c88f-c595dffa4f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Bulldog_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/bulldog/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    bulldog_image_pairs.append((image_pair, 'bulldog'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(bulldog_image_pairs, f)\n",
        "\n",
        "print(\"Bulldog_image pairs saved successfully.\")\n",
        "print(bulldog_image_pairs[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZakjqAa0mfd",
        "outputId": "cb31c59b-f8c1-4cdc-c285-42c4174ee333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulldog\n"
          ]
        }
      ],
      "source": [
        "print(bulldog_image_pairs[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5rsjqJZRZA"
      },
      "source": [
        "寻找dachshund类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECFZVVm5ISR",
        "outputId": "4ae21f17-ad08-4abf-b6b4-32a0599c1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Dachshund_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/dachshund/jungle_dachshund_2902.png', 'drive/MyDrive/ip/spawrious224/0/dirt/dachshund/dirt_dachshund_343.png'), 'dachshund')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/dachshund/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, 'dachshund'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(dachshund_image_pairs, f)\n",
        "\n",
        "print(\"Dachshund_image pairs saved successfully.\")\n",
        "print(dachshund_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rg9-OhsZW5L"
      },
      "source": [
        "寻找labrador类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJlI-7ZYi36",
        "outputId": "46c742ff-2dfa-4b2b-b784-b0159d897f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "labrador_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_1201.png', 'drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_563.png'), 'labrador')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/labrador/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, 'labrador'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(labrador_image_pairs, f)\n",
        "\n",
        "print(\"labrador_image pairs saved successfully.\")\n",
        "print(labrador_image_pairs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZrnXz155UP",
        "outputId": "53e9bcbf-5edf-4b44-ca94-7e3105e3d6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_84.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1530.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_767.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1743.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2387.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_760.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_277.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_726.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2953.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_108.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3163.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2315.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2777.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1187.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_453.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_15.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2413.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_561.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_924.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_232.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1990.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1076.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_72.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1741.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2743.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_239.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_325.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1091.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_570.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_358.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_892.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3150.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2448.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3015.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_186.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1691.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1509.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_642.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1888.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_150.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2282.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3003.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1379.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2980.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2456.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2364.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2308.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_248.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2026.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2679.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_307.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2849.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1887.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3136.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2786.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3000.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_470.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2965.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_791.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2599.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3161.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1707.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1886.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_830.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2378.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_916.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_768.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2295.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2137.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1126.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2966.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1845.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_232.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2885.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1513.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2699.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1051.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_159.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2067.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2853.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_98.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2226.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1131.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1441.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2613.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2625.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_877.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_424.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2505.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2908.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_535.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1043.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_663.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1536.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1818.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1616.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2796.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_376.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1318.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_261.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1939.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1933.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2282.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1356.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_6.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_222.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2452.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2738.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1883.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2041.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_895.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3084.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_167.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2461.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2204.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1463.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2982.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_541.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1523.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2483.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1299.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_867.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2379.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_1309.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2053.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2740.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_920.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_2389.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2985.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_2435.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_803.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1697.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_291.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1006.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1563.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1796.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1753.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2466.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_935.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2864.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1505.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_772.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1364.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3008.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2936.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_364.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1347.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_797.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1124.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1574.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1934.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2514.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_52.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1388.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2320.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2129.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_3076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1084.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_329.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2630.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_2588.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2372.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_730.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2140.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2166.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3046.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1634.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1942.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_839.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_473.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_420.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_30.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2847.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2576.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2185.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_923.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1769.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_508.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_486.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_3099.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1973.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_244.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2066.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3054.png'), 'bulldog')]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 打开 .pkl 文件\n",
        "file_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 查看文件中的数据\n",
        "print(data[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaxZX0939Vu",
        "outputId": "88087c2c-bcfe-4b6a-a3f4-22a7b0ea6311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png',\n",
              "  'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'),\n",
              " 'bulldog')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 定义一个函数来加载单个 .pkl 文件\n",
        "def load_pkl(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 定义多个 .pkl 文件夹的路径\n",
        "file1='drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "file2='drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "file3='drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "file4='drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "file_paths = [file1, file2, file3, file4]\n",
        "\n",
        "# 合并\n",
        "merged_data = []\n",
        "for file_path in file_paths:\n",
        "    data = load_pkl(file_path)\n",
        "    merged_data.extend(data)\n",
        "\n",
        "\n",
        "merged_data[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG4ZrbJW7gNT"
      },
      "source": [
        "定义图像变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fnPAS-3b7ff1",
        "outputId": "3a41426e-6d81-4bfb-b9cb-59838d2ff4ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 62094/152064 [15:29<22:26, 66.80it/s]    \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c26271761609>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtransformed_image_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 定义图像变换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整大小为 224x224\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 对 merged_data 中所有图片路径应用变换\n",
        "transformed_data = []\n",
        "for image_pair, category in tqdm(merged_data):\n",
        "    transformed_image_pair = (transform(Image.open(image_pair[0])), transform(Image.open(image_pair[1])))\n",
        "    transformed_data.append((transformed_image_pair, category))\n",
        "\n",
        "# 输出变换后的数据\n",
        "print(transformed_data[1])\n",
        "\n",
        "\n",
        "dataloader = DataLoader(transformed_data, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsDg8lb7Lo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "# 定义自定义数据集类\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义 ResNet18 模型\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)  # 修改最后一层全连接层，输出为2类（假设是二分类任务）\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 准备数据集\n",
        "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', ...]  # 假设这里是你的图像数据集路径列表\n",
        "transform = transforms.Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "dataset = CustomDataset(image_paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch_images in enumerate(dataloader):\n",
        "        inputs = batch_images\n",
        "        labels = torch.randint(0, 2, (batch_images.size(0),))  # 假设这里是随机生成的标签\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # 每 10 个 mini-batch 输出一次损失值\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR2Se1J7LrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCvom3K7LtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dSlXY-7LvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar0YMs7R7LxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW2CdWBYwpu",
        "outputId": "c5e3a98e-6ec4-445d-b016-181739cbdc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image size is 224 pixels wide by 224 pixels high.\n"
          ]
        }
      ],
      "source": [
        "# 替换下面的路径为你图像的实际路径\n",
        "image_path = '/content/drive/My Drive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png'\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# 获取图像的大小\n",
        "width, height = img.size\n",
        "\n",
        "# 打印图像的大小\n",
        "print(f'The image size is {width} pixels wide by {height} pixels high.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiRyFGtY8iJ",
        "outputId": "5bc07ce5-0670-4e35-910a-e2d5bbc58c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'spawrious224_rgb': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56vrZ45Ywri"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 提取特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 定义图像预处理步骤\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整图像大小为 ResNet18 模型的输入大小\n",
        "    transforms.ToTensor(),  # 将图像转换为 Tensor 格式\n",
        "])\n",
        "\n",
        "# 加载 RGB 图像并进行预处理\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 添加 batch 维度，变成一个大小为 (1, C, H, W) 的 Tensor\n",
        "\n",
        "# 将图像输入到 ResNet18 模型中，并提取全局平均池化层的输出\n",
        "with torch.no_grad():\n",
        "    features = feature_extractor(input_batch)\n",
        "\n",
        "# 将特征转换为一个向量（reshape 为 (1, num_features)）\n",
        "global_avg_pooling_output = features.view(features.size(0), -1)\n",
        "\n",
        "# 输出向量的大小\n",
        "print(\"Global Average Pooling Output Shape:\", global_avg_pooling_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHUMXcfxBRH",
        "outputId": "5023f978-9943-4b52-db95-3917306e8d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape: torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH72AAHsxBTv",
        "outputId": "a309654e-c496-4611-d74e-d199df8e5239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape (with pooling): torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp4djmqsxBWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ7JRGRmxBYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sOryq0lgGL",
        "outputId": "aef2dd6a-3c69-42b0-e04c-713082b138eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
            "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
            "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
            "        ...,\n",
            "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
            "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
            "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]],\n",
            "       requires_grad=True)\n",
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# 加载预训练的 ResNet-18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 截取特征提取器部分（不包括最后的全连接层）\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "weights=model.fc.weight\n",
        "print(weights)\n",
        "print(len(weights))\n",
        "\n",
        "\n",
        "\n",
        "# 加载并预处理上传的两张图片数据\n",
        "image1_path = 'path/to/your/first/image.jpg'\n",
        "image2_path = 'path/to/your/second/image.jpg'\n",
        "image1 = preprocess_image(image1_path)\n",
        "image2 = preprocess_image(image2_path)\n",
        "\n",
        "# 提取图片的特征向量\n",
        "with torch.no_grad():\n",
        "    feature1 = feature_extractor(image1)\n",
        "    feature2 = feature_extractor(image2)\n",
        "\n",
        "# 对提取的特征向量进行全局平均池化操作\n",
        "global_avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "feature1_vector = global_avg_pool(feature1).squeeze()\n",
        "feature2_vector = global_avg_pool(feature2).squeeze()\n",
        "\n",
        "# 打印两个特征向量\n",
        "print(\"Feature vector for image 1:\", feature1_vector)\n",
        "print(\"Feature vector for image 2:\", feature2_vector)\n",
        "\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#定义损失函数\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "\n",
        "        # 自定义损失函数的计算过程，这里假设是平方误差损失\n",
        "        loss = torch.mean((output - target)**2)\n",
        "        return loss\n",
        "\n",
        "#定义损失函数\n",
        "def loss():\n",
        "  lam_loss_all=0\n",
        "  for i in range(batch_size):\n",
        "\toriginal=Feature map[i]\n",
        "\tpair=Feature map[10+i]\n",
        "        y_1=y[i]\n",
        "        w=Classification head weight[y_1]**2\n",
        "\tdistance=(original-pair)**2\n",
        "        lam_loss=0\n",
        "        For k 1to 2048:\n",
        "              lam_loss+=w[I]*distance[I]\n",
        "\tlam_loss_all+=lam_loss\n",
        "\n",
        "lam_loss_all/=10\n",
        "\n",
        "loss=erm_loss+lambda*lam_loss_all\n",
        "\n",
        "#开始训练\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # 解压当前 batch 中的图片对\n",
        "        images1, images2 = batch\n",
        "\n",
        "        # 前向传播\n",
        "        outputs1 = model(images1)\n",
        "        outputs2 = model(images2)\n",
        "\n",
        "        feature1 = feature_extractor(images1)\n",
        "        feature2 = feature_extractor(images2)\n",
        "\n",
        "        # 计算损失\n",
        "        loss = loss_fn(outputs1, outputs2)\n",
        "\n",
        "        # 反向传播与参数更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 打印当前损失\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# 定义优化器，并将所有参数添加到优化器中\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 训练过程中的损失计算示例\n",
        "# 假设 inputs 是模型的输入数据，targets 是真实标签\n",
        "#outputs = model(inputs)\n",
        "\n",
        "\n",
        "#loss = criterion(outputs, targets)\n",
        "\n",
        "# 反向传播与参数更新\n",
        "#optimizer.zero_grad()\n",
        "#loss.backward()\n",
        "#optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8AYk6QV59s0",
        "outputId": "1d1fd7af-edde-41d9-f342-9d9d3297ec39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "images = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png\")\n",
        "inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "image_features = model.get_image_features(**inputs)\n",
        "image_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRBhDp1-EQK",
        "outputId": "db7e1d1e-4b2b-46dc-db74-248de8d8e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8947], grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_6.png\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "other_features = model.get_image_features(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "similarity = torch.cosine_similarity(image_features, other_features, dim=1)\n",
        "print(similarity)\n",
        "\n",
        "#similar_images.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNpx89JdYAW"
      },
      "outputs": [],
      "source": [
        "# tensor --> numpy array\n",
        "# 10*768 --> 10*10\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "pairwise_cos=cosine_similarity(all_features_image0, all_features_image0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzY4-Bg9amE0",
        "outputId": "2c8648e7-753e-4e45-f242-874989629e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The path of the file is: /content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 要查找的文件名\n",
        "filename = 'train.py'\n",
        "\n",
        "# 使用 os.walk() 函数遍历文件系统，查找文件\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        print(\"The path of the file is:\", file_path)\n",
        "        break\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4ydb8Tf1ZL"
      },
      "outputs": [],
      "source": [
        "import domainbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHz6ikvEbKB4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# 将当前工作目录添加到模块搜索路径中\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXILhm1Z5Lu",
        "outputId": "bc18d9c5-2477-4aec-db5a-4a9f44a6515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    from domainbed import datasets\n",
            "ModuleNotFoundError: No module named 'domainbed'\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/DomainBed/domainbed/scripts')\n",
        "\n",
        "\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py  --data_dir=./domainbed/data/mnist_data/MNIST/MNIST/raw\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHZs22kIHITz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEui0DbG2T-"
      },
      "outputs": [],
      "source": [
        "import domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ccrCEUpIe3U",
        "outputId": "973b3d5a-7e54-40c2-c79f-c33db6b566b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import domainbed.scripts.train\n",
        "print(domainbed.scripts.train.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_8DJU6GQkP",
        "outputId": "647d4860-e9ce-4939-ed22-e6fbcbf2c271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6nF9hh2B20I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed/domainbed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpBUtnGDDP_T",
        "outputId": "e0bdf4c4-f6a2-4ee1-c05c-469b1ac9223c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "domainbed 模块已经上传到 Colab 环境中。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 列出当前目录下的文件和文件夹\n",
        "files_and_folders = os.listdir()\n",
        "\n",
        "# 检查是否有 domainbed 相关的文件或者文件夹存在\n",
        "if 'DomainBed' in files_and_folders:\n",
        "    print(\"domainbed 模块已经上传到 Colab 环境中。\")\n",
        "else:\n",
        "    print(\"domainbed 模块未上传到 Colab 环境中，请上传该模块。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "U73FCwSYCtHs",
        "outputId": "9eedd15b-ca7a-44e8-9c8a-62b6fc3c7c1e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'DomainBed.scripts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-671f19c45cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDomainBed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DomainBed.scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import DomainBed.scripts.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104WHdolBMr9",
        "outputId": "9532160a-2771-495f-edbe-236058077489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/DomainBed/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-wDOYOGcrBd",
        "outputId": "1c155a51-cb25-4d33-cef8-b9d66beba886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CODE_OF_CONDUCT.md  CONTRIBUTING.md  domainbed\tLICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tpA8g5crEd",
        "outputId": "4c37650f-6c66-41ca-a43b-a054019e7395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed\n"
          ]
        }
      ],
      "source": [
        "%cd domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpMP-JYcrG8",
        "outputId": "a5671b8c-1378-43db-800d-025f0fd06a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/DomainBed/domainbed/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9j-jXU4qnV",
        "outputId": "9a47a5e4-38bc-4ad0-9e0a-116112baebe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c2d66b9d68e869eab2d7fb0ceb797bc93c5a2eba8da460ac75e6fa1222eaeafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Pwi1MG4s0Q"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLqCJYk6Z-H"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(\"local\", \"Example App\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoTkcfW9crKX",
        "outputId": "51c83067-2d6c-4cfe-ab10-a058f03451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = sc.parallelize(range(1, 100))\n",
        "t = 50\n",
        "B = A.filter(lambda x: x < t)\n",
        "B.cache()\n",
        "t = 10\n",
        "\n",
        "C = B.filter(lambda x: x > t)\n",
        "\n",
        "print(C.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722a2LCPcrMx",
        "outputId": "dc6f003d-0d78-4ad2-94f9-3dddb67f9ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product: 233\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "def dot_product(rdd1, rdd2):\n",
        "  zipped_rdd = rdd1.zip(rdd2)\n",
        "  dot_product = zipped_rdd.map(lambda x: x[0]*x[1]).reduce(lambda x,y:x+y)\n",
        "  return dot_product\n",
        "\n",
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "result = dot_product(r1, r2)\n",
        "print(\"Dot product:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pdehnc-7kN6",
        "outputId": "0bfc6140-a0ec-4ffd-895c-cef3f0637ee2"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e471822f655>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the total dot product by summing up the partial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtotal_dot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot product:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_dot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "# Induce a different partitioning\n",
        "r2 = r2.flatMap(lambda x: [] if x == 1 else [x])\\\n",
        "       .flatMap(lambda x: [9, 9] if x == 9 else [x])\n",
        "\n",
        "def compute_dot_product(partition):\n",
        "    partial_sum = 0\n",
        "    for x, y in partition:\n",
        "        partial_sum += x * y\n",
        "    yield partial_sum\n",
        "\n",
        "dot_product_rdd = r1.zip(r2).mapPartitions(compute_dot_product)\n",
        "\n",
        "# Compute the total dot product by summing up the partial results\n",
        "total_dot_product = dot_product_rdd.reduce(lambda x, y: x + y)\n",
        "\n",
        "print(\"Dot product:\", total_dot_product)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a326f8e44d3948738ef67f40424427de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b6fd8c8272d4f9185d841e4cf821782",
              "IPY_MODEL_8d7a57be40b7419888bd08b9e9036a5b",
              "IPY_MODEL_226c307812624cca937995e1fbf6031a"
            ],
            "layout": "IPY_MODEL_0d11dfe2e7fd4c77990bdc28fcb1f803"
          }
        },
        "9b6fd8c8272d4f9185d841e4cf821782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01164c326fa4bf6a7298b20855b56bd",
            "placeholder": "​",
            "style": "IPY_MODEL_2d6a04b97f63471994347bdec2a9da5c",
            "value": "config.json: 100%"
          }
        },
        "8d7a57be40b7419888bd08b9e9036a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688d08d3ccf94b31a6e03ce40ade5c2f",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f10fc168417498d9d98031e2912e3af",
            "value": 4186
          }
        },
        "226c307812624cca937995e1fbf6031a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0e062d40c44e73af0002d43c4c7562",
            "placeholder": "​",
            "style": "IPY_MODEL_3113ff8b5b6d4e299d1ae31e10a11265",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 338kB/s]"
          }
        },
        "0d11dfe2e7fd4c77990bdc28fcb1f803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01164c326fa4bf6a7298b20855b56bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6a04b97f63471994347bdec2a9da5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "688d08d3ccf94b31a6e03ce40ade5c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f10fc168417498d9d98031e2912e3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af0e062d40c44e73af0002d43c4c7562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3113ff8b5b6d4e299d1ae31e10a11265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1fe129c93ad4a38bf8f64a3615ab80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88e7c7313c7c46049b88107d20d67df2",
              "IPY_MODEL_55ec36cb9db145a4b35e4fe16c3deec1",
              "IPY_MODEL_06bcb9b149d842949a9c6695e8c276e9"
            ],
            "layout": "IPY_MODEL_7fc97a393d124e8c9b711354b0c4f82f"
          }
        },
        "88e7c7313c7c46049b88107d20d67df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87eb0863992c4831aa99bd54c2f0f120",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf4db48c18b421397fa69b2e71c5757",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "55ec36cb9db145a4b35e4fe16c3deec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3ffe7d6464a12b6a27406a404af34",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3699f51a6bf4b12b15eb7b92bbca226",
            "value": 605247071
          }
        },
        "06bcb9b149d842949a9c6695e8c276e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd513184a22439c95d906a1bfed78d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d46964f8a648cf916d5473ac6ac792",
            "value": " 605M/605M [00:04&lt;00:00, 227MB/s]"
          }
        },
        "7fc97a393d124e8c9b711354b0c4f82f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87eb0863992c4831aa99bd54c2f0f120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf4db48c18b421397fa69b2e71c5757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff3ffe7d6464a12b6a27406a404af34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3699f51a6bf4b12b15eb7b92bbca226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dd513184a22439c95d906a1bfed78d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d46964f8a648cf916d5473ac6ac792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}