{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzVjng0cq4V",
        "outputId": "cb987e69-30c4-4fb1-a56a-1262e7e4c597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1308, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1308 (delta 26), reused 24 (delta 11), pack-reused 1259\u001b[K\n",
            "Receiving objects: 100% (1308/1308), 1.08 MiB | 3.39 MiB/s, done.\n",
            "Resolving deltas: 100% (763/763), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HApsEKnU5rM2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxCp4JTdivj",
        "outputId": "1a5aa420-c994-4c2d-f8d2-157a1b1a0d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjylGMPbTZEl",
        "outputId": "e3a199f1-e6fc-4d60-b036-0f3464e88348"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa_F2E_wzly"
      },
      "source": [
        "Convert images to /content/...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_g-N8vfERdY",
        "outputId": "3df918d5-14da-44b9-9f1e-c53744e0db30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wilds\n",
        "# 安装wilds模块\n",
        "# 使用wilds可以帮助研究人员更好地评估他们的机器学习算法在实际应用中的性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r_kfReEsJhNO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NQUkwkKPp6Us"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from download import download_spawrious"
      ],
      "metadata": {
        "id": "QcFueQOivecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-gdbwEqDy2A"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/ip1\"\n",
        "# 制定下载数据集所需要的目录\n",
        "\n",
        "download_spawrious(data_dir)\n",
        "# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\n",
        "# 调用其他函数下载其他数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MG-PvtDxJOTD"
      },
      "outputs": [],
      "source": [
        "# 创建 SpawriousO2O_easy 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "\n",
        "spawrious_easy = SpawriousO2O_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousO2O_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousO2O_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5Us1_27TKM0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9efqXNB2K5Pe",
        "outputId": "85b2ba53-f02c-4cf9-be7d-43a0ef69d737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IZdwtDLlbsq"
      },
      "outputs": [],
      "source": [
        "env1 = spawrious_easy[1]\n",
        "env2 = spawrious_easy[2]\n",
        "test = spawrious_easy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avZK4NVnUZxW"
      },
      "outputs": [],
      "source": [
        "env1_medium = spawrious_medium[1]\n",
        "env2_medium = spawrious_medium[2]\n",
        "test_medium = spawrious_medium[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAxRKr-oNWHg",
        "outputId": "b9593e8a-6bd3-4fdd-8124-0c7cf4fa69e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12672\n",
            "12672\n",
            "25344\n"
          ]
        }
      ],
      "source": [
        "env1_hard = spawrious_hard[1]\n",
        "env2_hard = spawrious_hard[2]\n",
        "test_hard = spawrious_hard[0]\n",
        "\n",
        "print(len(env1_hard))\n",
        "print(len(env2_hard))\n",
        "print(len(test_hard))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs19CK7hOHN"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt'\n",
        "torch.save(test_hard, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZFQQiRyNN71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVYsqDeDtlGw"
      },
      "outputs": [],
      "source": [
        "torch.save(test, '/content/drive/MyDrive/ip/testdata.pt')\n",
        "torch.save(test_medium, '/content/drive/MyDrive/ip/testdata_medium.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWtjDTrG4ho"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:\n"
      ],
      "metadata": {
        "id": "JKGmsTaZZV_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "FTvxrF-j-BTL",
        "outputId": "4cdfe557-5bf2-4d30-da83-6f1ee072fc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_tensor = env1_hard[3072][0]\n",
        "label = env1_hard[3072][1]\n",
        "\n",
        "image_array = image_tensor.numpy()\n",
        "image_array_rgb = np.transpose(image_array, (1, 2, 0))\n",
        "plt.imshow(image_array_rgb)\n",
        "plt.axis('off')  # 关闭坐标轴\n",
        "plt.show()\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_medium1 = []\n",
        "bulldog_medium2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "f9TleOcUiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_filter_medium1 = []\n",
        "bulldog_filter_medium2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_medium2.append(env2_medium[i][0])\n"
      ],
      "metadata": {
        "id": "EIMPsQZtZcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkefLJvgPCDC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "bulldog_filter_medium1_np = np.array(bulldog_filter_medium1)\n",
        "bulldog_filter_medium2_np = np.array(bulldog_filter_medium2)\n",
        "\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium1.npy', bulldog_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium2.npy', bulldog_filter_medium2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6X3shuzsRIJ",
        "outputId": "dd8eb974-8984-4071-9b8c-05d05675bf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "bulldog_medium1_np = np.array(bulldog_medium1)\n",
        "bulldog_medium2_np = np.array(bulldog_medium2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium1.npy', bulldog_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium2.npy', bulldog_medium2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_filter_medium1 = []\n",
        "dachshund_filter_medium2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "sWIoCKWbiw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-neQ3YR2Ewg"
      },
      "outputs": [],
      "source": [
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3072, 3072+3072):\n",
        "  dachshund1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756, 2756+2756):\n",
        "  dachshund2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dachshund_filter_medium1_np = np.array(dachshund_filter_medium1)\n",
        "dachshund_filter_medium2_np = np.array(dachshund_filter_medium2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium1.npy', dachshund_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium2.npy', dachshund_filter_medium2_np)\n",
        "\n",
        "dachshund_medium1_np = np.array(dachshund1)\n",
        "dachshund_medium2_np = np.array(dachshund2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium1.npy', dachshund_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium2.npy', dachshund_medium2_np)\n"
      ],
      "metadata": {
        "id": "JAPYDkGXULGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftTNGcd2m0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNUdbmZ2m45"
      },
      "outputs": [],
      "source": [
        "labrador_filter1 = []\n",
        "labrador_filter2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwSyffW2m9D"
      },
      "outputs": [],
      "source": [
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3072*2, 3072*3):\n",
        "  labrador1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*2, 2756*3):\n",
        "  labrador2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save labrador\n",
        "\n",
        "import numpy as np\n",
        "labrador_filter1_np = np.array(labrador_filter1)\n",
        "labrador_filter2_np = np.array(labrador_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium1.npy', labrador_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium2.npy', labrador_filter2_np)\n",
        "\n",
        "labrador_medium1_np = np.array(labrador1)\n",
        "labrador_medium2_np = np.array(labrador2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium1.npy', labrador_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium2.npy', labrador_medium2_np)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2wi1WcfVMwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQtiHE4WDbfZ"
      },
      "outputs": [],
      "source": [
        "corgi_filter1 = []\n",
        "corgi_filter2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7IptW5pIsFD"
      },
      "outputs": [],
      "source": [
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3072*3, 3072*4):\n",
        "  corgi1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*3, 2756*4):\n",
        "  corgi2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save corgi\n",
        "\n",
        "import numpy as np\n",
        "corgi_filter1_np = np.array(corgi_filter1)\n",
        "corgi_filter2_np = np.array(corgi_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium1.npy', corgi_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium2.npy', corgi_filter2_np)\n",
        "\n",
        "corgi_medium1_np = np.array(corgi1)\n",
        "corgi_medium2_np = np.array(corgi2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium1.npy', corgi_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium2.npy', corgi_medium2_np)\n"
      ],
      "metadata": {
        "id": "O5DYMDBHV5cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOYWgQ7GsbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSt-PjHa0vxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189d9eae-d5d3-4107-c1aa-a8c447d28b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDkvJ3N9HlQq",
        "outputId": "9ecd4e4a-ae00-415f-8360-419403e2c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "49q4nMcrOk7q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mQyAlC-VAall"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_hard1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_hard2.npy')\n",
        "corgi_filter1 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard1.npy')\n",
        "corgi_filter2 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qZwOYqQjbC7l"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_hard1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_hard2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "504i9eqpyujC"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_hard1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_hard2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "naaok8gKyvUb"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_hard1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_hard2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "um-nuTB-_Rp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from transformers import CLIPModel\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:"
      ],
      "metadata": {
        "id": "nrEh7ntajEry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uX1xyS2g-QEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "faf0203ade3e4d6d95de506945873501",
            "2473c911f9934e4ab801f1e91dd49182",
            "dc04e368de3e48b4b2837591490e1bc1",
            "7f9931b24ac44650b3652d44d6cf0aa4",
            "98ce801c92a240f2ab8b887f6c42145f",
            "595a936ef28246309976d12e3aa84168",
            "d24e944b880c49728193b32a79ddf541",
            "3dda789eab754f2c8607c93c867c348a",
            "7015de9f4e974759ba4d63683a026711",
            "82eafc40c2e546d787830b1203f30c9c",
            "dcb9f02ac3a348f7ad96a3adfa757934",
            "556464689c8d4e218b42c74e17cc9915",
            "f08024ab1c6e4ae8a67abe3557c67330",
            "68de135480854c139c5099eb157ca40a",
            "b7f4bb79f0534854b07904889e6ecf3f",
            "26c378ba460243ac99cfa9ac6df6172c",
            "f889a2302ed041df8eb8b0ffe1744504",
            "65a83793b69e4e5d859405944642c501",
            "51769e5b2c3742fa85bf1c7acb3c8d6c",
            "58dcbfcb64184f3596903ae08236d284",
            "ff7e7eee1fa24b5faed7fae7530d5aa2",
            "4b704eca4f374935b0124622d1217ff8"
          ]
        },
        "outputId": "86510f2c-536e-47f1-f650-9e255a68cb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf0203ade3e4d6d95de506945873501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "556464689c8d4e218b42c74e17cc9915"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# generate semantic sharing pairs using cosine similarity\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def similar_pair(i, class_filter, class_tensor):\n",
        "  similarity = 0\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > similarity:\n",
        "        similarity = res\n",
        "        index = j\n",
        "\n",
        "    pair1 = class_filter[i]\n",
        "    pair2 = class_tensor[index]\n",
        "    image_pair = (pair1, pair2)\n",
        "\n",
        "    return image_pair\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4KmCdocQh8h",
        "outputId": "59727623-3b75-410e-9033-fb773fa16db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [42:00<00:00, 26.26s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs1 = []\n",
        "for i in tqdm(range(len(corgi_filter1))):\n",
        "    pair = similar_pair(i, corgi_filter1, corgi1)\n",
        "    corgi_pairs1.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h-PRdG5HFlcK"
      },
      "outputs": [],
      "source": [
        "corgi_pairs1_np = np.array(corgi_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs1.npy', corgi_pairs1_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoN6G33F179",
        "outputId": "8ac13ca2-d7ef-4afe-90f5-ac8e78c03ba5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:38:22<00:00, 23.06s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(corgi_filter2))):\n",
        "    pair = similar_pair(i, corgi_filter2, corgi2)\n",
        "    corgi_pairs2.append(pair)\n",
        "\n",
        "\n",
        "corgi_pairs2_np = np.array(corgi_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs2.npy', corgi_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkONXq1cJ6w",
        "outputId": "78d06744-03e0-4d0b-eba3-012d7bf197d9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:02<00:00, 25.65s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter1, labrador1)\n",
        "    labrador_pairs1.append(pair)\n",
        "\n",
        "labrador_pairs1_np = np.array(labrador_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs1.npy', labrador_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygDEfA1mB4H",
        "outputId": "95232c28-3bf8-44a0-8b19-0a5907c4850c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:36:51<00:00, 22.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter2, labrador2)\n",
        "    labrador_pairs2.append(pair)\n",
        "\n",
        "labrador_pairs2_np = np.array(labrador_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs2.npy', labrador_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zPieI6Qh-j",
        "outputId": "623e8156-6be9-4be3-a9c4-ea3733ce3886"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [40:54<00:00, 25.57s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter1, bulldog1)\n",
        "    bulldog_pairs1.append(pair)\n",
        "\n",
        "bulldog_pairs1_np = np.array(bulldog_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs1.npy', bulldog_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUl4yFAKFDQ",
        "outputId": "934b6e3b-db43-4376-9f1e-0389d05bcb8b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:39:22<00:00, 23.21s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter2, bulldog2)\n",
        "    bulldog_pairs2.append(pair)\n",
        "\n",
        "bulldog_pairs2_np = np.array(bulldog_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs2.npy', bulldog_pairs2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKWFg-QXE7m",
        "outputId": "7a83c0ee-7d90-4338-dc90-501fcbb8a848"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:44<00:00, 26.09s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter1, dachshund1)\n",
        "    dachshund_pairs1.append(pair)\n",
        "\n",
        "dachshund_pairs1_np = np.array(dachshund_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs1.npy', dachshund_pairs1_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmg9gwwAbAd",
        "outputId": "dde5b7da-17f2-41fb-d1d1-80f084afe701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 412/412 [2:57:25<00:00, 25.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter2, dachshund2)\n",
        "    dachshund_pairs2.append(pair)\n",
        "\n",
        "dachshund_pairs2_np = np.array(dachshund_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs2.npy', dachshund_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cp0U6fMo5WkK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HKAgASqCmOKe"
      },
      "outputs": [],
      "source": [
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFrOE3RrLiG",
        "outputId": "2c079d89-33bd-41a3-98f3-30bfe0ed1462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-PMu7dA7nNUM"
      },
      "outputs": [],
      "source": [
        "training_data_np = np.array(training_data)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/training_data_hard.npy', training_data_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NrGu-LoTCz",
        "outputId": "2941f1f6-9d5a-4ae6-b1b8-7e86a7e6bfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2032"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0PdbNapNHB",
        "outputId": "54030c5e-e6fa-4299-e4f1-09c1a40ecede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "张量的形状： torch.Size([2032, 2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKslUAPyprb4",
        "outputId": "c6a75294-c4b4-4b19-f372-2a3842a347c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_easy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BAHgrw9bePe"
      },
      "source": [
        "convert all images into RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt50-fATZa32",
        "outputId": "ce1f6d76-1c38-4738-a51d-9cff9eff7433"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:07<00:00, 400.32it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.64it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.75it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.36it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.11it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.11it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.44it/s] \n",
            "100%|██████████| 3168/3168 [00:42<00:00, 73.81it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.81it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.29it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.98it/s] \n",
            "100%|██████████| 3168/3168 [00:41<00:00, 76.55it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.96it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.95it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.51it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.09it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:45<00:00, 69.65it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.34it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.47it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.75it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.43it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.11it/s] \n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:40<00:00, 78.95it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.40it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.98it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.39it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.18it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.05it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.91it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.46it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 80.48it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.66it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.47it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.05it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.02it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.07it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.99it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.61it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.41it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.99it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.86it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.81it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.70it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 83.88it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "所有图片转换完成！\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ip/spawrious224'\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        file_path = os.path.join(root, file)\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "            image.save(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRV3cb6FnoSX",
        "outputId": "c81a4785-7144-48f0-9653-fe0e26a6a245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bulldog', 'corgi', 'dachshund', 'labrador']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spawrious_easy.class_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swUTlzMZbAvm"
      },
      "source": [
        "find corgi images in env1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBlgf9kbPo1"
      },
      "source": [
        "find all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "MLAL0885BH2w",
        "outputId": "b23aef31-8b4b-429d-aad9-ff796f29b36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1826/12672 [02:35<15:20, 11.78it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e8a513c52f61>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspawrious_easy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bulldog\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbulldog_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corgi_images = []\n",
        "bulldog_images = []\n",
        "dachshund_images = []\n",
        "labrador_images = []\n",
        "\n",
        "\n",
        "for image, label in tqdm(env1):\n",
        "  if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images.append(image)\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images.append(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbcjhnlAXcZ",
        "outputId": "1f6b6fa3-702d-455e-815e-e80510a09565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3168\n",
            "3168\n",
            "3168\n",
            "3168\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi_images))\n",
        "print(len(bulldog_images))\n",
        "print(len(dachshund_images))\n",
        "print(len(labrador_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrz3aOyDbV9M"
      },
      "source": [
        "find all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFOg-czCymV",
        "outputId": "5b34ec3d-e0b2-4def-ea7e-51e8af9cf95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12672/12672 [1:20:01<00:00,  2.64it/s]\n"
          ]
        }
      ],
      "source": [
        "corgi_images2 = []\n",
        "bulldog_images2 = []\n",
        "dachshund_images2 = []\n",
        "labrador_images2 = []\n",
        "\n",
        "for image, label in tqdm(env2):\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images2.append(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKi8m9ibmRg"
      },
      "source": [
        "save all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGtK1RWUk7p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "def save_images(image_list, folder_path, label):\n",
        "    # 检查目标文件夹是否存在，不存在则创建\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 遍历图像列表，保存每张图像\n",
        "    for idx, tensor in enumerate(image_list):\n",
        "        image = TF.to_pil_image(tensor)                               # 将 tensor 转换为 PIL 图像\n",
        "        image_path = os.path.join(folder_path, f\"{label}_{idx}.png\")  # 定义图像的保存路径\n",
        "        image.save(image_path)                                        # 保存图像\n",
        "\n",
        "# Google Drive 挂载路径\n",
        "drive_path = \"/content/drive/MyDrive/ip/SpawriousImages\"\n",
        "\n",
        "# 分别保存每种类别的图像\n",
        "save_images(bulldog_images, os.path.join(drive_path, 'bulldog'), 'bulldog')\n",
        "save_images(dachshund_images, os.path.join(drive_path, 'dachshund'), 'dachshund')\n",
        "save_images(labrador_images, os.path.join(drive_path, 'labrador'), 'labrador')\n",
        "save_images(corgi_images, os.path.join(drive_path, 'corgi'), 'corgi')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ELr3P6bt2K"
      },
      "source": [
        "save all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFFo56kXnMc"
      },
      "outputs": [],
      "source": [
        "save_images(bulldog_images2, os.path.join(drive_path, 'bulldog2'), 'bulldog')\n",
        "save_images(dachshund_images2, os.path.join(drive_path, 'dachshund2'), 'dachshund')\n",
        "save_images(labrador_images2, os.path.join(drive_path, 'labrador2'), 'labrador')\n",
        "save_images(corgi_images2, os.path.join(drive_path, 'corgi2'), 'corgi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClB9-zM4fGNx",
        "outputId": "a7af8175-f2df-4362-d221-0e0215af6bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Dictionary: {'bulldog': 0, 'corgi': 1, 'dachshund': 2, 'labrador': 3}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_list = [\"bulldog\", \"corgi\", \"dachshund\", \"labrador\"]\n",
        "\n",
        "# 将列表转换为字典，键是标签，值是索引\n",
        "class_dict = {class_name: index for index, class_name in enumerate(class_list)}\n",
        "\n",
        "# 打印转换后的字典\n",
        "print(\"Class Dictionary:\", class_dict)\n",
        "class_dict['bulldog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GwhB5ObypD"
      },
      "source": [
        "create random pairs of bulldog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-q9MMaxtcQ",
        "outputId": "e613c57a-2c52-4e32-c420-daa56f69c1b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 697747.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/bulldog/bulldog_2213.png',\n",
              "  '/content/SpawriousImages/bulldog2/bulldog_2962.png'),\n",
              " 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder1_path = \"/content/SpawriousImages/bulldog\"\n",
        "folder2_path = \"/content/SpawriousImages/bulldog2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # Randomly pair\n",
        "    bulldog_image_pairs.append((image_pair, class_dict['bulldog']))\n",
        "\n",
        "bulldog_image_pairs[200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lJvdadb88y"
      },
      "source": [
        "create random pairs of corgi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8hN7jvyClr",
        "outputId": "95523183-db68-4d8e-dee9-6b4275c1ec7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 817519.62it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_208.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_3064.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/corgi\"\n",
        "folder2_path = \"/content/SpawriousImages/corgi2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "corgi_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, class_dict['corgi']))\n",
        "\n",
        "corgi_image_pairs[1093]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwyYjK7cDoq"
      },
      "source": [
        "create random pairs of dachshund"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4alSoc414EiM",
        "outputId": "de3c8564-b5d9-4dbd-87eb-f64d0cd25426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 800262.29it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/dachshund/dachshund_2053.png',\n",
              "  '/content/SpawriousImages/dachshund2/dachshund_1682.png'),\n",
              " 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/dachshund\"\n",
        "folder2_path = \"/content/SpawriousImages/dachshund2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "# 将文件名转换为完整的文件路径\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, class_dict['dachshund']))\n",
        "\n",
        "dachshund_image_pairs[100]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VW1QOicJPa"
      },
      "source": [
        "Create random pairs of labrador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcVbDd94K2U",
        "outputId": "ba1ae18c-d68b-4151-8c77-74a069314f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 733835.26it/s]\n"
          ]
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/labrador\"\n",
        "folder2_path = \"/content/SpawriousImages/labrador2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, class_dict['labrador']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fejvc8A3cM7p"
      },
      "source": [
        "merge all four classes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBx_U4Dw4Tpe",
        "outputId": "4f6c1004-2f97-4611-ded4-a06ede1873d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_2342.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_2470.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = labrador_image_pairs + dachshund_image_pairs + corgi_image_pairs + bulldog_image_pairs\n",
        "\n",
        "# 打乱合并后的列表\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "training_data[981]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1hM69h4ZxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 明确指定数组的数据类型为 object\n",
        "training_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# 指定保存文件的路径和文件名\n",
        "save_path = \"/content/training_data.npy\"\n",
        "\n",
        "# 将 NumPy 数组保存为 .npy 文件\n",
        "np.save(save_path, training_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCZHUx14Z3I",
        "outputId": "18ca66d3-0b33-41fa-de18-91c66657593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (25344, 2)\n",
            "Size: 50688\n",
            "[('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            " 3]\n",
            "('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            "/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加载 .npy 文件\n",
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# 查看数组的形状和大小\n",
        "print(\"Shape:\", array.shape)\n",
        "print(\"Size:\", array.size)\n",
        "\n",
        "\n",
        "print(array[1])\n",
        "print(array[1][0])\n",
        "print(array[1][0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check an example\n"
      ],
      "metadata": {
        "id": "70s-6zucXos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Axn7L7Sqruo",
        "outputId": "578daa98-81ed-4e89-deb7-97b93674d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png'),\n",
              "       3], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "array[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "942VqoXnP0OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image_paths = sample[0]\n",
        "        label = sample[1]\n",
        "        images = [Image.open(path) for path in image_paths]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ip1/training_data_easy.npy\"\n",
        "custom_dataset = CustomDataset(data_path, transform=transform)\n",
        "trainloader = DataLoader(custom_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezAlnNFwESe",
        "outputId": "1bff5902-46d5-466a-f900-5aaa006b432e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EI82mktkohs"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJN4vrei4Ag",
        "outputId": "a8a5a118-71f5-4f8a-e94e-12f6841a9b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "([tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]]), tensor([[[ 0.2967,  0.1426, -0.0116,  ..., -1.7240, -1.9467,  2.1462],\n",
            "         [ 0.4337,  0.5193,  0.0741,  ...,  2.1462,  1.9235,  1.9920],\n",
            "         [ 0.4337,  0.5193,  0.1426,  ...,  2.0777,  1.9920,  1.8550],\n",
            "         ...,\n",
            "         [ 2.1975,  1.8208,  1.6667,  ..., -1.6727, -1.5870, -1.5870],\n",
            "         [ 1.8893,  1.4440,  1.3755,  ...,  1.8893,  2.0434, -2.1179],\n",
            "         [ 1.5982,  1.4440,  1.3755,  ...,  1.8208,  1.8208,  1.9749]],\n",
            "\n",
            "        [[ 2.3060,  2.2360,  1.9909,  ...,  0.2052, -0.2675, -0.4951],\n",
            "         [-1.9307, -2.0182,  1.9909,  ..., -0.4251, -0.7402, -0.6527],\n",
            "         [-1.9307, -2.0182,  2.1485,  ..., -0.5826, -0.6527, -0.9678],\n",
            "         ...,\n",
            "         [-1.3179, -1.8606,  2.3761,  ..., -0.8452, -0.7752, -0.6176],\n",
            "         [-1.9482,  2.1485,  1.9209,  ..., -1.8606, -1.7031, -1.3880],\n",
            "         [ 2.3060,  2.0609,  1.9209,  ..., -2.0182, -2.0182, -1.8606]],\n",
            "\n",
            "        [[-0.8981, -1.0550, -1.2119,  ...,  1.5594,  1.0888,  0.8622],\n",
            "         [-0.6541, -0.7413, -1.2119,  ...,  1.0191,  0.6182,  0.7054],\n",
            "         [-0.6541, -0.7413, -1.0550,  ...,  0.7751,  0.7751,  0.4614],\n",
            "         ...,\n",
            "         [ 0.0605, -0.4798, -0.7064,  ...,  0.6182,  0.7576,  0.7576],\n",
            "         [-0.4798, -0.9330, -1.2467,  ..., -0.3927, -0.0790, -0.0092],\n",
            "         [-0.7064, -1.0201, -1.2467,  ..., -0.6367, -0.4798, -0.4798]]])], 1)\n"
          ]
        }
      ],
      "source": [
        "# 数据集的长度，一共有25344对图像\n",
        "print(len(custom_dataset))\n",
        "\n",
        "\n",
        "print(custom_dataset[3])\n",
        "\n",
        "# pairs\n",
        "#print(custom_dataset[3][0])\n",
        "\n",
        "# label\n",
        "#print(custom_dataset[3][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPLwSINk_IW"
      },
      "outputs": [],
      "source": [
        "batch_size= 10\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwbKV4Ay7Rq",
        "outputId": "98059a33-0549-48c3-a035-348232838ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]])\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(trainloader))\n",
        "first_data = first_batch[0][0]  # 获取第一个数据样本\n",
        "print(first_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ83k-aWJrgv"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhU_0iIXJqpZ",
        "outputId": "4e97126e-6c72-43b0-cc6f-3462131d3cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "2535\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n",
        "print(len(trainloader))\n",
        "print(type(trainloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIKQNL6rpCw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Erge4frq72"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZFFBiirq-R",
        "outputId": "3dc54f4b-67a6-4e40-e482-55c7405ba0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQM3HHBKFiE"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuuWRMBrrAY",
        "outputId": "15e1819c-fa7d-49ab-b944-d5f5110459b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "last_fc_layer = model.fc\n",
        "\n",
        "input_features = last_fc_layer.in_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqf7iroOwvq2",
        "outputId": "e133fb06-9868-4912-e836-80b9f9f293d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全连接层结构： Linear(in_features=512, out_features=4, bias=True)\n",
            "全连接层权重形状： torch.Size([4, 512])\n",
            "全连接层偏置形状： torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "fc_layer = model.fc\n",
        "\n",
        "print(\"全连接层结构：\", fc_layer)\n",
        "print(\"全连接层权重形状：\", fc_layer.weight.shape)\n",
        "print(\"全连接层偏置形状：\", fc_layer.bias.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1UnM4ToMPXv"
      },
      "source": [
        "Check:(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWh-kHp1vNb",
        "outputId": "dbac08e4-05f8-40f4-d882-200e045c7e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "tensor(1.5868, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, label = next(dataiter)\n",
        "\n",
        "#print(\"Inputs:\", images[0])       # 显示输入数据\n",
        "      # 只处理第一个 batch 后退出循环\n",
        "\n",
        "type(images[0])\n",
        "\n",
        "\n",
        "input_tensor = torch.cat((images[0], images[1]), dim=0)\n",
        "import torch\n",
        "\n",
        "\n",
        "labels = torch.cat((label, label), dim=0)\n",
        "#print(labels)\n",
        "\n",
        "outputs = model(input_tensor)\n",
        "#print(outputs)\n",
        "\n",
        "print(len(outputs))\n",
        "print(len(labels))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jMXI2Dukty",
        "outputId": "04a13456-1823-485e-a009-ce4c51837bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7cd3252a3d60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "test = torch.load('/content/drive/MyDrive/ip/testdata.pt')\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hSVD3wsqim"
      },
      "source": [
        "check an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOpFA1vlUXy",
        "outputId": "022b77ae-f4ec-46ef-c2a4-51696568a29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取第一个 batch\n",
        "first_batch = next(iter(trainloader))\n",
        "\n",
        "# 打印第一个 batch\n",
        "# print(first_batch)\n",
        "\n",
        "print(len(first_batch[0][1]))\n",
        "print(len(first_batch[0][0]))\n",
        "\n",
        "# batch_size个\n",
        "\n",
        "\n",
        "# for i, items in enumerate(trainloader, 0):\n",
        "#  print(i, items)\n",
        "#  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModifiedResNet\n"
      ],
      "metadata": {
        "id": "pgY9MuCX8xzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JeRhqEhNW7D4",
        "outputId": "dd7122f6-a2e1-4418-f1cc-5d7d9edbef4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'first_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b4ede2f49613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.cat((first_batch[0][0], first_batch[0][1]), dim=0)\n",
        "labels = torch.cat((first_batch[1], first_batch[1]), dim=0)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(input_tensor.shape[0])\n",
        "print(labels.shape)\n",
        "#input_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train process"
      ],
      "metadata": {
        "id": "RTaK4QPx86Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdykKpAdrrCz",
        "outputId": "16ca98b5-5d29-4022-ac41-520c242bc1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "11it [07:23, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [11/198], Loss: 1.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:57, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [22/198], Loss: 0.6445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:22, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [33/198], Loss: 0.4303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:54, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [44/198], Loss: 0.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:29, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [55/198], Loss: 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:59, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [66/198], Loss: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:32, 41.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [77/198], Loss: 0.1903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:09, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [88/198], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [99/198], Loss: 0.1815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:02, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [110/198], Loss: 0.1576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:38, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [121/198], Loss: 0.1529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:14, 40.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [132/198], Loss: 0.1419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:45, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [143/198], Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:20, 41.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [154/198], Loss: 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:51, 41.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [165/198], Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:16, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [176/198], Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:39, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [187/198], Loss: 0.0940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:00, 40.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [198/198], Loss: 0.0900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "11it [07:30, 40.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [11/198], Loss: 0.0390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:50, 40.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [22/198], Loss: 0.0359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [33/198], Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:35, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [44/198], Loss: 0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [36:59, 40.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [55/198], Loss: 0.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:22, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [66/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [51:46, 40.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [77/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:10, 40.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [88/198], Loss: 0.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:06:34, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [99/198], Loss: 0.0300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:06, 41.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [110/198], Loss: 0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:21:36, 40.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [121/198], Loss: 0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:07, 40.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [132/198], Loss: 0.0299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:36:37, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [143/198], Loss: 0.0309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:09, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [154/198], Loss: 0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:51:42, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [165/198], Loss: 0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:14, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [176/198], Loss: 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:06:46, 41.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [187/198], Loss: 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:14, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [198/198], Loss: 0.0209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:15, 40.68s/it]\n",
            "11it [07:32, 40.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [11/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:58, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [22/198], Loss: 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:30, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [33/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:55, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [44/198], Loss: 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:20, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [55/198], Loss: 0.0084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:48, 40.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [66/198], Loss: 0.0086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:14, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [77/198], Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:48, 40.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [88/198], Loss: 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:16, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [99/198], Loss: 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:49, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [110/198], Loss: 0.0072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:17, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [121/198], Loss: 0.0077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:46, 40.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [132/198], Loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:18, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [143/198], Loss: 0.0064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:43, 40.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [154/198], Loss: 0.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:10, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [165/198], Loss: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:40, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [176/198], Loss: 0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:06, 40.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [187/198], Loss: 0.0068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:33, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [198/198], Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:34, 40.78s/it]\n",
            "11it [07:41, 41.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [11/198], Loss: 0.0058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:13, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [22/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:44, 40.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [33/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:16, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [44/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:40, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [55/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:09, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [66/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:35, 40.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [77/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:10, 41.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [88/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [99/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:13, 41.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [110/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:47, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [121/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:16, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [132/198], Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:43, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [143/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:16, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [154/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:45, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [165/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:13, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [176/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:50, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [187/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:26, 41.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [198/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:27, 41.05s/it]\n",
            "11it [07:41, 41.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [11/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:20, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [22/198], Loss: 0.0048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:58, 41.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [33/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:37, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [44/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [55/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:50, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [66/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:27, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [77/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:01:08, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [88/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:39, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [99/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:16, 41.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [110/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:52, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [121/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:20, 40.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [132/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:53, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [143/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:27, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [154/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:04, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [165/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:42, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [176/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:21, 41.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [187/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:56, 41.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [198/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:57, 41.50s/it]\n",
            "11it [07:44, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [11/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:25, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [22/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [33/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:34, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [44/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:05, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [55/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:32, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [66/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:05, 41.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [77/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:39, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [88/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:15, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [99/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:47, 40.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [110/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:19, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [121/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:55, 41.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [132/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:29, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [143/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:06, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [154/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:43, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [165/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:11, 40.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [176/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:42, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [187/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:24, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [198/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:25, 41.34s/it]\n",
            "11it [07:35, 40.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [11/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:06, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [22/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:47, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [33/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:19, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:57, 41.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [55/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:34, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [66/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:14, 41.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [77/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:47, 41.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [88/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:20, 41.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [99/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:04, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:41, 41.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [121/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:21, 41.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [132/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:39:00, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [143/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:33, 41.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [154/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:02, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [165/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:35, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [176/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:04, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [187/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:42, 41.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [198/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:43, 41.43s/it]\n",
            "11it [07:45, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [11/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:21, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [22/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [33/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:33, 41.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [55/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:46, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [66/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:22, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [77/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:51, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [88/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:14, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [99/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:46, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:22, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [121/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:58, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [132/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:33, 41.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [143/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:11, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [154/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:46, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [165/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [176/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:41, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [187/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "189it [2:10:05, 41.73s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "modified_model=modified_model.to(device)\n",
        "modified_model=modified_model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "            for j in range(batch_size):\n",
        "                y = items[1][j].to(device)           # Class label\n",
        "                images1 = items[0][0][j].to(device)  # First image\n",
        "                images2 = items[0][1][j].to(device)  # Second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                lam_loss = 0.0\n",
        "                for k in range(512):\n",
        "                    w = fc_layer.weight[y, k] ** 2\n",
        "                    dst = (f1[0, k, 0, 0] - f2[0, k, 0, 0]) ** 2\n",
        "                    lam_loss += w * dst\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i+1) %  11== 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/11))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/model_weights_output_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLMZjBCqaZ6"
      },
      "outputs": [],
      "source": [
        "training_data = torch.tensor(data)\n",
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIsQ3KbelCN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/ip/model_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For similar pairs:"
      ],
      "metadata": {
        "id": "WuiZXWkG9DYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8dm1j-oLek0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        images = sample[0]\n",
        "        label = sample[1]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hHEyvVUR1FiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b51c3e5-223b-49ed-8850-59bade14672f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNWe9eClKJiM",
        "outputId": "b6d20052-16ce-404d-e6f1-711a633c9d27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBGtMHhpzKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dachshund_medium2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium2.npy')\n",
        "dachshund_medium1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium1.npy')\n",
        "bulldog_medium1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium1.npy')\n",
        "bulldog_medium2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium2.npy')\n",
        "corgi_medium1 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium1.npy')\n",
        "corgi_medium2 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium2.npy')\n",
        "labrador_medium2 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium2.npy')\n",
        "labrador_medium1 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium1.npy')\n",
        "\n",
        "labrador_medium = np.concatenate((labrador_medium1, labrador_medium2), axis=0)\n",
        "bulldog_medium = np.concatenate((bulldog_medium1, bulldog_medium2), axis=0)\n",
        "corgi_medium = np.concatenate((corgi_medium1, corgi_medium2), axis=0)\n",
        "dachshund_medium = np.concatenate((dachshund_medium1, dachshund_medium2), axis=0)\n",
        "\n",
        "data_medium = np.concatenate((labrador_medium, bulldog_medium, corgi_medium, dachshund_medium), axis=0)\n",
        "training_data_medium = torch.tensor(data_medium)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-y4fDJnxWmP"
      },
      "outputs": [],
      "source": [
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.load('/content/drive/MyDrive/ip1/training_data_hard.npy')"
      ],
      "metadata": {
        "id": "quVzjbVK3c_l"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lipfY6ZIuxro",
        "outputId": "5e22fc5a-20b6-4bc7-c9a9-c00ab0d6fad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "           1.4611696 ,  1.4611696 ],\n",
              "         ...,\n",
              "         [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "          -0.37117907, -0.37117907],\n",
              "         [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "          -0.38830382, -0.38830382],\n",
              "         [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "          -0.38830382, -0.37117907]],\n",
              " \n",
              "        [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         ...,\n",
              "         [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "          -0.35504198, -0.35504198],\n",
              "         [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897],\n",
              "         [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897]],\n",
              " \n",
              "        [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "           2.1519828 ,  2.2042704 ],\n",
              "         [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         ...,\n",
              "         [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "          -0.21838771, -0.21838771],\n",
              "         [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.23581691],\n",
              "         [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              " array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "           0.72480524,  0.74193   ],\n",
              "         [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "           0.74193   ,  0.7590547 ],\n",
              "         [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "           0.7761795 ,  0.7761795 ],\n",
              "         ...,\n",
              "         [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "          -1.5699118 , -1.5699118 ],\n",
              "         [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "          -1.5699118 , -1.5527872 ],\n",
              "         [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "          -1.5870366 , -1.5356624 ]],\n",
              " \n",
              "        [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "           0.87044823,  0.88795525],\n",
              "         [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "           0.88795525,  0.90546227],\n",
              "         [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "           0.9229692 ,  0.9229692 ],\n",
              "         ...,\n",
              "         [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "          -1.4754901 , -1.4754901 ],\n",
              "         [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "          -1.4754901 , -1.457983  ],\n",
              "         [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "          -1.4929972 , -1.4404761 ]],\n",
              " \n",
              "        [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "           1.0888019 ,  1.1062311 ],\n",
              "         [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "           1.1062311 ,  1.1236603 ],\n",
              "         [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "           1.1410894 ,  1.1410894 ],\n",
              "         ...,\n",
              "         [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "          -1.2467101 , -1.2467101 ],\n",
              "         [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "          -1.2467101 , -1.229281  ],\n",
              "         [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "          -1.2641394 , -1.2118517 ]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 将每个 data 转换为所需的形式\n",
        "training_data = [transform_data(data) for data in training_data]\n",
        "training_data[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T872dSn4qXrP",
        "outputId": "96f82541-3f55-454b-cf75-e35f6b475709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[-0.4739, -0.4911, -0.5082,  ..., -0.6623, -0.6452, -0.6452],\n",
              "          [-0.4911, -0.4739, -0.4568,  ..., -0.6623, -0.6623, -0.6452],\n",
              "          [-0.4397, -0.4054, -0.3883,  ..., -0.6623, -0.6794, -0.6452],\n",
              "          ...,\n",
              "          [-1.5528, -0.6452,  0.0056,  ...,  1.0331,  1.4783,  1.0844],\n",
              "          [-1.0733, -0.7822, -1.4672,  ...,  0.9646,  1.4783,  1.3070],\n",
              "          [-1.2103, -1.4500, -1.7583,  ...,  0.6049,  1.4783,  1.3413]],\n",
              " \n",
              "         [[ 0.6254,  0.6429,  0.6429,  ...,  0.3277,  0.3627,  0.3627],\n",
              "          [ 0.6604,  0.6779,  0.6429,  ...,  0.3277,  0.3277,  0.3102],\n",
              "          [ 0.6779,  0.6954,  0.6779,  ...,  0.3277,  0.3627,  0.3803],\n",
              "          ...,\n",
              "          [-0.7052,  0.2227,  0.5203,  ...,  0.5028,  0.9930,  0.4503],\n",
              "          [-0.3901,  0.0301, -0.5651,  ...,  0.2927,  0.9755,  0.7479],\n",
              "          [-0.7752, -0.9853, -1.2829,  ..., -0.0749,  0.9930,  0.8704]],\n",
              " \n",
              "         [[ 1.1934,  1.2457,  1.2457,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2631,  1.2805,  1.2631,  ...,  0.9145,  0.9145,  0.9145],\n",
              "          [ 1.2980,  1.3154,  1.2980,  ...,  0.9145,  0.9319,  0.9668],\n",
              "          ...,\n",
              "          [-1.1596, -0.3578,  0.2348,  ...,  0.4788,  0.9842,  0.4962],\n",
              "          [-0.5495, -0.3230, -1.1421,  ...,  0.2871,  0.9319,  0.7576],\n",
              "          [-0.7936, -1.1596, -1.5604,  ..., -0.0790,  0.9842,  0.8971]]]),\n",
              " tensor([[[-0.5082, -0.5253, -0.4911,  ...,  1.5639,  1.8037,  1.8379],\n",
              "          [-0.4739, -0.4226, -0.4911,  ...,  1.6667,  1.8550,  1.8722],\n",
              "          [-0.4568, -0.4226, -0.4911,  ...,  1.8550,  1.8208,  1.8037],\n",
              "          ...,\n",
              "          [-1.0904, -0.5082, -0.3541,  ..., -0.5938, -0.7479, -0.3027],\n",
              "          [-1.5528, -1.7069, -1.3644,  ..., -0.6281, -0.5938, -0.6452],\n",
              "          [-1.3644, -1.4329, -1.5528,  ..., -0.2684, -0.4568, -0.9020]],\n",
              " \n",
              "         [[-1.1078, -1.1253, -1.0903,  ...,  1.2556,  1.6758,  1.8158],\n",
              "          [-1.1078, -1.0728, -1.1078,  ...,  1.4307,  1.8859,  1.9559],\n",
              "          [-1.0553, -1.0378, -1.0903,  ...,  1.9034,  1.9034,  1.8158],\n",
              "          ...,\n",
              "          [-1.3880, -1.0203, -1.0378,  ..., -1.0903, -1.2129, -0.8452],\n",
              "          [-1.6681, -1.8782, -1.6506,  ..., -1.1253, -1.1078, -1.2129],\n",
              "          [-1.5455, -1.4755, -1.5980,  ..., -0.7752, -0.9853, -1.4230]],\n",
              " \n",
              "         [[-0.8807, -0.8807, -0.8458,  ...,  1.2108,  1.6291,  1.8208],\n",
              "          [-0.8458, -0.8458, -0.8458,  ...,  1.3851,  1.8905,  1.9603],\n",
              "          [-0.8110, -0.7936, -0.8284,  ...,  1.9428,  1.9951,  1.8557],\n",
              "          ...,\n",
              "          [-0.9330, -0.7761, -0.6890,  ..., -0.7761, -0.9156, -0.5670],\n",
              "          [-1.4036, -1.5604, -1.3687,  ..., -0.8284, -0.8284, -0.9504],\n",
              "          [-1.3164, -1.2293, -1.3164,  ..., -0.5495, -0.7238, -1.1421]]])]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 使用列表推导式将每个 data 转换为所需的形式\n",
        "training_data_medium = [transform_data(data) for data in training_data_medium]\n",
        "training_data_medium[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTtNaRpmCpd",
        "outputId": "97e63415-5c40-4883-bc00-8c62e042d84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 定义每个类别的名称和数量\n",
        "labels = []\n",
        "\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(508):\n",
        "    labels.extend([3])  # 前508个为3\n",
        "for _ in range(508):\n",
        "    labels.extend([0])  # 508-508*2为0\n",
        "for _ in range(508):\n",
        "    labels.extend([1])  # 508*2-508*3为1\n",
        "for _ in range(508):\n",
        "    labels.extend([2])  # 508*3-508*4为2\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels))  # 应该打印出 2032\n",
        "labels[507]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hS8AgE4pKyv",
        "outputId": "9a22f95f-7493-44aa-94a9-cb110a8170ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train = list(zip(training_data, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train))  # 应该打印出 2032\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bjA_xicqu-q",
        "outputId": "7ee7ddcd-b828-458b-9b5a-9571b30cc089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHc6RZzlfZAD",
        "outputId": "54639128-ebb9-49be-80e2-1070c634cc29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "            1.4611696 ,  1.4611696 ],\n",
              "          ...,\n",
              "          [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "           -0.37117907, -0.37117907],\n",
              "          [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "           -0.38830382, -0.38830382],\n",
              "          [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "           -0.38830382, -0.37117907]],\n",
              "  \n",
              "         [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          ...,\n",
              "          [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "           -0.35504198, -0.35504198],\n",
              "          [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897],\n",
              "          [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897]],\n",
              "  \n",
              "         [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "            2.1519828 ,  2.2042704 ],\n",
              "          [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          ...,\n",
              "          [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "           -0.21838771, -0.21838771],\n",
              "          [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.23581691],\n",
              "          [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              "  array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "            0.72480524,  0.74193   ],\n",
              "          [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "            0.74193   ,  0.7590547 ],\n",
              "          [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "            0.7761795 ,  0.7761795 ],\n",
              "          ...,\n",
              "          [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "           -1.5699118 , -1.5699118 ],\n",
              "          [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "           -1.5699118 , -1.5527872 ],\n",
              "          [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "           -1.5870366 , -1.5356624 ]],\n",
              "  \n",
              "         [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "            0.87044823,  0.88795525],\n",
              "          [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "            0.88795525,  0.90546227],\n",
              "          [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "            0.9229692 ,  0.9229692 ],\n",
              "          ...,\n",
              "          [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "           -1.4754901 , -1.4754901 ],\n",
              "          [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "           -1.4754901 , -1.457983  ],\n",
              "          [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "           -1.4929972 , -1.4404761 ]],\n",
              "  \n",
              "         [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "            1.0888019 ,  1.1062311 ],\n",
              "          [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "            1.1062311 ,  1.1236603 ],\n",
              "          [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "            1.1410894 ,  1.1410894 ],\n",
              "          ...,\n",
              "          [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "           -1.2467101 , -1.2467101 ],\n",
              "          [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "           -1.2467101 , -1.229281  ],\n",
              "          [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "           -1.2641394 , -1.2118517 ]]], dtype=float32)],\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "custom_dataset = CustomDataset(combined_train)\n",
        "custom_dataset[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zihO8aa0cjKh"
      },
      "outputs": [],
      "source": [
        "# 导入需要的库\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "trainloader = DataLoader(custom_dataset, batch_size=127, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SGwJcfPBE2G",
        "outputId": "615f0ca0-cdf4-4d04-e071-d961f00db085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "print(f1.shape)\n",
        "f1_squared = torch.pow(f1, 2)\n",
        "print(f1_squared.shape)\n",
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5a5RVH2yT5G",
        "outputId": "abfb6b9f-5eaa-45c1-c502-2271b45a4617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8c9wMs83eX",
        "outputId": "07840e10-8594-44b7-f34f-7e43503a35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "print(f1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGEKEWSuorD",
        "outputId": "237061d1-0de8-457d-fdc7-743052b7066f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "fc_layer = modified_model.final_layer\n",
        "print(fc_layer.weight.shape)\n",
        "w = fc_layer.weight[1]**2\n",
        "\n",
        "print(w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJHhdBkAIYm",
        "outputId": "a6f09fc0-7e39-4e99-d8fb-8807e06b1517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1103,  0.0845, -1.4639,  0.0241],\n",
            "        [-0.1507, -0.0891, -0.3924,  0.3247]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([1, 3], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "image1 = torch.randn(3, 224, 224)  # 假设图片1的形状为 [3, 224, 224]\n",
        "image2 = torch.randn(3, 224, 224)  # 假设图片2的形状为 [3, 224, 224]\n",
        "\n",
        "input_tensor = torch.cat((image1.unsqueeze(0), image2.unsqueeze(0)), dim=0)\n",
        "input_tensor\n",
        "y=modified_model(input_tensor.to(device))[1]\n",
        "print(y)\n",
        "predicted = torch.argmax(y, dim=1)\n",
        "print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90F789NYgK0e",
        "outputId": "4187a6d6-6602-4769-f781-25b13629f3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.final_layer = list(model.children())[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features_flattened = features.view( x.shape[0], -1)\n",
        "        final_output = self.final_layer(features_flattened)\n",
        "\n",
        "        return features, final_output\n",
        "\n",
        "\n",
        "modified_model = ModifiedResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBmyZK2PrrEX",
        "outputId": "0bc85989-4533-44c7-9a3d-68bfd842b23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [16/16], Loss: 0.5988, Accuracy: 76.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [16/16], Loss: 0.1426, Accuracy: 94.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [16/16], Loss: 0.0642, Accuracy: 97.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [16/16], Loss: 0.0238, Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [16/16], Loss: 0.0125, Accuracy: 99.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [16/16], Loss: 0.0073, Accuracy: 99.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [16/16], Loss: 0.0058, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [16/16], Loss: 0.0056, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [16/16], Loss: 0.0048, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:39,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [16/16], Loss: 0.0045, Accuracy: 100.00%\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 127\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "modified_model=modified_model.to(device).train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "\n",
        "            for j in range(batch_size):\n",
        "\n",
        "                y = items[1][j].to(device)           # jth class label\n",
        "                images1 = items[0][0][j].to(device)  # jth first image\n",
        "                images2 = items[0][1][j].to(device)  # jth second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                w = fc_layer.weight[y] ** 2\n",
        "                diff = torch.squeeze(torch.pow(f1- f2, 2))\n",
        "                lam_loss = torch.sum(torch.mul(diff, w))\n",
        "\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i+1) %  16== 0:\n",
        "                accuracy = 100 * correct / total\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/16, accuracy))\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip1/output_O2O_middle_model/output_O2O_middle_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34hKBm823Sg",
        "outputId": "b0462f28-5efc-4ab2-8dac-b33aae377248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[-1.6213, -1.6727, -2.0665,  ..., -0.3369, -0.3541, -0.3369],\n",
            "         [-1.2445, -1.0904, -1.8782,  ..., -0.3369, -0.3369, -0.3198],\n",
            "         [-1.7240, -1.1075, -1.4329,  ..., -0.3198, -0.3541, -0.3369],\n",
            "         ...,\n",
            "         [-1.5528, -0.9020,  1.0673,  ..., -1.2959, -1.0219, -1.0904],\n",
            "         [ 0.7762,  1.7865,  1.4954,  ..., -1.1418, -1.3473, -1.5699],\n",
            "         [ 1.8379,  0.3481, -0.5767,  ...,  1.5297,  0.2624, -1.2959]],\n",
            "\n",
            "        [[-1.5455, -1.5980, -1.8606,  ...,  0.9755,  0.9405,  0.8880],\n",
            "         [-1.1253, -0.8978, -1.7381,  ...,  0.9755,  0.9580,  0.9055],\n",
            "         [-1.5980, -0.8978, -1.4055,  ...,  0.9930,  0.9755,  0.9230],\n",
            "         ...,\n",
            "         [-1.7556, -0.9503,  1.0280,  ..., -1.3704, -1.0728, -1.0903],\n",
            "         [ 0.7304,  1.7458,  1.5007,  ..., -1.1604, -1.3529, -1.5980],\n",
            "         [ 1.9384,  0.2227, -0.7052,  ...,  1.5882,  0.3627, -1.3354]],\n",
            "\n",
            "        [[-1.4733, -1.5779, -1.6127,  ...,  2.2391,  2.2043,  2.2217],\n",
            "         [-1.1421, -1.0027, -1.7173,  ...,  2.2391,  2.2217,  2.2566],\n",
            "         [-1.5604, -1.0376, -1.5081,  ...,  2.2391,  2.2391,  2.2740],\n",
            "         ...,\n",
            "         [-1.5256, -0.6890,  1.2457,  ..., -0.6890, -0.3753, -0.4101],\n",
            "         [ 0.7751,  1.8731,  1.7163,  ..., -0.0964, -0.6541, -1.0376],\n",
            "         [ 2.0823,  0.5659, -0.5495,  ...,  2.1520,  1.3677, -0.6541]]]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "testdata = torch.load('/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt')\n",
        "len(testdata)\n",
        "print(testdata[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAWgmfNd25rs",
        "outputId": "9c659574-2bf5-4d90-8ecb-29fef5eadc03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/output_O2O_middle_model/output_O2O_middle_epoch_10.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "tEy8VCn39eGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOJujGudYhYa",
        "outputId": "9fe0c61a-f8f4-4ba9-82e5-ca45fc88251f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 198/198 [3:01:03<00:00, 54.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分类任务的准确率: 77.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/output_O2O_middle_model/output_O2O_middle_epoch_10.pth'))\n",
        "modified_model = modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "# 将测试数据集转化为 DataLoader\n",
        "test_loader_medium = DataLoader(testdata, batch_size=128, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = modified_model(images)[1]\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v01aSR00LqpI",
        "outputId": "a500650e-6281-4fc4-f3b4-e62cc78fdf74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25344"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "testdata_medium = torch.load('/content/drive/MyDrive/ip/testdata_medium.pt')\n",
        "len(testdata_medium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1ygIB_HDyY",
        "outputId": "12c8fef2-8817-435e-bd66-336564f8ea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [3:22:21<00:00, 61.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分类任务的准确率: 75.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "\n",
        "# 加载.pt文件\n",
        "\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = modified_model(images)[1]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n",
        "0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28HS3FWGtR8s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset:\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index][0], self.data[index][1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_tensor(self):\n",
        "        tensor_data = []\n",
        "        for image, label in self.data:\n",
        "            tensor_data.append((torch.tensor(image), label))\n",
        "\n",
        "        return tensor_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hFvXsW8SrYFM",
        "outputId": "a7ffd795-e2a5-499c-b0be-f80562e9f7a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c8bbd58e4b7a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ip/training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtensor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),                     # 调整图像短边至 256 像素\n",
        "    transforms.CenterCrop(224),                 # 中心裁剪图像为 224x224\n",
        "    transforms.ToTensor(),                      # 转换图像为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像数据\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 加载自定义数据集\n",
        "dataset = CustomDataset(npy_file=\"/content/drive/MyDrive/ip/training_data.npy\", transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 创建 DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztB9GY4v4yo",
        "outputId": "3392943a-290f-4547-8cb4-cef983a10d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Type: <class '__main__.CustomDataset'>\n",
            "Dataset Dimension: (25344, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset_type = type(dataset)\n",
        "print(\"Dataset Type:\", dataset_type)\n",
        "\n",
        "# 获取数据集的维度\n",
        "dataset_dimension = dataset.data.shape\n",
        "print(\"Dataset Dimension:\", dataset_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EOBx1nCxuCsC",
        "outputId": "ac4a35e3-ae9c-450d-84a0-d76fc73641c0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unexpected type <class 'tuple'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d57b01628137>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 获取 DataLoader 中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 打印第一个批次的输入数据和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected type {type(img)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'tuple'>"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch 是一个列表，包含了一个批次的样本数据\n",
        "    # 在这里你可以自定义处理逻辑，将样本转换为张量形式\n",
        "\n",
        "    # 假设 batch 中的每个元素是一个元组，其中包含输入数据和对应的标签\n",
        "    inputs = [item[0] for item in batch]  # 提取输入数据\n",
        "    labels = [item[1] for item in batch]  # 提取标签\n",
        "\n",
        "    # 将输入数据和标签转换为张量形式\n",
        "    inputs_tensor = torch.tensor(inputs)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    return inputs_tensor, labels_tensor\n",
        "\n",
        "# 定义 DataLoader，指定 collate_fn 参数为自定义的 collate_fn 函数\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 获取 DataLoader 中的数据\n",
        "inputs, labels = next(iter(data_loader))\n",
        "\n",
        "# 打印第一个批次的输入数据和标签\n",
        "print(\"First Batch Inputs:\", inputs)\n",
        "print(\"First Batch Labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsUjsKgl-2i",
        "outputId": "012f56c5-3a7e-4912-ad02-2443ff0d8f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (25344, 2)\n",
            "Train Y shape: (25344,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for element in array:\n",
        "\n",
        "    sample, label = element\n",
        "\n",
        "    train_x.append(sample)\n",
        "    train_y.append(label)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHRm6Ylmz7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpL-8JSj55R",
        "outputId": "9512c9a5-a704-4b99-b006-6df0900056bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('corgi_2105.png', 'corgi_954.png'), 'corgi'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYXYu7OrxQc",
        "outputId": "bfdbc041-8821-4b96-9dc4-c915662440e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder contains 3168 images.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# 指定文件夹路径\n",
        "folder_path = '/content/drive/MyDrive/ip/SpawriousImages/bulldog'\n",
        "\n",
        "# 使用glob.glob获取所有图片文件的路径，并计算数量\n",
        "num_images = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
        "print(f'The folder contains {num_images} images.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFzy3YrH9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rx8CzfX9rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGjjkXis9rpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce:\n"
      ],
      "metadata": {
        "id": "r69Yy9KS9r3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFjpaL71qgR",
        "outputId": "25c3c22d-1295-431c-de66-aeedc0711426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3864667587  0.3897000789  0.3901163938  0.3981846882  0.3810416256  0.4013417522  0.0000000000  1.5313433409  5.6991815567  0             27.390903472 \n",
            "0.7663247189  0.7667719021  0.9904320379  0.9861878453  0.9788913001  0.9668508287  1.2625764451  0.1483003787  5.7843055725  100           0.6112645364 \n",
            "0.7623791675  0.7582872928  0.9927993687  0.9881610103  0.9869796804  0.9798737174  2.5251528901  0.0304591087  5.7843055725  200           0.6120824623 \n",
            "0.8103176169  0.8086029992  0.9964490037  0.9881610103  0.9929966463  0.9798737174  3.7877293352  0.0201038574  5.7843055725  300           0.6128335547 \n",
            "0.7342177944  0.7229676401  0.9921088972  0.9881610103  0.9876701519  0.9731649566  5.0503057802  0.0166535372  5.7843055725  400           0.6066111851 \n",
            "0.7267705662  0.7213891081  0.9958571710  0.9909234412  0.9922075360  0.9763220205  6.3128822253  0.0185868401  5.7843055725  500           0.6118927002 \n",
            "0.7765831525  0.7778216259  0.9984217794  0.9925019732  0.9967449201  0.9818468824  7.5754586703  0.0134620355  5.7843055725  600           0.6051793170 \n",
            "0.7576938252  0.7480268350  0.9978299467  0.9936858721  0.9957585323  0.9842146803  8.8380351154  0.0087729464  5.7843055725  700           0.6085211968 \n",
            "0.7600611560  0.7563141279  0.9984217794  0.9925019732  0.9962517262  0.9818468824  10.100611560  0.0123126021  5.7843055725  800           0.6048365140 \n",
            "0.7093115013  0.7091554854  0.9961530874  0.9885556433  0.9950680608  0.9818468824  11.363188005  0.0064040128  5.7843055725  900           0.6142849422 \n",
            "0.7815150917  0.7792028414  0.9968435589  0.9901341752  0.9906293154  0.9790844515  12.625764450  0.0093996652  5.7843055725  1000          0.6039929366 \n",
            "0.7462024068  0.7490134175  0.9994081673  0.9921073402  0.9986190570  0.9834254144  13.888340895  0.0092029764  5.7843055725  1100          0.6129468703 \n",
            "0.8009469323  0.7959747435  0.9992108897  0.9928966062  0.9991122509  0.9857932123  15.150917340  0.0058361374  5.7843055725  1200          0.6129310250 \n",
            "0.7381633458  0.7391475927  0.9972381140  0.9897395422  0.9964490037  0.9802683504  16.413493785  0.0065432409  5.7843055725  1300          0.6122647572 \n",
            "0.6935292957  0.6906077348  0.9981258631  0.9913180742  0.9978299467  0.9802683504  17.676070230  0.0046631041  5.7843055725  1400          0.6144099188 \n",
            "0.6489938844  0.6475927388  0.9986190570  0.9940805051  0.9951666995  0.9786898185  18.938646675  0.0084209092  5.7843055725  1500          0.6136151099 \n",
            "0.7438350760  0.7450670876  0.9994081673  0.9913180742  0.9993095285  0.9869771113  20.201223120  0.0082047096  5.7843055725  1600          0.6134618235 \n",
            "0.7649437759  0.7588792423  0.9970408365  0.9885556433  0.9971394752  0.9794790845  21.463799566  0.0020670449  5.7843055725  1700          0.6151823425 \n",
            "0.8479976327  0.8433307024  0.9973367528  0.9893449092  0.9966462813  0.9767166535  22.726376011  0.0058088228  5.7843055725  1800          0.6114165998 \n",
            "0.7854113237  0.7847277032  0.9984217794  0.9921073402  0.9957585323  0.9814522494  23.988952456  0.0053677419  5.7843055725  1900          0.6099036169 \n",
            "0.7859538370  0.7786108919  0.9989149734  0.9917127072  0.9975340304  0.9834254144  25.251528901  0.0037218446  5.7843055725  2000          0.6132613826 \n",
            "0.6918524364  0.6793606946  0.9976326692  0.9897395422  0.9973367528  0.9830307814  26.514105346  0.0072307730  5.7843055725  2100          0.6134376049 \n",
            "0.7332314066  0.7269139700  0.9992108897  0.9948697711  0.9986190570  0.9802683504  27.776681791  0.0073834352  5.7843055725  2200          0.6204751110 \n",
            "0.7945847307  0.7878847672  0.9979285855  0.9913180742  0.9969421977  0.9818468824  29.039258236  0.0084000665  5.7843055725  2300          0.6125090265 \n",
            "0.7764845137  0.7647987372  1.0000000000  0.9917127072  0.9999013612  0.9834254144  30.301834681  0.0061496431  5.7843055725  2400          0.6324354410 \n",
            "0.6687216413  0.6590370955  0.9953639771  0.9834254144  0.9920102584  0.9767166535  31.564411126  0.0049843378  5.7843055725  2500          0.6270753837 \n",
            "0.7318011442  0.7241515391  0.9984217794  0.9889502762  0.9978299467  0.9814522494  32.826987571  0.0057329830  5.7843055725  2600          0.6227247167 \n",
            "0.7836851450  0.7756511444  0.9999013612  0.9944751381  0.9992108897  0.9838200474  34.089564016  0.0009479631  5.7843055725  2700          0.6132366180 \n",
            "0.7607023081  0.7576953433  0.9985204182  0.9925019732  0.9973367528  0.9802683504  35.352140461  0.0028693231  5.7843055725  2800          0.6186019158 \n",
            "0.7607516275  0.7513812155  0.9984217794  0.9885556433  0.9939830341  0.9767166535  36.614716906  0.0079865522  5.7843055725  2900          0.6299188948 \n",
            "0.7857072401  0.7758484609  0.9998027224  0.9909234412  0.9995068061  0.9846093133  37.877293351  0.0030832417  5.7843055725  3000          0.6098960829 \n",
            "0.7091635431  0.6939621152  0.9978299467  0.9885556433  0.9969421977  0.9771112865  39.139869796  0.0061063865  5.7843055725  3100          0.6046432948 \n",
            "0.7215427106  0.7095501184  0.9965476425  0.9893449092  0.9955612547  0.9806629834  40.402446241  0.0045622018  5.7843055725  3200          0.6033505225 \n",
            "0.7802821069  0.7715074980  0.9998027224  0.9925019732  0.9990136122  0.9881610103  41.665022686  0.0067104823  5.7843055725  3300          0.6084430003 \n",
            "0.7143420793  0.7109313339  0.9959558098  0.9869771113  0.9970408365  0.9782951855  42.927599132  0.0011498852  5.7843055725  3400          0.6063428593 \n",
            "0.6730124285  0.6653512234  0.9973367528  0.9889502762  0.9950680608  0.9739542226  44.190175577  0.0085864400  5.7843055725  3500          0.6008972216 \n",
            "0.6958966266  0.6898184688  0.9998027224  0.9921073402  0.9996054449  0.9857932123  45.452752022  0.0064733884  5.7843055725  3600          0.6162673044 \n",
            "0.7082757940  0.7028413575  1.0000000000  0.9956590371  0.9999013612  0.9889502762  46.715328467  0.0012216950  5.7843055725  3700          0.6148056483 \n",
            "0.7186328664  0.7099447514  1.0000000000  0.9944751381  1.0000000000  0.9889502762  47.977904912  0.0000642128  5.7843055725  3800          0.6070259309 \n",
            "0.7200631288  0.7113259669  0.9997040836  0.9921073402  0.9998027224  0.9861878453  49.240481357  0.0027398469  5.7843055725  3900          0.6156265235 \n",
            "0.7058591438  0.7091554854  0.9995068061  0.9940805051  0.9994081673  0.9881610103  50.503057802  0.0021378895  5.7843055725  4000          0.6109139323 \n",
            "0.6887453147  0.6779794791  0.9994081673  0.9917127072  0.9993095285  0.9861878453  51.765634247  0.0059131746  5.7843055725  4100          0.6170952582 \n",
            "0.6611757743  0.6572612470  0.9973367528  0.9913180742  0.9970408365  0.9806629834  53.028210692  0.0104169882  5.7843055725  4200          0.6217965150 \n",
            "0.6604853028  0.6515390687  0.9982245019  0.9905288082  0.9955612547  0.9763220205  54.290787137  0.0042702924  5.7843055725  4300          0.6096786547 \n",
            "0.7143913987  0.7036306235  0.9992108897  0.9936858721  0.9978299467  0.9802683504  55.553363582  0.0065798409  5.7843055725  4400          0.6024882984 \n",
            "0.7114815545  0.7056037885  0.9999013612  0.9952644041  0.9997040836  0.9917127072  56.815940027  0.0049846871  5.7843055725  4500          0.6199430537 \n",
            "0.6791773525  0.6659431728  0.9992108897  0.9928966062  0.9990136122  0.9806629834  58.078516472  0.0005054018  5.7843055725  4600          0.6146416759 \n",
            "0.7630203196  0.7582872928  0.9999013612  0.9956590371  1.0000000000  0.9869771113  59.341092917  0.0010236725  5.7843055725  4700          0.6122219038 \n",
            "0.7570033537  0.7513812155  0.9999013612  0.9952644041  0.9999013612  0.9881610103  60.603669362  0.0000619924  5.7843055725  4800          0.6136543655 \n",
            "0.6861807063  0.6712707182  0.9983231407  0.9889502762  0.9973367528  0.9810576164  61.866245807  0.0034500310  5.7843055725  4900          0.6070861173 \n",
            "0.6905208128  0.6902131018  0.9999013612  0.9952644041  0.9989149734  0.9822415154  63.128822252  0.0057498560  5.7843055725  5000          0.6079993272 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647,\\\n",
        "        \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLCqJpRpZla",
        "outputId": "1a0e5102-ef83-43f2-d0eb-2034bc3093f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        71.1 +/- 0.0               71.1                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        69.1 +/- 0.0               69.1                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSJ6vNQiFYD",
        "outputId": "6a81e146-dd33-456a-c9e6-95da2b3fd601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_medium/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 107MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3137699744  0.3155090766  0.4236535806  0.4340962904  0.4138883409  0.4352801894  0.0000000000  1.5721870661  5.6991815567  0             121.17406868 \n",
            "0.6615210101  0.6598263615  0.9904320379  0.9889502762  0.9813572697  0.9790844515  1.2625764451  0.1269948081  5.7843055725  100           0.5992083979 \n",
            "0.6557999605  0.6521310182  0.9934898402  0.9928966062  0.9871769580  0.9810576164  2.5251528901  0.0242757843  5.7843055725  200           0.6010344815 \n",
            "0.7217893076  0.7209944751  0.9941803117  0.9901341752  0.9905306767  0.9822415154  3.7877293352  0.0248986174  5.7843055725  300           0.6032668781 \n",
            "0.6864766226  0.6795580110  0.9990136122  0.9976322021  0.9960544486  0.9857932123  5.0503057802  0.0148176499  5.7843055725  400           0.6020192647 \n",
            "0.7547346617  0.7531570639  0.9977313080  0.9940805051  0.9947721444  0.9857932123  6.3128822253  0.0099429032  5.7843055725  500           0.6023221374 \n",
            "0.6849477214  0.6823204420  0.9983231407  0.9960536701  0.9959558098  0.9822415154  7.5754586703  0.0127289780  5.7843055725  600           0.5986590838 \n",
            "0.6821365161  0.6754143646  0.9976326692  0.9940805051  0.9963503650  0.9853985793  8.8380351154  0.0070593210  5.7843055725  700           0.5992206550 \n",
            "0.7350562241  0.7342146803  0.9992108897  0.9964483031  0.9980272243  0.9877663773  10.100611560  0.0090081152  5.7843055725  800           0.5954315782 \n",
            "0.6724699152  0.6637726914  0.9995068061  0.9956590371  0.9983231407  0.9877663773  11.363188005  0.0071447303  5.7843055725  900           0.5991444755 \n",
            "0.7353521405  0.7310576164  0.9983231407  0.9964483031  0.9978299467  0.9873717443  12.625764450  0.0082690991  5.7843055725  1000          0.6007423878 \n",
            "0.7047247978  0.6971191792  0.9989149734  0.9952644041  0.9990136122  0.9861878453  13.888340895  0.0095554909  5.7843055725  1100          0.5999678946 \n",
            "0.7175478398  0.7115232833  0.9984217794  0.9956590371  0.9976326692  0.9850039463  15.150917340  0.0074848697  5.7843055725  1200          0.6209489059 \n",
            "0.6003156441  0.5935280189  0.9908265930  0.9846093133  0.9845137108  0.9739542226  16.413493785  0.0061670831  5.7843055725  1300          0.6227960443 \n",
            "0.7109883606  0.6983030781  0.9990136122  0.9932912391  0.9984217794  0.9877663773  17.676070230  0.0095289110  5.7843055725  1400          0.6323509693 \n",
            "0.7592227264  0.7523677979  0.9981258631  0.9956590371  0.9963503650  0.9846093133  18.938646675  0.0060454098  5.7843055725  1500          0.6389152265 \n",
            "0.7201617676  0.7127071823  0.9993095285  0.9956590371  0.9986190570  0.9889502762  20.201223120  0.0078355287  5.7843055725  1600          0.6430245256 \n",
            "0.7292858552  0.7211917916  0.9998027224  0.9956590371  0.9997040836  0.9925019732  21.463799566  0.0018214593  5.7843055725  1700          0.6293191934 \n",
            "0.7227756954  0.7123125493  0.9999013612  0.9968429361  0.9999013612  0.9893449092  22.726376011  0.0015204751  5.7843055725  1800          0.6129930377 \n",
            "0.6896823831  0.6892265193  0.9999013612  0.9964483031  0.9998027224  0.9897395422  23.988952456  0.0028037445  5.7843055725  1900          0.6100966716 \n",
            "0.7653383310  0.7582872928  0.9993095285  0.9964483031  0.9994081673  0.9932912391  25.251528901  0.0004546101  5.7843055725  2000          0.6023241353 \n",
            "0.7000887749  0.6896211523  0.9985204182  0.9936858721  0.9977313080  0.9865824783  26.514105346  0.0064458975  5.7843055725  2100          0.5988242507 \n",
            "0.6427303216  0.6410812944  0.9988163346  0.9968429361  0.9988163346  0.9873717443  27.776681791  0.0060048382  5.7843055725  2200          0.5992763162 \n",
            "0.7598638785  0.7527624309  1.0000000000  0.9988161010  0.9998027224  0.9905288082  29.039258236  0.0023152082  5.7843055725  2300          0.5971370530 \n",
            "0.6899289801  0.6874506709  0.9981258631  0.9913180742  0.9959558098  0.9873717443  30.301834681  0.0050733112  5.7843055725  2400          0.5996246147 \n",
            "0.7281515092  0.7239542226  0.9898402052  0.9767166535  0.9817518248  0.9723756906  31.564411126  0.0072616203  5.7843055725  2500          0.5943894243 \n",
            "0.7001380943  0.6992896606  0.9995068061  0.9956590371  0.9988163346  0.9881610103  32.826987571  0.0440309145  5.7843055725  2600          0.6050425506 \n",
            "0.7320970606  0.7237569061  0.9992108897  0.9956590371  0.9990136122  0.9905288082  34.089564016  0.0048803466  5.7843055725  2700          0.6109957647 \n",
            "0.6917044782  0.6831097080  0.9991122509  0.9932912391  0.9984217794  0.9846093133  35.352140461  0.0067349893  5.7843055725  2800          0.6111056709 \n",
            "0.7432432432  0.7421073402  1.0000000000  0.9984214680  0.9995068061  0.9893449092  36.614716906  0.0033565566  5.7843055725  2900          0.6050006723 \n",
            "0.6926415467  0.6876479874  0.9998027224  0.9952644041  0.9990136122  0.9857932123  37.877293351  0.0042016615  5.7843055725  3000          0.6177810144 \n",
            "0.7025547445  0.6949486977  0.9993095285  0.9976322021  0.9993095285  0.9897395422  39.139869796  0.0010211611  5.7843055725  3100          0.6140088010 \n",
            "0.7367330834  0.7367797948  0.9998027224  0.9972375691  0.9999013612  0.9893449092  40.402446241  0.0002262877  5.7843055725  3200          0.6185925364 \n",
            "0.7027027027  0.7020520916  1.0000000000  0.9976322021  1.0000000000  0.9913180742  41.665022686  0.0000888569  5.7843055725  3300          0.6096006036 \n",
            "0.6934306569  0.6850828729  0.9984217794  0.9952644041  0.9978299467  0.9865824783  42.927599132  0.0015141229  5.7843055725  3400          0.6194707274 \n",
            "0.7383113040  0.7346093133  0.9997040836  0.9972375691  0.9996054449  0.9901341752  44.190175577  0.0052019510  5.7843055725  3500          0.6134506059 \n",
            "0.7237127639  0.7231649566  1.0000000000  0.9980268350  0.9997040836  0.9865824783  45.452752022  0.0014862453  5.7843055725  3600          0.6209367180 \n",
            "0.7188794634  0.7131018153  1.0000000000  0.9972375691  1.0000000000  0.9921073402  46.715328467  0.0002694762  5.7843055725  3700          0.6362010550 \n",
            "0.7268692050  0.7259273875  0.9997040836  0.9940805051  0.9994081673  0.9897395422  47.977904912  0.0023738948  5.7843055725  3800          0.6051948500 \n",
            "0.7473367528  0.7415153907  0.9980272243  0.9940805051  0.9964490037  0.9838200474  49.240481357  0.0045498827  5.7843055725  3900          0.6058934021 \n",
            "0.7382126652  0.7344119968  0.9985204182  0.9968429361  0.9986190570  0.9869771113  50.503057802  0.0044438702  5.7843055725  4000          0.5994641709 \n",
            "0.6705464589  0.6643646409  0.9996054449  0.9925019732  0.9985204182  0.9850039463  51.765634247  0.0016873248  5.7843055725  4100          0.6027762508 \n",
            "0.7104458473  0.7071823204  0.9964490037  0.9877663773  0.9947721444  0.9822415154  53.028210692  0.0083639084  5.7843055725  4200          0.6098940921 \n",
            "0.7332807260  0.7302683504  1.0000000000  0.9972375691  1.0000000000  0.9905288082  54.290787137  0.0016600816  5.7843055725  4300          0.6013520265 \n",
            "0.7476326692  0.7407261247  0.9999013612  0.9948697711  0.9993095285  0.9897395422  55.553363582  0.0006339125  5.7843055725  4400          0.6025332189 \n",
            "0.7573979089  0.7525651144  0.9995068061  0.9980268350  0.9997040836  0.9877663773  56.815940027  0.0026876356  5.7843055725  4500          0.6076181936 \n",
            "0.6943677254  0.6925808998  0.9982245019  0.9936858721  0.9981258631  0.9842146803  58.078516472  0.0067190079  5.7843055725  4600          0.6034590435 \n",
            "0.7445255474  0.7391475927  0.9998027224  0.9976322021  0.9998027224  0.9909234412  59.341092917  0.0018836914  5.7843055725  4700          0.6027166390 \n",
            "0.7162655356  0.7067876875  1.0000000000  0.9964483031  0.9995068061  0.9885556433  60.603669362  0.0002436092  5.7843055725  4800          0.6082473326 \n",
            "0.7426020911  0.7385556433  0.9997040836  0.9948697711  0.9996054449  0.9905288082  61.866245807  0.0029796615  5.7843055725  4900          0.6071765113 \n",
            "0.7145393569  0.7097474349  0.9997040836  0.9944751381  0.9995068061  0.9897395422  63.128822252  0.0053898869  5.7843055725  5000          0.5998121667 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_medium/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuk-R16KzgOs",
        "outputId": "88244172-31ce-4811-8014-0c01efa9820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_hard/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 122MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             115.15087747 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.6141159964 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6257791138 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6224927640 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6194511318 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6173342490 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6224610925 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6156367707 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6182522154 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6168373513 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6274501014 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6201179457 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6196286297 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6265635109 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6200313568 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6176273632 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6281948471 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6170152378 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6204898381 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6164195275 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6218380213 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6168248272 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6204351020 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6241048074 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6225018644 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6205320001 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6193700123 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6194021606 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6208199739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6187628269 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6196645617 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6212025905 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6200934267 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6221250558 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6164404726 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6187021542 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6219896412 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6192560601 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6193850613 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6188530970 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6250334597 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6187652969 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6202621436 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6278406334 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6186798120 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6220876169 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6206880021 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6187240529 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6160216904 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6204047894 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6245353127 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_hard/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3W8kEpoNLl",
        "outputId": "3aafe63a-379d-4388-d85e-894fe453b5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/5 [00:00<?, ?it/s]\r                                                                                \rTotal records: 162\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.1 +/- 0.0               76.5 +/- 0.0               62.0 +/- 0.0               69.9                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        69.1 +/- 0.0               71.5 +/- 0.0               65.6 +/- 0.0               68.7                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtUrzrD4gOn",
        "outputId": "5a15d81f-aaee-46da-c1e9-64ebe124f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3447425528  0.3441199684  0.4174393371  0.4167324388  0.3603274808  0.3756906077  0.0000000000  1.5444172621  5.6991815567  0             92.626631498 \n",
            "0.8121424344  0.8239936859  0.9850069047  0.9790844515  0.9830341290  0.9818468824  1.2625764451  0.1916547985  5.7843055725  100           0.6161201310 \n",
            "0.7284474255  0.7334254144  0.9866837641  0.9790844515  0.9876701519  0.9822415154  2.5251528901  0.0378335118  5.7843055725  200           0.6242212915 \n",
            "0.7226277372  0.7243488556  0.9810613533  0.9629044988  0.9826395739  0.9763220205  3.7877293352  0.0316097732  5.7843055725  300           0.6324607801 \n",
            "0.7568553955  0.7604577743  0.9951666995  0.9865824783  0.9946735056  0.9861878453  5.0503057802  0.0218457361  5.7843055725  400           0.6257872558 \n",
            "0.7536003156  0.7574980268  0.9976326692  0.9877663773  0.9951666995  0.9897395422  6.3128822253  0.0149130280  5.7843055725  500           0.6235587239 \n",
            "0.7291378970  0.7357932123  0.9983231407  0.9893449092  0.9986190570  0.9936858721  7.5754586703  0.0117882919  5.7843055725  600           0.6279401875 \n",
            "0.7667192740  0.7693370166  0.9972381140  0.9869771113  0.9940816729  0.9889502762  8.8380351154  0.0145306918  5.7843055725  700           0.6247380352 \n",
            "0.7499506806  0.7573007103  0.9987176958  0.9901341752  0.9971394752  0.9913180742  10.100611560  0.0118083848  5.7843055725  800           0.6312047601 \n",
            "0.7436871178  0.7490134175  0.9961530874  0.9853985793  0.9956598935  0.9897395422  11.363188005  0.0109967921  5.7843055725  900           0.6202681732 \n",
            "0.7388044979  0.7474348856  0.9984217794  0.9905288082  0.9988163346  0.9932912391  12.625764450  0.0094502301  5.7843055725  1000          0.6276606607 \n",
            "0.7751035707  0.7717048145  0.9973367528  0.9822415154  0.9943775893  0.9869771113  13.888340895  0.0125363544  5.7843055725  1100          0.6285728884 \n",
            "0.7802327875  0.7839384373  0.9979285855  0.9877663773  0.9977313080  0.9889502762  15.150917340  0.0060999116  5.7843055725  1200          0.6247079110 \n",
            "0.7494081673  0.7580899763  0.9963503650  0.9881610103  0.9939830341  0.9850039463  16.413493785  0.0112833397  5.7843055725  1300          0.6322773695 \n",
            "0.7387551785  0.7470402526  0.9997040836  0.9932912391  0.9991122509  0.9925019732  17.676070230  0.0054056202  5.7843055725  1400          0.6218444490 \n",
            "0.7769283882  0.7778216259  0.9954626159  0.9830307814  0.9946735056  0.9869771113  18.938646675  0.0055534037  5.7843055725  1500          0.6221671605 \n",
            "0.7031958966  0.7073796369  0.9993095285  0.9861878453  0.9988163346  0.9936858721  20.201223120  0.0049165712  5.7843055725  1600          0.6286919904 \n",
            "0.7267705662  0.7241515391  0.9984217794  0.9885556433  0.9983231407  0.9905288082  21.463799566  0.0085521347  5.7843055725  1700          0.6241571999 \n",
            "0.6414973368  0.6497632202  0.9959558098  0.9869771113  0.9966462813  0.9869771113  22.726376011  0.0072744866  5.7843055725  1800          0.6317688847 \n",
            "0.7176464786  0.7237569061  0.9986190570  0.9889502762  0.9985204182  0.9885556433  23.988952456  0.0103979792  5.7843055725  1900          0.6230329943 \n",
            "0.7049713948  0.7058011050  0.9990136122  0.9877663773  0.9986190570  0.9897395422  25.251528901  0.0090116992  5.7843055725  2000          0.6276224732 \n",
            "0.7456105741  0.7494080505  0.9995068061  0.9940805051  0.9988163346  0.9925019732  26.514105346  0.0028007768  5.7843055725  2100          0.6244829988 \n",
            "0.7336752811  0.7395422257  0.9983231407  0.9909234412  0.9982245019  0.9897395422  27.776681791  0.0026261529  5.7843055725  2200          0.6262957954 \n",
            "0.7256362202  0.7332280979  0.9992108897  0.9901341752  0.9988163346  0.9925019732  29.039258236  0.0057956400  5.7843055725  2300          0.6327015185 \n",
            "0.7500986388  0.7533543804  0.9999013612  0.9913180742  0.9996054449  0.9917127072  30.301834681  0.0036455327  5.7843055725  2400          0.6239596629 \n",
            "0.7312586309  0.7320441989  0.9995068061  0.9921073402  0.9990136122  0.9901341752  31.564411126  0.0055238133  5.7843055725  2500          0.6324523091 \n",
            "0.6998421779  0.7042225730  0.9975340304  0.9850039463  0.9986190570  0.9897395422  32.826987571  0.0033805106  5.7843055725  2600          0.6255412984 \n",
            "0.7127638587  0.7168508287  0.9993095285  0.9905288082  0.9987176958  0.9928966062  34.089564016  0.0076531138  5.7843055725  2700          0.6293179131 \n",
            "0.7118761097  0.7156669298  0.9982245019  0.9897395422  0.9994081673  0.9913180742  35.352140461  0.0009840014  5.7843055725  2800          0.6253333163 \n",
            "0.6811008088  0.6838989740  0.9984217794  0.9897395422  0.9981258631  0.9877663773  36.614716906  0.0084054508  5.7843055725  2900          0.6237844157 \n",
            "0.6834188203  0.6831097080  0.9950680608  0.9798737174  0.9948707832  0.9857932123  37.877293351  0.0044238523  5.7843055725  3000          0.6262417722 \n",
            "0.6974748471  0.6994869771  0.9990136122  0.9921073402  0.9991122509  0.9897395422  39.139869796  0.0053147116  5.7843055725  3100          0.6270702934 \n",
            "0.7625764451  0.7665745856  0.9983231407  0.9857932123  0.9987176958  0.9913180742  40.402446241  0.0073252049  5.7843055725  3200          0.6314353418 \n",
            "0.7540935096  0.7634175217  0.9960544486  0.9826361484  0.9956598935  0.9861878453  41.665022686  0.0049057113  5.7843055725  3300          0.6251897311 \n",
            "0.7499506806  0.7535516969  0.9972381140  0.9834254144  0.9981258631  0.9917127072  42.927599132  0.0060753603  5.7843055725  3400          0.6289313126 \n",
            "0.7582363385  0.7586819258  0.9996054449  0.9909234412  0.9991122509  0.9893449092  44.190175577  0.0043921365  5.7843055725  3500          0.6250557089 \n",
            "0.7938942592  0.7989344909  0.9983231407  0.9881610103  0.9973367528  0.9913180742  45.452752022  0.0058474739  5.7843055725  3600          0.6268724537 \n",
            "0.7414677451  0.7472375691  0.9993095285  0.9909234412  0.9994081673  0.9921073402  46.715328467  0.0069936835  5.7843055725  3700          0.6215211320 \n",
            "0.7010258434  0.7063930545  0.9998027224  0.9925019732  0.9993095285  0.9928966062  47.977904912  0.0050067931  5.7843055725  3800          0.6244132352 \n",
            "0.7601104754  0.7582872928  0.9984217794  0.9869771113  0.9954626159  0.9873717443  49.240481357  0.0033604602  5.7843055725  3900          0.6313518667 \n",
            "0.7292365358  0.7352012628  1.0000000000  0.9960536701  1.0000000000  0.9917127072  50.503057802  0.0013490497  5.7843055725  4000          0.6236331105 \n",
            "0.7278062734  0.7357932123  0.9999013612  0.9917127072  0.9997040836  0.9921073402  51.765634247  0.0003818883  5.7843055725  4100          0.6287024641 \n",
            "0.7287926613  0.7336227309  0.9989149734  0.9853985793  0.9990136122  0.9913180742  53.028210692  0.0050014239  5.7843055725  4200          0.6291932082 \n",
            "0.7303215624  0.7377663773  0.9999013612  0.9889502762  0.9997040836  0.9901341752  54.290787137  0.0019504495  5.7843055725  4300          0.6304660201 \n",
            "0.7283487867  0.7322415154  1.0000000000  0.9921073402  0.9992108897  0.9921073402  55.553363582  0.0029379294  5.7843055725  4400          0.6251601553 \n",
            "0.7387058591  0.7399368587  0.9985204182  0.9885556433  0.9974353916  0.9913180742  56.815940027  0.0021374228  5.7843055725  4500          0.6251562452 \n",
            "0.6670447820  0.6708760852  0.9999013612  0.9932912391  0.9989149734  0.9897395422  58.078516472  0.0064164825  5.7843055725  4600          0.6286752725 \n",
            "0.7800848294  0.7833464878  0.9954626159  0.9830307814  0.9954626159  0.9885556433  59.341092917  0.0082279910  5.7843055725  4700          0.6250292301 \n",
            "0.6997435392  0.7042225730  0.9991122509  0.9925019732  0.9993095285  0.9925019732  60.603669362  0.0060093180  5.7843055725  4800          0.6258044958 \n",
            "0.7043795620  0.7111286504  0.9996054449  0.9917127072  0.9991122509  0.9928966062  61.866245807  0.0029612238  5.7843055725  4900          0.6235942554 \n",
            "0.7195699349  0.7170481452  0.9990136122  0.9909234412  0.9976326692  0.9877663773  63.128822252  0.0055418774  5.7843055725  5000          0.6231913924 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVSmQgNyig5",
        "outputId": "d6ede5dd-1397-4f48-f18f-ba33b2f2faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3572696784  0.3620757695  0.4539356875  0.4613259669  0.4520615506  0.4723756906  0.0000000000  1.6331243515  5.6991815567  0             55.661369085 \n",
            "0.4934405208  0.4964483031  0.9753403038  0.9688239937  0.9762280529  0.9723756906  1.2625764451  0.1566427394  5.7843055725  100           0.6162090135 \n",
            "0.5097159203  0.5185477506  0.9811599921  0.9775059195  0.9777076346  0.9668508287  2.5251528901  0.0377939333  5.7843055725  200           0.6225361347 \n",
            "0.5271256658  0.5380820837  0.9936871178  0.9881610103  0.9930952851  0.9861878453  3.7877293352  0.0288028434  5.7843055725  300           0.6236338639 \n",
            "0.4824422963  0.4968429361  0.9942789505  0.9877663773  0.9955612547  0.9909234412  5.0503057802  0.0388437792  5.7843055725  400           0.6268619251 \n",
            "0.5513908069  0.5586029992  0.9965476425  0.9869771113  0.9954626159  0.9869771113  6.3128822253  0.0148880032  5.7843055725  500           0.6201543760 \n",
            "0.4632570527  0.4727703236  0.9920102584  0.9794790845  0.9947721444  0.9857932123  7.5754586703  0.0180947598  5.7843055725  600           0.6200311804 \n",
            "0.3317715526  0.3326756117  0.9895442888  0.9767166535  0.9944762281  0.9893449092  8.8380351154  0.0098999443  5.7843055725  700           0.6183829451 \n",
            "0.4919609390  0.4948697711  0.9970408365  0.9865824783  0.9965476425  0.9857932123  10.100611560  0.0145966782  5.7843055725  800           0.6291699719 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUY2J85V-Ad",
        "outputId": "9e6fcdee-21bb-48d4-e2a2-b3f4f60d6298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.9 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.9 +/- 0.0               72.9                      \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.0 +/- 0.0               72.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output_M2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFubiAzerSGY",
        "outputId": "f7a88181-e706-4af8-a327-0b1490d252a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                    | 0/13 [00:00<?, ?it/s]\r                                                                                \rTotal records: 53\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               76.5 +/- 0.0               76.6                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               71.5 +/- 0.0               74.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2WzQYG9FSV",
        "outputId": "66d56659-a265-45fe-fb14-15d19d5c51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: train_output\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             99.749756574 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.5983280587 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6206359911 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6142829299 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6070183587 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6080141449 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6082016397 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6092026901 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6103980064 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6360183382 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6049654841 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6108168197 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6118657756 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6163139319 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6108947682 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6053397083 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6072963905 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6118159246 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6154971886 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6100856686 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6081331706 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6135662699 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6160948730 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6087784386 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6098929572 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6067762327 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6125501800 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6110928893 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6085288739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6073611617 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6072861338 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6083596730 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6128425336 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6068048215 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6056645203 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6041939640 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6081425190 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6051037884 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6070308352 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6057835174 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6114358330 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6085151696 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6074985671 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6056443095 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6110575628 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6077594399 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6041522574 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6092551422 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6140078497 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6102016497 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6084288812 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0 \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyPsM8-qTs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/train_output /content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeSXi_BAsw2",
        "outputId": "f8a407f0-e5b5-4577-e522-74fb8eb078eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 102\n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        76.5 +/- 0.0               62.0 +/- 0.0               69.3                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.5 +/- 0.0               65.6 +/- 0.0               68.5                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxPRKSpd7tW",
        "outputId": "e0a98e3b-2119-4b5a-d89a-0b08cc774ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
            "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
            "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
            "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 78, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
            "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
            "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
            "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/stringpict.py\", line 15, in <module>\n",
            "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Colab执行train.py脚本\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py\\\n",
        "        --data_dir=./domainbed/data/MNIST/\\\n",
        "        --algorithm IGA\\\n",
        "        --dataset ColoredMNIST\\\n",
        "        --test_env 2\n",
        "\n",
        "#启动python3解释器，并且执行名为train.py的python脚本\n",
        "#--data_dir, --algorithm, --dataset, --text_env是train.py文件中的命令行参数，命令行参数用来制定程序或脚本执行书所需要的配置，选项或参数。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXA5s87_0FX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 读取图像\n",
        "img = cv2.imread('input_image.jpg')\n",
        "\n",
        "# 创建与输入图像相同大小的掩码\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "\n",
        "# 创建前景和背景模型\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "# 定义一个矩形ROI，用于指定图像中的前景对象\n",
        "rect = (50,50,450,290)\n",
        "\n",
        "# 使用GrabCut算法进行图像分割\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# 将掩码中的可能的前景和可能的背景区域设置为0和2\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# 将原始图像与掩码相乘以获取前景对象\n",
        "img = img*mask2[:,:,np.newaxis]\n",
        "\n",
        "# 显示结果\n",
        "cv2.imshow('Result', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8MAbsYPTOg",
        "outputId": "4e5ff9f9-5fbd-4dbc-8b46-79903673f419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=\"/env/python:/content/DomainBed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tbOpWGPat2",
        "outputId": "f18a4248-822b-47e9-ae93-45ef19092c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLo5O4wdhf9",
        "outputId": "2f40c461-8185-4792-f68e-3a0b676773ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a5269aa7743b791c64ed6649418c057a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 575962639\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/173bf54d6d078902e3c95d84cd058342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 177603528\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/35d2062ac241826e2573114eb184c10b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1731344775\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 7.625215427542097e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.00047223799345445756\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/30fd34e2f4f278867b6ff5b3217c9af4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1643360463\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/93cbbc15feea120dcb5ef40876e5d339\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1552394041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b85999a8f7f51d5d4618de70657b6458\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 872123425\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7c7b782b06a6e854e2a90f87af941fab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1532722295\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ad9ee36f7c977d2e63461bd67f281f65\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1348154927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c6917ed9721df5093c80bb496ec569e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1049203149\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 12\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e09d3ae124ba408cc7b777e802abfc3b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 820509365\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.0061945703598755e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0003150750110930775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ec6ad8a352a25d018524a0799865c9c7\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 305456027\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a12555295bb7c7f7b16f49fa46aa6d43\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 335001469\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3933a42f4a7daf484c66126f193511cd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1090282834\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e0caf4e9b7f63f5f2e9dfc9c2cbd706f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 707756686\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.7028930742148706e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00044832883881609976\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a8bfbb8d29ad30056577251d58640c92\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1803180728\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3e97244e0bba4eff7f3112b1a237b744\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 988398352\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.5948054187960416e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.2409030903340844e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c56965d1318c614519d8d1aeeec2acc0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1033766585\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/359830bd171b960b8f49828cf7daea45\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1062091682\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c71071003a4a8e03d31fbc73dc56b251\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1323517681\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c21df39fbbbbff9e17a2219b8a0bdb4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 899531956\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.1059719178287245e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0226894592810383e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/144f7e007023484daf0f1835e105fa02\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1174342691\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00028242988155030726\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.0915251755880437e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/60e1b946d5dfb28c75817cb3b0f37895\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 894262147\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 15\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.768725917122619e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.692204119563736e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9e4750f5e7cdef36d12c41b1a6b11d8b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 430670040\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/d407d5a24ac774b5d0e87374d7bb0dcc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 939727439\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9b1089b3fd6bf0f3ece44fc77e993b3e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 406951466\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/eb213ec0817439be32acdbd077992b09\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 471015569\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa8f08ae34d3dae732c41aa5d02c8316\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 534836152\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/48d90e374515bb88643f4e2e9410980b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1405017170\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.456280188921339e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.005463379786545902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/123c1a60dc113b3ef130905aab29cf61\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1450517853\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/6830b2706bf869ab62120c8ec8a3d902\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1428592723\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3826168925328977e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.615900325399353e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a928b33eb83a3c2cd3efa5ea3f1ea8d9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1629628786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/476612568012d54c53a90e62b696d7bb\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1884237580\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 19\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f87bb4114b1895f7916f2b4ffc4cb860\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 536959106\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 11\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.323285967621206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.046120234156778e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b796a096bf44125b17789f4408dca06b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1903818547\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2eee150674bdf7a82d8c51eb4b1ce04a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 23433006\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/abc93fad1fd1056001dbadf8a1ca9e19\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1664885690\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1d6201f69bb66d8b6e489eda38dccc2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1064525671\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/61034eaa8320196809d9f605b075ea24\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 95358269\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a2a7ca35a2f50073f1242eb91762424c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1823278137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/09c50cd0748144c2769d47af395d8a2f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 809856719\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4134e9367b6221b835b22b88489a951d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 164181522\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dff4b52c83c4125df3323fd2db2b9f81\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 275388093\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b91c3a1a306c19c073d526f06d69ba03\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 216618918\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2c1b55962114ca954a4293b359288011\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 441369813\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5f9a4b767b89224a4075aee4b86b6256\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2034037337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002383446436179699\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 6.431270010222042e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/8b64798c53a5a1bba405d5c75dbf27e9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 693005437\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4b0c702dd74c39ad2ca842e5f3fc8ffc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1721323264\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5c18fb7899bf0c12dc359ebe9c1081d6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 244140596\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a44e96d250f70e7917800a5786e1f2fe\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 338717337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7d28429d6d35cc9f06f22e3a55845051\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1588968328\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002748180350891229\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.9000025480760227e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/991425b1146b1f446d84b36c087a6ef2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 895393786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/23a434a5febeed79a9ed9afeeb610ea9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1005706515\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e31aa2e37b983f5aa514b6243bb897e4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 539823350\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/97caedc9c298c79240b7148e65bd4864\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 848241137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/37de55f16c6cadbf954bb9c28018c6c9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1441525987\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1b86d2e19fa131d32841fa95fc15428\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1025341559\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.079846025444368e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.634713155314057e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84459224cbcb079b22304c4ca0337b15\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 658930196\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/840cda333a109b446d2d0be1aec01f44\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 797173368\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/0db98c8fc5bbd3ad85f5198cd2a9e242\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1690752950\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/00bb81be3e5faa7fa0e06a3d1b9fc214\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 640543768\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 35\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.203148467315319e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.5941595326730853e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a3cf6270845a5d9f19504a02c74d48d8\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 527331476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b719be2f2334c73ca22825242a857d83\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 794168150\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84dc1acf1587fab8013f239b8ee2a854\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 140411788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3b7e19147f067cefd3e300112c5744d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 889114309\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2bd0763b666af3a8b7180488e49f5df1\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1600026954\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ee01751ed5822f49800f2dff6d39011c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 652031788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a1fc347c08f7519f1a9885e2e4e1cc5a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2028568414\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3967520349d463cc0f4b42aa0e5a3cdc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2011109722\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a068a437f435df1e975b81101ea52090\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 887238287\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dcded23bc701bc64d1143bea8426fa7a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 874017095\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b338ef7ae36014cea7290002c49cdeab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 397958724\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7fcd0102087c6411f477f01e6e94adcd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1653294381\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f5541915a154a7ea2d59d32511dca70e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1008122992\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f4402201077fefda135d3f266680fb9d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1974935474\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fef9439cc09895fc8d5ed384d557aa2e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1905078720\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/21ce002219dcf5223be83527bc032575\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 16214241\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fae278ee4d6005566e976812d300076e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1838315136\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/15aef282c233ccf23bb82500660e4a85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1806374394\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/95dcaf3d7552b20d324e650e8344e391\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2139648535\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b59d08c5158891d095647c260599df72\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 863415268\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/396a66c0e9a33f42933162e9e157a7f6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1028178153\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/40a2ab0a6403041f72bcd672cd9685a6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2114559099\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dd31f52ac86bba2d9ad1ffdeee34c342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2029184004\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9cb8aefc8442b126f9c05a7cce526779\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 902654909\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/398e724ba11d5f6f2445d5b356ace1b0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1764407478\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4256491a7b9ddea5fd4f3b9404ed7948\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1041059927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa922f8e301f7a452a7d7802449b8900\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1622227716\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/bc89363eaa59127ca10cf772d2c57263\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1192519524\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/56102dff2a7005ef5db4c5933673ea85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 152054124\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 21\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00011281359420053416\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 5.000446907120253e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3f28d0e95f209ff5df269857a136372\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 472711008\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4514b27fbe9c296ab91cd05de3734f5e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1704833476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00015197093111758464\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0329604555494109e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9222fb7e414cd07468f4347ff233885d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 463949901\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4d35045a63b1eff681e8a628d2988b23\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 37332015\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.1375153221880086e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 6.326696718610415e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f936c2b44cc3dab85a923d914871cc4a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1141715041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c08bd5bdc0e4a927433e11e6f552089e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1353102125\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/205162f67cb34c386d1288cf23a3e73f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1743459794\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Launched 360 jobs!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.sweep launch\\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224\\\n",
        "       --output_dir=/content/MyDrive/ip/sweep_output\\\n",
        "       --command_launcher local\\\n",
        "       --algorithms ERM\\\n",
        "       --datasets SpawriousO2O_easy\\\n",
        "       --skip_confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr393evgOlTE",
        "outputId": "ace5ca35-edc0-49e3-ff67-4f086f769414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in directory: /content/domainbed/data\n",
            "MNIST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 指定要查看的目录路径\n",
        "data_dir = '/content/domainbed/data'  # 这里替换为你下载数据的目录路径\n",
        "\n",
        "# 列出指定目录下的文件和文件夹\n",
        "files_and_folders = os.listdir(data_dir)\n",
        "\n",
        "# 输出文件和文件夹列表\n",
        "print(\"Files and folders in directory:\", data_dir)\n",
        "for item in files_and_folders:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLTQ7T-5lgV"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peRMyZEz54u3",
        "outputId": "4d3a351e-775f-465a-a50d-86f28087b753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnjVjGVkZAQy"
      },
      "source": [
        "将所有图片转换成rgb形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZYfhASF-6u"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hzsjtd9Fn2k"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/ip/spawrious224/\"\n",
        "hparams = {\"data_augmentation\": True}\n",
        "test_envs = 0\n",
        "spawrious_o2o_easy = SpawriousO2O_easy(root_dir, test_envs, hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ByCqk5tsF2L8",
        "outputId": "bee03919-976b-48c0-fa21-5842a7b81a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'build_type1_combination' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-d9a268ae9e32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_type1_combination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_type1_combination' is not defined"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_o2o_easy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "8bwrHD3Qsnwv",
        "outputId": "2062da6d-58a0-4ecd-e19d-3fbc65dac0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [01:48<00:00, 29.17it/s]\n",
            "  4%|▍         | 136/3168 [00:32<12:02,  4.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-115b0497dc50>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0munloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk43pd2wZJ0M"
      },
      "source": [
        "寻找corgi类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUk9545INv",
        "outputId": "1c907d20-5c53-4e72-a511-78a91db9bbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corgi_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2441.png', 'drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2.png'), 'corgi')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "\n",
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/corgi/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "\n",
        "corgi_image_pairs = []\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, 'corgi'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "\n",
        "# 将 corgi_image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(corgi_image_pairs, f)\n",
        "\n",
        "print(\"Corgi_image pairs saved successfully.\")\n",
        "print(corgi_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeA1A4ALZNYR"
      },
      "source": [
        "寻找bulldog类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyT3OSv5IQT",
        "outputId": "585e03c4-a5f5-45a1-c88f-c595dffa4f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Bulldog_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/bulldog/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    bulldog_image_pairs.append((image_pair, 'bulldog'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(bulldog_image_pairs, f)\n",
        "\n",
        "print(\"Bulldog_image pairs saved successfully.\")\n",
        "print(bulldog_image_pairs[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZakjqAa0mfd",
        "outputId": "cb31c59b-f8c1-4cdc-c285-42c4174ee333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulldog\n"
          ]
        }
      ],
      "source": [
        "print(bulldog_image_pairs[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5rsjqJZRZA"
      },
      "source": [
        "寻找dachshund类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECFZVVm5ISR",
        "outputId": "4ae21f17-ad08-4abf-b6b4-32a0599c1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Dachshund_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/dachshund/jungle_dachshund_2902.png', 'drive/MyDrive/ip/spawrious224/0/dirt/dachshund/dirt_dachshund_343.png'), 'dachshund')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/dachshund/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, 'dachshund'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(dachshund_image_pairs, f)\n",
        "\n",
        "print(\"Dachshund_image pairs saved successfully.\")\n",
        "print(dachshund_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rg9-OhsZW5L"
      },
      "source": [
        "寻找labrador类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJlI-7ZYi36",
        "outputId": "46c742ff-2dfa-4b2b-b784-b0159d897f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "labrador_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_1201.png', 'drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_563.png'), 'labrador')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/labrador/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, 'labrador'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(labrador_image_pairs, f)\n",
        "\n",
        "print(\"labrador_image pairs saved successfully.\")\n",
        "print(labrador_image_pairs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZrnXz155UP",
        "outputId": "53e9bcbf-5edf-4b44-ca94-7e3105e3d6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_84.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1530.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_767.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1743.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2387.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_760.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_277.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_726.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2953.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_108.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3163.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2315.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2777.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1187.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_453.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_15.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2413.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_561.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_924.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_232.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1990.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1076.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_72.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1741.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2743.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_239.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_325.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1091.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_570.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_358.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_892.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3150.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2448.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3015.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_186.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1691.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1509.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_642.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1888.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_150.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2282.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3003.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1379.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2980.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2456.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2364.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2308.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_248.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2026.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2679.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_307.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2849.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1887.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3136.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2786.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3000.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_470.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2965.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_791.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2599.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3161.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1707.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1886.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_830.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2378.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_916.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_768.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2295.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2137.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1126.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2966.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1845.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_232.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2885.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1513.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2699.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1051.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_159.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2067.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2853.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_98.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2226.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1131.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1441.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2613.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2625.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_877.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_424.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2505.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2908.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_535.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1043.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_663.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1536.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1818.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1616.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2796.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_376.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1318.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_261.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1939.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1933.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2282.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1356.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_6.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_222.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2452.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2738.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1883.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2041.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_895.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3084.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_167.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2461.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2204.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1463.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2982.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_541.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1523.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2483.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1299.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_867.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2379.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_1309.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2053.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2740.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_920.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_2389.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2985.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_2435.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_803.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1697.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_291.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1006.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1563.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1796.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1753.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2466.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_935.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2864.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1505.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_772.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1364.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3008.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2936.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_364.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1347.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_797.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1124.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1574.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1934.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2514.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_52.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1388.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2320.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2129.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_3076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1084.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_329.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2630.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_2588.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2372.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_730.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2140.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2166.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3046.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1634.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1942.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_839.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_473.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_420.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_30.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2847.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2576.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2185.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_923.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1769.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_508.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_486.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_3099.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1973.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_244.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2066.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3054.png'), 'bulldog')]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 打开 .pkl 文件\n",
        "file_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 查看文件中的数据\n",
        "print(data[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaxZX0939Vu",
        "outputId": "88087c2c-bcfe-4b6a-a3f4-22a7b0ea6311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png',\n",
              "  'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'),\n",
              " 'bulldog')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 定义一个函数来加载单个 .pkl 文件\n",
        "def load_pkl(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 定义多个 .pkl 文件夹的路径\n",
        "file1='drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "file2='drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "file3='drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "file4='drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "file_paths = [file1, file2, file3, file4]\n",
        "\n",
        "# 合并\n",
        "merged_data = []\n",
        "for file_path in file_paths:\n",
        "    data = load_pkl(file_path)\n",
        "    merged_data.extend(data)\n",
        "\n",
        "\n",
        "merged_data[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG4ZrbJW7gNT"
      },
      "source": [
        "定义图像变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fnPAS-3b7ff1",
        "outputId": "3a41426e-6d81-4bfb-b9cb-59838d2ff4ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 62094/152064 [15:29<22:26, 66.80it/s]    \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c26271761609>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtransformed_image_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 定义图像变换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整大小为 224x224\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 对 merged_data 中所有图片路径应用变换\n",
        "transformed_data = []\n",
        "for image_pair, category in tqdm(merged_data):\n",
        "    transformed_image_pair = (transform(Image.open(image_pair[0])), transform(Image.open(image_pair[1])))\n",
        "    transformed_data.append((transformed_image_pair, category))\n",
        "\n",
        "# 输出变换后的数据\n",
        "print(transformed_data[1])\n",
        "\n",
        "\n",
        "dataloader = DataLoader(transformed_data, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsDg8lb7Lo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "# 定义自定义数据集类\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义 ResNet18 模型\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)  # 修改最后一层全连接层，输出为2类（假设是二分类任务）\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 准备数据集\n",
        "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', ...]  # 假设这里是你的图像数据集路径列表\n",
        "transform = transforms.Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "dataset = CustomDataset(image_paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch_images in enumerate(dataloader):\n",
        "        inputs = batch_images\n",
        "        labels = torch.randint(0, 2, (batch_images.size(0),))  # 假设这里是随机生成的标签\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # 每 10 个 mini-batch 输出一次损失值\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR2Se1J7LrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCvom3K7LtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dSlXY-7LvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar0YMs7R7LxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW2CdWBYwpu",
        "outputId": "c5e3a98e-6ec4-445d-b016-181739cbdc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image size is 224 pixels wide by 224 pixels high.\n"
          ]
        }
      ],
      "source": [
        "# 替换下面的路径为你图像的实际路径\n",
        "image_path = '/content/drive/My Drive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png'\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# 获取图像的大小\n",
        "width, height = img.size\n",
        "\n",
        "# 打印图像的大小\n",
        "print(f'The image size is {width} pixels wide by {height} pixels high.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiRyFGtY8iJ",
        "outputId": "5bc07ce5-0670-4e35-910a-e2d5bbc58c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'spawrious224_rgb': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56vrZ45Ywri"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 提取特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 定义图像预处理步骤\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整图像大小为 ResNet18 模型的输入大小\n",
        "    transforms.ToTensor(),  # 将图像转换为 Tensor 格式\n",
        "])\n",
        "\n",
        "# 加载 RGB 图像并进行预处理\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 添加 batch 维度，变成一个大小为 (1, C, H, W) 的 Tensor\n",
        "\n",
        "# 将图像输入到 ResNet18 模型中，并提取全局平均池化层的输出\n",
        "with torch.no_grad():\n",
        "    features = feature_extractor(input_batch)\n",
        "\n",
        "# 将特征转换为一个向量（reshape 为 (1, num_features)）\n",
        "global_avg_pooling_output = features.view(features.size(0), -1)\n",
        "\n",
        "# 输出向量的大小\n",
        "print(\"Global Average Pooling Output Shape:\", global_avg_pooling_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHUMXcfxBRH",
        "outputId": "5023f978-9943-4b52-db95-3917306e8d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape: torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH72AAHsxBTv",
        "outputId": "a309654e-c496-4611-d74e-d199df8e5239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape (with pooling): torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp4djmqsxBWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ7JRGRmxBYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sOryq0lgGL",
        "outputId": "aef2dd6a-3c69-42b0-e04c-713082b138eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
            "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
            "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
            "        ...,\n",
            "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
            "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
            "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]],\n",
            "       requires_grad=True)\n",
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# 加载预训练的 ResNet-18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 截取特征提取器部分（不包括最后的全连接层）\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "weights=model.fc.weight\n",
        "print(weights)\n",
        "print(len(weights))\n",
        "\n",
        "\n",
        "\n",
        "# 加载并预处理上传的两张图片数据\n",
        "image1_path = 'path/to/your/first/image.jpg'\n",
        "image2_path = 'path/to/your/second/image.jpg'\n",
        "image1 = preprocess_image(image1_path)\n",
        "image2 = preprocess_image(image2_path)\n",
        "\n",
        "# 提取图片的特征向量\n",
        "with torch.no_grad():\n",
        "    feature1 = feature_extractor(image1)\n",
        "    feature2 = feature_extractor(image2)\n",
        "\n",
        "# 对提取的特征向量进行全局平均池化操作\n",
        "global_avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "feature1_vector = global_avg_pool(feature1).squeeze()\n",
        "feature2_vector = global_avg_pool(feature2).squeeze()\n",
        "\n",
        "# 打印两个特征向量\n",
        "print(\"Feature vector for image 1:\", feature1_vector)\n",
        "print(\"Feature vector for image 2:\", feature2_vector)\n",
        "\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#定义损失函数\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "\n",
        "        # 自定义损失函数的计算过程，这里假设是平方误差损失\n",
        "        loss = torch.mean((output - target)**2)\n",
        "        return loss\n",
        "\n",
        "#定义损失函数\n",
        "def loss():\n",
        "  lam_loss_all=0\n",
        "  for i in range(batch_size):\n",
        "\toriginal=Feature map[i]\n",
        "\tpair=Feature map[10+i]\n",
        "        y_1=y[i]\n",
        "        w=Classification head weight[y_1]**2\n",
        "\tdistance=(original-pair)**2\n",
        "        lam_loss=0\n",
        "        For k 1to 2048:\n",
        "              lam_loss+=w[I]*distance[I]\n",
        "\tlam_loss_all+=lam_loss\n",
        "\n",
        "lam_loss_all/=10\n",
        "\n",
        "loss=erm_loss+lambda*lam_loss_all\n",
        "\n",
        "#开始训练\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # 解压当前 batch 中的图片对\n",
        "        images1, images2 = batch\n",
        "\n",
        "        # 前向传播\n",
        "        outputs1 = model(images1)\n",
        "        outputs2 = model(images2)\n",
        "\n",
        "        feature1 = feature_extractor(images1)\n",
        "        feature2 = feature_extractor(images2)\n",
        "\n",
        "        # 计算损失\n",
        "        loss = loss_fn(outputs1, outputs2)\n",
        "\n",
        "        # 反向传播与参数更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 打印当前损失\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# 定义优化器，并将所有参数添加到优化器中\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 训练过程中的损失计算示例\n",
        "# 假设 inputs 是模型的输入数据，targets 是真实标签\n",
        "#outputs = model(inputs)\n",
        "\n",
        "\n",
        "#loss = criterion(outputs, targets)\n",
        "\n",
        "# 反向传播与参数更新\n",
        "#optimizer.zero_grad()\n",
        "#loss.backward()\n",
        "#optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8AYk6QV59s0",
        "outputId": "1d1fd7af-edde-41d9-f342-9d9d3297ec39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "images = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png\")\n",
        "inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "image_features = model.get_image_features(**inputs)\n",
        "image_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRBhDp1-EQK",
        "outputId": "db7e1d1e-4b2b-46dc-db74-248de8d8e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8947], grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_6.png\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "other_features = model.get_image_features(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "similarity = torch.cosine_similarity(image_features, other_features, dim=1)\n",
        "print(similarity)\n",
        "\n",
        "#similar_images.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNpx89JdYAW"
      },
      "outputs": [],
      "source": [
        "# tensor --> numpy array\n",
        "# 10*768 --> 10*10\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "pairwise_cos=cosine_similarity(all_features_image0, all_features_image0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzY4-Bg9amE0",
        "outputId": "2c8648e7-753e-4e45-f242-874989629e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The path of the file is: /content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 要查找的文件名\n",
        "filename = 'train.py'\n",
        "\n",
        "# 使用 os.walk() 函数遍历文件系统，查找文件\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        print(\"The path of the file is:\", file_path)\n",
        "        break\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4ydb8Tf1ZL"
      },
      "outputs": [],
      "source": [
        "import domainbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHz6ikvEbKB4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# 将当前工作目录添加到模块搜索路径中\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXILhm1Z5Lu",
        "outputId": "bc18d9c5-2477-4aec-db5a-4a9f44a6515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    from domainbed import datasets\n",
            "ModuleNotFoundError: No module named 'domainbed'\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/DomainBed/domainbed/scripts')\n",
        "\n",
        "\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py  --data_dir=./domainbed/data/mnist_data/MNIST/MNIST/raw\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHZs22kIHITz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEui0DbG2T-"
      },
      "outputs": [],
      "source": [
        "import domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ccrCEUpIe3U",
        "outputId": "973b3d5a-7e54-40c2-c79f-c33db6b566b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import domainbed.scripts.train\n",
        "print(domainbed.scripts.train.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_8DJU6GQkP",
        "outputId": "647d4860-e9ce-4939-ed22-e6fbcbf2c271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6nF9hh2B20I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed/domainbed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpBUtnGDDP_T",
        "outputId": "e0bdf4c4-f6a2-4ee1-c05c-469b1ac9223c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "domainbed 模块已经上传到 Colab 环境中。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 列出当前目录下的文件和文件夹\n",
        "files_and_folders = os.listdir()\n",
        "\n",
        "# 检查是否有 domainbed 相关的文件或者文件夹存在\n",
        "if 'DomainBed' in files_and_folders:\n",
        "    print(\"domainbed 模块已经上传到 Colab 环境中。\")\n",
        "else:\n",
        "    print(\"domainbed 模块未上传到 Colab 环境中，请上传该模块。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "U73FCwSYCtHs",
        "outputId": "9eedd15b-ca7a-44e8-9c8a-62b6fc3c7c1e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'DomainBed.scripts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-671f19c45cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDomainBed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DomainBed.scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import DomainBed.scripts.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104WHdolBMr9",
        "outputId": "9532160a-2771-495f-edbe-236058077489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/DomainBed/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-wDOYOGcrBd",
        "outputId": "1c155a51-cb25-4d33-cef8-b9d66beba886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CODE_OF_CONDUCT.md  CONTRIBUTING.md  domainbed\tLICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tpA8g5crEd",
        "outputId": "4c37650f-6c66-41ca-a43b-a054019e7395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed\n"
          ]
        }
      ],
      "source": [
        "%cd domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpMP-JYcrG8",
        "outputId": "a5671b8c-1378-43db-800d-025f0fd06a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/DomainBed/domainbed/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9j-jXU4qnV",
        "outputId": "9a47a5e4-38bc-4ad0-9e0a-116112baebe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c2d66b9d68e869eab2d7fb0ceb797bc93c5a2eba8da460ac75e6fa1222eaeafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Pwi1MG4s0Q"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLqCJYk6Z-H"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(\"local\", \"Example App\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoTkcfW9crKX",
        "outputId": "51c83067-2d6c-4cfe-ab10-a058f03451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = sc.parallelize(range(1, 100))\n",
        "t = 50\n",
        "B = A.filter(lambda x: x < t)\n",
        "B.cache()\n",
        "t = 10\n",
        "\n",
        "C = B.filter(lambda x: x > t)\n",
        "\n",
        "print(C.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722a2LCPcrMx",
        "outputId": "dc6f003d-0d78-4ad2-94f9-3dddb67f9ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product: 233\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "def dot_product(rdd1, rdd2):\n",
        "  zipped_rdd = rdd1.zip(rdd2)\n",
        "  dot_product = zipped_rdd.map(lambda x: x[0]*x[1]).reduce(lambda x,y:x+y)\n",
        "  return dot_product\n",
        "\n",
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "result = dot_product(r1, r2)\n",
        "print(\"Dot product:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pdehnc-7kN6",
        "outputId": "0bfc6140-a0ec-4ffd-895c-cef3f0637ee2"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e471822f655>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the total dot product by summing up the partial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtotal_dot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot product:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_dot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "# Induce a different partitioning\n",
        "r2 = r2.flatMap(lambda x: [] if x == 1 else [x])\\\n",
        "       .flatMap(lambda x: [9, 9] if x == 9 else [x])\n",
        "\n",
        "def compute_dot_product(partition):\n",
        "    partial_sum = 0\n",
        "    for x, y in partition:\n",
        "        partial_sum += x * y\n",
        "    yield partial_sum\n",
        "\n",
        "dot_product_rdd = r1.zip(r2).mapPartitions(compute_dot_product)\n",
        "\n",
        "# Compute the total dot product by summing up the partial results\n",
        "total_dot_product = dot_product_rdd.reduce(lambda x, y: x + y)\n",
        "\n",
        "print(\"Dot product:\", total_dot_product)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "faf0203ade3e4d6d95de506945873501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2473c911f9934e4ab801f1e91dd49182",
              "IPY_MODEL_dc04e368de3e48b4b2837591490e1bc1",
              "IPY_MODEL_7f9931b24ac44650b3652d44d6cf0aa4"
            ],
            "layout": "IPY_MODEL_98ce801c92a240f2ab8b887f6c42145f"
          }
        },
        "2473c911f9934e4ab801f1e91dd49182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595a936ef28246309976d12e3aa84168",
            "placeholder": "​",
            "style": "IPY_MODEL_d24e944b880c49728193b32a79ddf541",
            "value": "config.json: 100%"
          }
        },
        "dc04e368de3e48b4b2837591490e1bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dda789eab754f2c8607c93c867c348a",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7015de9f4e974759ba4d63683a026711",
            "value": 4186
          }
        },
        "7f9931b24ac44650b3652d44d6cf0aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82eafc40c2e546d787830b1203f30c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb9f02ac3a348f7ad96a3adfa757934",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 316kB/s]"
          }
        },
        "98ce801c92a240f2ab8b887f6c42145f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595a936ef28246309976d12e3aa84168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24e944b880c49728193b32a79ddf541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dda789eab754f2c8607c93c867c348a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7015de9f4e974759ba4d63683a026711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82eafc40c2e546d787830b1203f30c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb9f02ac3a348f7ad96a3adfa757934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "556464689c8d4e218b42c74e17cc9915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f08024ab1c6e4ae8a67abe3557c67330",
              "IPY_MODEL_68de135480854c139c5099eb157ca40a",
              "IPY_MODEL_b7f4bb79f0534854b07904889e6ecf3f"
            ],
            "layout": "IPY_MODEL_26c378ba460243ac99cfa9ac6df6172c"
          }
        },
        "f08024ab1c6e4ae8a67abe3557c67330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f889a2302ed041df8eb8b0ffe1744504",
            "placeholder": "​",
            "style": "IPY_MODEL_65a83793b69e4e5d859405944642c501",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "68de135480854c139c5099eb157ca40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51769e5b2c3742fa85bf1c7acb3c8d6c",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58dcbfcb64184f3596903ae08236d284",
            "value": 605247071
          }
        },
        "b7f4bb79f0534854b07904889e6ecf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7e7eee1fa24b5faed7fae7530d5aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b704eca4f374935b0124622d1217ff8",
            "value": " 605M/605M [00:02&lt;00:00, 239MB/s]"
          }
        },
        "26c378ba460243ac99cfa9ac6df6172c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f889a2302ed041df8eb8b0ffe1744504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a83793b69e4e5d859405944642c501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51769e5b2c3742fa85bf1c7acb3c8d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58dcbfcb64184f3596903ae08236d284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff7e7eee1fa24b5faed7fae7530d5aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b704eca4f374935b0124622d1217ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}