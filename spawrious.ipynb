{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzVjng0cq4V",
        "outputId": "60698d01-c0ed-43ee-bbe6-71127cf3690e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1308, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1308 (delta 26), reused 37 (delta 24), pack-reused 1259\u001b[K\n",
            "Receiving objects: 100% (1308/1308), 1.09 MiB | 988.00 KiB/s, done.\n",
            "Resolving deltas: 100% (764/764), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HApsEKnU5rM2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxCp4JTdivj",
        "outputId": "73a6bc84-d0ed-46b5-bf50-028406168b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjylGMPbTZEl",
        "outputId": "9e1b994e-aea6-4617-c4a7-7128237d14be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa_F2E_wzly"
      },
      "source": [
        "Convert images to /content/...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_g-N8vfERdY",
        "outputId": "25b5c553-3e59-462f-d8e6-7d4989b5dbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/126.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wilds\n",
        "# 安装wilds模块\n",
        "# 使用wilds可以帮助研究人员更好地评估他们的机器学习算法在实际应用中的性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r_kfReEsJhNO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NQUkwkKPp6Us"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from download import download_spawrious"
      ],
      "metadata": {
        "id": "QcFueQOivecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-gdbwEqDy2A"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/ip1\"\n",
        "# 制定下载数据集所需要的目录\n",
        "\n",
        "download_spawrious(data_dir)\n",
        "# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\n",
        "# 调用其他函数下载其他数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG-PvtDxJOTD"
      },
      "outputs": [],
      "source": [
        "# 创建 SpawriousO2O_easy 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "\n",
        "spawrious_easy = SpawriousO2O_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousO2O_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousO2O_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#创建 SpawriousM2M 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "spawrious_easy = SpawriousM2M_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousM2M_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousM2M_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n"
      ],
      "metadata": {
        "id": "G5UXya1ngdo8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5Us1_27TKM0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9efqXNB2K5Pe",
        "outputId": "85b2ba53-f02c-4cf9-be7d-43a0ef69d737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8IZdwtDLlbsq"
      },
      "outputs": [],
      "source": [
        "env1 = spawrious_easy[1]\n",
        "env2 = spawrious_easy[2]\n",
        "test = spawrious_easy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "avZK4NVnUZxW"
      },
      "outputs": [],
      "source": [
        "env1_medium = spawrious_medium[1]\n",
        "env2_medium = spawrious_medium[2]\n",
        "test_medium = spawrious_medium[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAxRKr-oNWHg",
        "outputId": "ef137bcd-23c2-4d4c-f5c0-b77b5f0bdb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12672\n",
            "12672\n",
            "25344\n"
          ]
        }
      ],
      "source": [
        "env1_hard = spawrious_hard[1]\n",
        "env2_hard = spawrious_hard[2]\n",
        "test_hard = spawrious_hard[0]\n",
        "\n",
        "print(len(env1_hard))\n",
        "print(len(env2_hard))\n",
        "print(len(test_hard))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs19CK7hOHN"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt'\n",
        "torch.save(test_hard, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZFQQiRyNN71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kVYsqDeDtlGw"
      },
      "outputs": [],
      "source": [
        "torch.save(test, '/content/drive/MyDrive/ip1/M2M_test/testdata.pt')\n",
        "torch.save(test_medium, '/content/drive/MyDrive/ip1/M2M_test/testdata_medium.pt')\n",
        "torch.save(test_hard, '/content/drive/MyDrive/ip1/M2M_test/testdata_hard.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ksWtjDTrG4ho"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:\n"
      ],
      "metadata": {
        "id": "JKGmsTaZZV_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "FTvxrF-j-BTL",
        "outputId": "573130be-c4dc-4b31-fb1e-ea613ee457b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_tensor = env1_hard[3068*2-7][0]\n",
        "label = env1_hard[3068*2-7][1]\n",
        "\n",
        "image_array = image_tensor.numpy()\n",
        "image_array_rgb = np.transpose(image_array, (1, 2, 0))\n",
        "plt.imshow(image_array_rgb)\n",
        "plt.axis('off')  # 关闭坐标轴\n",
        "plt.show()\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label for m2m (3068 for each breed): 0231\n",
        "# 0: bulldog 2: dachshund 3: labrador 1:corgi\n",
        "labels_env1 = env2[1][1]\n",
        "\n",
        "\n",
        "print(\"Unique labels:\", labels_env1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdA_Egd9wE-Q",
        "outputId": "18a6405d-c1b5-44d6-aa5b-6ab497ccea9a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels: tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate filter and the graph for O2O"
      ],
      "metadata": {
        "id": "QsrCV4yszW4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_medium1 = []\n",
        "bulldog_medium2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "f9TleOcUiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_filter_medium1 = []\n",
        "bulldog_filter_medium2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_medium2.append(env2_medium[i][0])\n"
      ],
      "metadata": {
        "id": "EIMPsQZtZcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkefLJvgPCDC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "bulldog_filter_medium1_np = np.array(bulldog_filter_medium1)\n",
        "bulldog_filter_medium2_np = np.array(bulldog_filter_medium2)\n",
        "\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium1.npy', bulldog_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium2.npy', bulldog_filter_medium2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6X3shuzsRIJ",
        "outputId": "dd8eb974-8984-4071-9b8c-05d05675bf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "bulldog_medium1_np = np.array(bulldog_medium1)\n",
        "bulldog_medium2_np = np.array(bulldog_medium2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium1.npy', bulldog_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium2.npy', bulldog_medium2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_filter_medium1 = []\n",
        "dachshund_filter_medium2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "sWIoCKWbiw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-neQ3YR2Ewg"
      },
      "outputs": [],
      "source": [
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3072, 3072+3072):\n",
        "  dachshund1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756, 2756+2756):\n",
        "  dachshund2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dachshund_filter_medium1_np = np.array(dachshund_filter_medium1)\n",
        "dachshund_filter_medium2_np = np.array(dachshund_filter_medium2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium1.npy', dachshund_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium2.npy', dachshund_filter_medium2_np)\n",
        "\n",
        "dachshund_medium1_np = np.array(dachshund1)\n",
        "dachshund_medium2_np = np.array(dachshund2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium1.npy', dachshund_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium2.npy', dachshund_medium2_np)\n"
      ],
      "metadata": {
        "id": "JAPYDkGXULGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftTNGcd2m0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNUdbmZ2m45"
      },
      "outputs": [],
      "source": [
        "labrador_filter1 = []\n",
        "labrador_filter2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwSyffW2m9D"
      },
      "outputs": [],
      "source": [
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3072*2, 3072*3):\n",
        "  labrador1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*2, 2756*3):\n",
        "  labrador2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save labrador\n",
        "\n",
        "import numpy as np\n",
        "labrador_filter1_np = np.array(labrador_filter1)\n",
        "labrador_filter2_np = np.array(labrador_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium1.npy', labrador_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium2.npy', labrador_filter2_np)\n",
        "\n",
        "labrador_medium1_np = np.array(labrador1)\n",
        "labrador_medium2_np = np.array(labrador2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium1.npy', labrador_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium2.npy', labrador_medium2_np)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2wi1WcfVMwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQtiHE4WDbfZ"
      },
      "outputs": [],
      "source": [
        "corgi_filter1 = []\n",
        "corgi_filter2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7IptW5pIsFD"
      },
      "outputs": [],
      "source": [
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3072*3, 3072*4):\n",
        "  corgi1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*3, 2756*4):\n",
        "  corgi2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save corgi\n",
        "\n",
        "import numpy as np\n",
        "corgi_filter1_np = np.array(corgi_filter1)\n",
        "corgi_filter2_np = np.array(corgi_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium1.npy', corgi_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium2.npy', corgi_filter2_np)\n",
        "\n",
        "corgi_medium1_np = np.array(corgi1)\n",
        "corgi_medium2_np = np.array(corgi2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium1.npy', corgi_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium2.npy', corgi_medium2_np)\n"
      ],
      "metadata": {
        "id": "O5DYMDBHV5cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate graph for each label in M2M"
      ],
      "metadata": {
        "id": "W7xLKduJzkyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "bulldog1 = []\n",
        "bulldog2 = []\n",
        "for i in range(0, 3068):\n",
        "  bulldog1.append(env1[i][0])\n",
        "\n",
        "for i in range(0, 3068):\n",
        "  bulldog2.append(env2[i][0])\n",
        "\n",
        "bulldog1_np = np.array(bulldog1)\n",
        "bulldog2_np = np.array(bulldog2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog1.npy', bulldog1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog2.npy', bulldog2_np)\n"
      ],
      "metadata": {
        "id": "9ahGas8BzsMn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3068, 3068*2):\n",
        "  dachshund1.append(env1[i][0])\n",
        "\n",
        "for i in range(3068, 3068*2):\n",
        "  dachshund2.append(env2[i][0])\n",
        "\n",
        "dachshund1_np = np.array(dachshund1)\n",
        "dachshund2_np = np.array(dachshund2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund1.npy', dachshund1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund2.npy', dachshund2_np)\n"
      ],
      "metadata": {
        "id": "1c_k0Ai3zirS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3068*2, 3068*3):\n",
        "  labrador1.append(env1[i][0])\n",
        "\n",
        "for i in range(3068*2, 3068*3):\n",
        "  labrador2.append(env2[i][0])\n",
        "\n",
        "labrador1_np = np.array(labrador1)\n",
        "labrador2_np = np.array(labrador2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/labrador1.npy', labrador1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador2.npy', labrador2_np)\n"
      ],
      "metadata": {
        "id": "WQONA12i2Jaw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3068*3, 3068*4):\n",
        "  corgi1.append(env1[i][0])\n",
        "\n",
        "for i in range(3068*3, 3068*4):\n",
        "  corgi2.append(env2[i][0])\n",
        "\n",
        "corgi1_np = np.array(corgi1)\n",
        "corgi2_np = np.array(corgi2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/corgi1.npy', corgi1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi2.npy', corgi2_np)\n"
      ],
      "metadata": {
        "id": "HcDMxgCI2SHX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOYWgQ7GsbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSt-PjHa0vxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189d9eae-d5d3-4107-c1aa-a8c447d28b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDkvJ3N9HlQq",
        "outputId": "9ecd4e4a-ae00-415f-8360-419403e2c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "49q4nMcrOk7q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQyAlC-VAall"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_hard1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_hard2.npy')\n",
        "corgi_filter1 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard1.npy')\n",
        "corgi_filter2 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZwOYqQjbC7l"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_hard1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_hard2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504i9eqpyujC"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_hard1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_hard2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaok8gKyvUb"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_hard1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_hard2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi2.npy')"
      ],
      "metadata": {
        "id": "0hxwKGm58gOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "um-nuTB-_Rp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from transformers import CLIPModel\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:"
      ],
      "metadata": {
        "id": "nrEh7ntajEry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uX1xyS2g-QEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "13af87f2c8324581bd9f46ec89021fd3",
            "d4f18ac33c1c422285be743c98061adc",
            "44bcd236741f482ab47931207aba574a",
            "8a566ac1b65c49e2ab73d4b6cfff2e34",
            "9ee4e698d268447fac1c3ee92d95411d",
            "49c536fab538490583199cd268783dca",
            "fa1ee5dd8b134b0e94451a222b46839c",
            "4af14a07d61d4ef1ae01b544dbd3a5b1",
            "87801aa7d35e4e7189a6b085ae1dfb68",
            "707daa8dfecf4d4f80003d5075523e41",
            "ff563ca8d7d343a688d33be98daa23a6",
            "b2747a1020114b0f9d06c6a1106a0713",
            "0b269ec6eb724e1b85e03aeed185d9d3",
            "30d60635407542e6b554d75c385fbe8a",
            "e193fcc2d94046b6a8fef6cad7e67300",
            "b31d1d9f1b284f509c311ec8e358e611",
            "8613db8ed4e44ad295f70a9971ee7cce",
            "19c8dbc899c7434487873d1f05a98aa1",
            "7b12649ad7c246ea904a1a73c4fd0744",
            "aea355581a5b4fa8b245ab89994a1b33",
            "1188bc8f2e684eaaa47f7b70fbdc8629",
            "53d6e534c5974eddad7c28b08a343145"
          ]
        },
        "outputId": "964523c0-e678-4721-a783-5b29b71f7e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13af87f2c8324581bd9f46ec89021fd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2747a1020114b0f9d06c6a1106a0713"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# generate semantic sharing pairs using cosine similarity\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def similar_pair(i, class_filter, class_tensor):\n",
        "  similarity = 0\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > similarity:\n",
        "        similarity = res\n",
        "        index = j\n",
        "\n",
        "    pair1 = class_filter[i]\n",
        "    pair2 = class_tensor[index]\n",
        "    image_pair = (pair1, pair2)\n",
        "\n",
        "    return image_pair\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def fast_similar_pair(i, class_filter, class_tensor, threshold=0.85):\n",
        "  # Set a similarity threshold\n",
        "\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > threshold: # Check if similarity is above the threshold\n",
        "        pair1 = class_filter[i]\n",
        "        pair2 = class_tensor[j]\n",
        "        image_pair = (pair1, pair2)\n",
        "\n",
        "        return image_pair # Return the pair if found\n",
        "\n",
        "    return (class_filter[i], class_filter[i]) # Return itself as pair if no pair found above the threshold\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "d48610cd04c0414e8969c450f0093c27",
            "de6325a3356c4fa7b3240b8507916771",
            "609c3c5ddcf84744bb8868eccdcba82b",
            "0bb20509e2674c08a60e286dff677f55",
            "85e0ddbe144c46cea745f2aef93fa604",
            "8267386b63074894844d8d43c46702dc",
            "5dde775d992e4fdcb53cb98e97cb12c7",
            "62da91797130404f81c6b35bcbb49675",
            "3df8ed4247284715b56add188894d194",
            "08ef7828d66f42d39247a65e543d627d",
            "fc44b5d9e39644e2a4f7b72be24ee8b3",
            "f42bbeebeec34811946f0f81e3ebefe9",
            "5df2e94ce1bf4a699a4a2a2f4fbe0705",
            "61041f90f7324994a0d9a046d279f1c2",
            "26643df9223942e9b0543e65c3356f10",
            "e17320efe8da4d6a975af85ab0e06ec6",
            "174a5648a1e84f3d834506a643560f99",
            "3493e422359e4c7da44cd5284e44d8c1",
            "8844f88681e640839cbd4bf3b039397d",
            "6577bd5578ea478586fc10488c53c600",
            "f5e32770f7ea495cb6d31abcf138e9e7",
            "0fc4679fe68a4f91ae0d89806ebf7d2a"
          ]
        },
        "id": "5cbJ5WvCGBFG",
        "outputId": "a4ef5255-68e5-4e35-f7b1-9846e21d356a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48610cd04c0414e8969c450f0093c27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f42bbeebeec34811946f0f81e3ebefe9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/ip1/o2o_easy_similar_pairs/training_data_easy.npy')"
      ],
      "metadata": {
        "id": "VPWX4HxtGeds"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWECHSsaHqPD",
        "outputId": "75bb5a85-fe12-4f12-8306-9e7a0773f964"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min = 1\n",
        "for i in tqdm(range(len(data))):\n",
        "  features1 = model.get_image_features(torch.tensor(data[i][0]).unsqueeze(0).to(device))\n",
        "  features2 = model.get_image_features(torch.tensor(data[i][1]).unsqueeze(0).to(device))\n",
        "  res = F.cosine_similarity(features1, features2).item()\n",
        "  if res < min:\n",
        "    min = res\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIgDbcFiHDhE",
        "outputId": "e6f1e7d7-b60e-4565-dac7-67e26bbbebf6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2032/2032 [00:46<00:00, 44.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8610764741897583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4KmCdocQh8h",
        "outputId": "59727623-3b75-410e-9033-fb773fa16db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [42:00<00:00, 26.26s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs1 = []\n",
        "for i in tqdm(range(len(corgi_filter1))):\n",
        "    pair = similar_pair(i, corgi_filter1, corgi1)\n",
        "    corgi_pairs1.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PRdG5HFlcK"
      },
      "outputs": [],
      "source": [
        "corgi_pairs1_np = np.array(corgi_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs1.npy', corgi_pairs1_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoN6G33F179",
        "outputId": "8ac13ca2-d7ef-4afe-90f5-ac8e78c03ba5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:38:22<00:00, 23.06s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(corgi_filter2))):\n",
        "    pair = similar_pair(i, corgi_filter2, corgi2)\n",
        "    corgi_pairs2.append(pair)\n",
        "\n",
        "\n",
        "corgi_pairs2_np = np.array(corgi_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs2.npy', corgi_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkONXq1cJ6w",
        "outputId": "78d06744-03e0-4d0b-eba3-012d7bf197d9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:02<00:00, 25.65s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter1, labrador1)\n",
        "    labrador_pairs1.append(pair)\n",
        "\n",
        "labrador_pairs1_np = np.array(labrador_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs1.npy', labrador_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygDEfA1mB4H",
        "outputId": "95232c28-3bf8-44a0-8b19-0a5907c4850c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:36:51<00:00, 22.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter2, labrador2)\n",
        "    labrador_pairs2.append(pair)\n",
        "\n",
        "labrador_pairs2_np = np.array(labrador_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs2.npy', labrador_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zPieI6Qh-j",
        "outputId": "623e8156-6be9-4be3-a9c4-ea3733ce3886"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [40:54<00:00, 25.57s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter1, bulldog1)\n",
        "    bulldog_pairs1.append(pair)\n",
        "\n",
        "bulldog_pairs1_np = np.array(bulldog_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs1.npy', bulldog_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUl4yFAKFDQ",
        "outputId": "934b6e3b-db43-4376-9f1e-0389d05bcb8b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:39:22<00:00, 23.21s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter2, bulldog2)\n",
        "    bulldog_pairs2.append(pair)\n",
        "\n",
        "bulldog_pairs2_np = np.array(bulldog_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs2.npy', bulldog_pairs2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKWFg-QXE7m",
        "outputId": "7a83c0ee-7d90-4338-dc90-501fcbb8a848"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:44<00:00, 26.09s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter1, dachshund1)\n",
        "    dachshund_pairs1.append(pair)\n",
        "\n",
        "dachshund_pairs1_np = np.array(dachshund_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs1.npy', dachshund_pairs1_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmg9gwwAbAd",
        "outputId": "dde5b7da-17f2-41fb-d1d1-80f084afe701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 412/412 [2:57:25<00:00, 25.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter2, dachshund2)\n",
        "    dachshund_pairs2.append(pair)\n",
        "\n",
        "dachshund_pairs2_np = np.array(dachshund_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs2.npy', dachshund_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog1))):\n",
        "\n",
        "    pair = fast_similar_pair(i, bulldog1, bulldog2)\n",
        "    bulldog_pairs.append(pair)\n",
        "\n",
        "bulldog_pairs_np = np.array(bulldog_pairs)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bull_pairs.npy', bulldog_pairs_np)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6j3rYBg-Sku",
        "outputId": "ea43173b-2428-48e5-a081-1fba41f8ea4b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3068/3068 [7:35:01<00:00,  8.90s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_pairs = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund1))):\n",
        "\n",
        "    pair = fast_similar_pair(i, dachshund1, dachshund2)\n",
        "    dachshund_pairs.append(pair)\n",
        "\n",
        "dachshund_pairs_np = np.array(dachshund_pairs)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dach_pairs.npy', dachshund_pairs_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyf5mZvk-8oa",
        "outputId": "9cd94664-e658-4ff1-a16c-7c5414c0f308"
      },
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3068/3068 [1:09:36<00:00,  1.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labrador_pairs = []\n",
        "\n",
        "for i in tqdm(range(len(labrador1))):\n",
        "\n",
        "    pair = fast_similar_pair(i, labrador1, labrador2)\n",
        "    labrador_pairs.append(pair)\n",
        "\n",
        "labrador_pairs_np = np.array(labrador_pairs)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labra_pairs.npy', labrador_pairs_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TtgmDQ2_RLe",
        "outputId": "61a1746a-e087-424c-9f75-399910e34006"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3068/3068 [1:58:52<00:00,  2.32s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corgi_pairs = []\n",
        "\n",
        "for i in tqdm(range(len(corgi1))):\n",
        "\n",
        "    pair = fast_similar_pair(i, corgi1, corgi2)\n",
        "    corgi_pairs.append(pair)\n",
        "\n",
        "corgi_pairs_np = np.array(corgi_pairs)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs.npy', corgi_pairs_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5sIFPVU_RSM",
        "outputId": "2fff73c0-3834-4b8b-fd46-29743e93a79d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3068/3068 [1:29:39<00:00,  1.75s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cp0U6fMo5WkK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKAgASqCmOKe"
      },
      "outputs": [],
      "source": [
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFrOE3RrLiG",
        "outputId": "2c079d89-33bd-41a3-98f3-30bfe0ed1462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PMu7dA7nNUM"
      },
      "outputs": [],
      "source": [
        "training_data_np = np.array(training_data)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/training_data_hard.npy', training_data_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NrGu-LoTCz",
        "outputId": "2941f1f6-9d5a-4ae6-b1b8-7e86a7e6bfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2032"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0PdbNapNHB",
        "outputId": "54030c5e-e6fa-4299-e4f1-09c1a40ecede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "张量的形状： torch.Size([2032, 2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKslUAPyprb4",
        "outputId": "c6a75294-c4b4-4b19-f372-2a3842a347c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_easy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BAHgrw9bePe"
      },
      "source": [
        "convert all images into RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt50-fATZa32",
        "outputId": "ce1f6d76-1c38-4738-a51d-9cff9eff7433"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:07<00:00, 400.32it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.64it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.75it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.36it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.11it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.11it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.44it/s] \n",
            "100%|██████████| 3168/3168 [00:42<00:00, 73.81it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.81it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.29it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.98it/s] \n",
            "100%|██████████| 3168/3168 [00:41<00:00, 76.55it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.96it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.95it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.51it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.09it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:45<00:00, 69.65it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.34it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.47it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.75it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.43it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.11it/s] \n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:40<00:00, 78.95it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.40it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.98it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.39it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.18it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.05it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.91it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.46it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 80.48it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.66it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.47it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.05it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.02it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.07it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.99it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.61it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.41it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.99it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.86it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.81it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.70it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 83.88it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "所有图片转换完成！\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ip/spawrious224'\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        file_path = os.path.join(root, file)\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "            image.save(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRV3cb6FnoSX",
        "outputId": "c81a4785-7144-48f0-9653-fe0e26a6a245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bulldog', 'corgi', 'dachshund', 'labrador']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spawrious_easy.class_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swUTlzMZbAvm"
      },
      "source": [
        "find corgi images in env1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBlgf9kbPo1"
      },
      "source": [
        "find all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "MLAL0885BH2w",
        "outputId": "b23aef31-8b4b-429d-aad9-ff796f29b36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1826/12672 [02:35<15:20, 11.78it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e8a513c52f61>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspawrious_easy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bulldog\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbulldog_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corgi_images = []\n",
        "bulldog_images = []\n",
        "dachshund_images = []\n",
        "labrador_images = []\n",
        "\n",
        "\n",
        "for image, label in tqdm(env1):\n",
        "  if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images.append(image)\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images.append(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbcjhnlAXcZ",
        "outputId": "1f6b6fa3-702d-455e-815e-e80510a09565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3168\n",
            "3168\n",
            "3168\n",
            "3168\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi_images))\n",
        "print(len(bulldog_images))\n",
        "print(len(dachshund_images))\n",
        "print(len(labrador_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrz3aOyDbV9M"
      },
      "source": [
        "find all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFOg-czCymV",
        "outputId": "5b34ec3d-e0b2-4def-ea7e-51e8af9cf95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12672/12672 [1:20:01<00:00,  2.64it/s]\n"
          ]
        }
      ],
      "source": [
        "corgi_images2 = []\n",
        "bulldog_images2 = []\n",
        "dachshund_images2 = []\n",
        "labrador_images2 = []\n",
        "\n",
        "for image, label in tqdm(env2):\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images2.append(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKi8m9ibmRg"
      },
      "source": [
        "save all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGtK1RWUk7p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "def save_images(image_list, folder_path, label):\n",
        "    # 检查目标文件夹是否存在，不存在则创建\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 遍历图像列表，保存每张图像\n",
        "    for idx, tensor in enumerate(image_list):\n",
        "        image = TF.to_pil_image(tensor)                               # 将 tensor 转换为 PIL 图像\n",
        "        image_path = os.path.join(folder_path, f\"{label}_{idx}.png\")  # 定义图像的保存路径\n",
        "        image.save(image_path)                                        # 保存图像\n",
        "\n",
        "# Google Drive 挂载路径\n",
        "drive_path = \"/content/drive/MyDrive/ip/SpawriousImages\"\n",
        "\n",
        "# 分别保存每种类别的图像\n",
        "save_images(bulldog_images, os.path.join(drive_path, 'bulldog'), 'bulldog')\n",
        "save_images(dachshund_images, os.path.join(drive_path, 'dachshund'), 'dachshund')\n",
        "save_images(labrador_images, os.path.join(drive_path, 'labrador'), 'labrador')\n",
        "save_images(corgi_images, os.path.join(drive_path, 'corgi'), 'corgi')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ELr3P6bt2K"
      },
      "source": [
        "save all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFFo56kXnMc"
      },
      "outputs": [],
      "source": [
        "save_images(bulldog_images2, os.path.join(drive_path, 'bulldog2'), 'bulldog')\n",
        "save_images(dachshund_images2, os.path.join(drive_path, 'dachshund2'), 'dachshund')\n",
        "save_images(labrador_images2, os.path.join(drive_path, 'labrador2'), 'labrador')\n",
        "save_images(corgi_images2, os.path.join(drive_path, 'corgi2'), 'corgi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClB9-zM4fGNx",
        "outputId": "a7af8175-f2df-4362-d221-0e0215af6bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Dictionary: {'bulldog': 0, 'corgi': 1, 'dachshund': 2, 'labrador': 3}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_list = [\"bulldog\", \"corgi\", \"dachshund\", \"labrador\"]\n",
        "\n",
        "# 将列表转换为字典，键是标签，值是索引\n",
        "class_dict = {class_name: index for index, class_name in enumerate(class_list)}\n",
        "\n",
        "# 打印转换后的字典\n",
        "print(\"Class Dictionary:\", class_dict)\n",
        "class_dict['bulldog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GwhB5ObypD"
      },
      "source": [
        "create random pairs of bulldog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-q9MMaxtcQ",
        "outputId": "e613c57a-2c52-4e32-c420-daa56f69c1b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 697747.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/bulldog/bulldog_2213.png',\n",
              "  '/content/SpawriousImages/bulldog2/bulldog_2962.png'),\n",
              " 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder1_path = \"/content/SpawriousImages/bulldog\"\n",
        "folder2_path = \"/content/SpawriousImages/bulldog2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # Randomly pair\n",
        "    bulldog_image_pairs.append((image_pair, class_dict['bulldog']))\n",
        "\n",
        "bulldog_image_pairs[200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lJvdadb88y"
      },
      "source": [
        "create random pairs of corgi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8hN7jvyClr",
        "outputId": "95523183-db68-4d8e-dee9-6b4275c1ec7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 817519.62it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_208.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_3064.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/corgi\"\n",
        "folder2_path = \"/content/SpawriousImages/corgi2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "corgi_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, class_dict['corgi']))\n",
        "\n",
        "corgi_image_pairs[1093]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwyYjK7cDoq"
      },
      "source": [
        "create random pairs of dachshund"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4alSoc414EiM",
        "outputId": "de3c8564-b5d9-4dbd-87eb-f64d0cd25426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 800262.29it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/dachshund/dachshund_2053.png',\n",
              "  '/content/SpawriousImages/dachshund2/dachshund_1682.png'),\n",
              " 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/dachshund\"\n",
        "folder2_path = \"/content/SpawriousImages/dachshund2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "# 将文件名转换为完整的文件路径\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, class_dict['dachshund']))\n",
        "\n",
        "dachshund_image_pairs[100]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VW1QOicJPa"
      },
      "source": [
        "Create random pairs of labrador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcVbDd94K2U",
        "outputId": "ba1ae18c-d68b-4151-8c77-74a069314f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 733835.26it/s]\n"
          ]
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/labrador\"\n",
        "folder2_path = \"/content/SpawriousImages/labrador2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, class_dict['labrador']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fejvc8A3cM7p"
      },
      "source": [
        "merge all four classes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBx_U4Dw4Tpe",
        "outputId": "4f6c1004-2f97-4611-ded4-a06ede1873d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_2342.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_2470.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = labrador_image_pairs + dachshund_image_pairs + corgi_image_pairs + bulldog_image_pairs\n",
        "\n",
        "# 打乱合并后的列表\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "training_data[981]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1hM69h4ZxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 明确指定数组的数据类型为 object\n",
        "training_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# 指定保存文件的路径和文件名\n",
        "save_path = \"/content/training_data.npy\"\n",
        "\n",
        "# 将 NumPy 数组保存为 .npy 文件\n",
        "np.save(save_path, training_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCZHUx14Z3I",
        "outputId": "18ca66d3-0b33-41fa-de18-91c66657593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (25344, 2)\n",
            "Size: 50688\n",
            "[('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            " 3]\n",
            "('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            "/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加载 .npy 文件\n",
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# 查看数组的形状和大小\n",
        "print(\"Shape:\", array.shape)\n",
        "print(\"Size:\", array.size)\n",
        "\n",
        "\n",
        "print(array[1])\n",
        "print(array[1][0])\n",
        "print(array[1][0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check an example\n"
      ],
      "metadata": {
        "id": "70s-6zucXos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Axn7L7Sqruo",
        "outputId": "578daa98-81ed-4e89-deb7-97b93674d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png'),\n",
              "       3], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "array[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "942VqoXnP0OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image_paths = sample[0]\n",
        "        label = sample[1]\n",
        "        images = [Image.open(path) for path in image_paths]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ip1/training_data_easy.npy\"\n",
        "custom_dataset = CustomDataset(data_path, transform=transform)\n",
        "trainloader = DataLoader(custom_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezAlnNFwESe",
        "outputId": "1bff5902-46d5-466a-f900-5aaa006b432e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EI82mktkohs"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJN4vrei4Ag",
        "outputId": "a8a5a118-71f5-4f8a-e94e-12f6841a9b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "([tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]]), tensor([[[ 0.2967,  0.1426, -0.0116,  ..., -1.7240, -1.9467,  2.1462],\n",
            "         [ 0.4337,  0.5193,  0.0741,  ...,  2.1462,  1.9235,  1.9920],\n",
            "         [ 0.4337,  0.5193,  0.1426,  ...,  2.0777,  1.9920,  1.8550],\n",
            "         ...,\n",
            "         [ 2.1975,  1.8208,  1.6667,  ..., -1.6727, -1.5870, -1.5870],\n",
            "         [ 1.8893,  1.4440,  1.3755,  ...,  1.8893,  2.0434, -2.1179],\n",
            "         [ 1.5982,  1.4440,  1.3755,  ...,  1.8208,  1.8208,  1.9749]],\n",
            "\n",
            "        [[ 2.3060,  2.2360,  1.9909,  ...,  0.2052, -0.2675, -0.4951],\n",
            "         [-1.9307, -2.0182,  1.9909,  ..., -0.4251, -0.7402, -0.6527],\n",
            "         [-1.9307, -2.0182,  2.1485,  ..., -0.5826, -0.6527, -0.9678],\n",
            "         ...,\n",
            "         [-1.3179, -1.8606,  2.3761,  ..., -0.8452, -0.7752, -0.6176],\n",
            "         [-1.9482,  2.1485,  1.9209,  ..., -1.8606, -1.7031, -1.3880],\n",
            "         [ 2.3060,  2.0609,  1.9209,  ..., -2.0182, -2.0182, -1.8606]],\n",
            "\n",
            "        [[-0.8981, -1.0550, -1.2119,  ...,  1.5594,  1.0888,  0.8622],\n",
            "         [-0.6541, -0.7413, -1.2119,  ...,  1.0191,  0.6182,  0.7054],\n",
            "         [-0.6541, -0.7413, -1.0550,  ...,  0.7751,  0.7751,  0.4614],\n",
            "         ...,\n",
            "         [ 0.0605, -0.4798, -0.7064,  ...,  0.6182,  0.7576,  0.7576],\n",
            "         [-0.4798, -0.9330, -1.2467,  ..., -0.3927, -0.0790, -0.0092],\n",
            "         [-0.7064, -1.0201, -1.2467,  ..., -0.6367, -0.4798, -0.4798]]])], 1)\n"
          ]
        }
      ],
      "source": [
        "# 数据集的长度，一共有25344对图像\n",
        "print(len(custom_dataset))\n",
        "\n",
        "\n",
        "print(custom_dataset[3])\n",
        "\n",
        "# pairs\n",
        "#print(custom_dataset[3][0])\n",
        "\n",
        "# label\n",
        "#print(custom_dataset[3][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPLwSINk_IW"
      },
      "outputs": [],
      "source": [
        "batch_size= 10\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwbKV4Ay7Rq",
        "outputId": "98059a33-0549-48c3-a035-348232838ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]])\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(trainloader))\n",
        "first_data = first_batch[0][0]  # 获取第一个数据样本\n",
        "print(first_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ83k-aWJrgv"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhU_0iIXJqpZ",
        "outputId": "4e97126e-6c72-43b0-cc6f-3462131d3cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "2535\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n",
        "print(len(trainloader))\n",
        "print(type(trainloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIKQNL6rpCw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Erge4frq72"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZFFBiirq-R",
        "outputId": "3dc54f4b-67a6-4e40-e482-55c7405ba0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQM3HHBKFiE"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuuWRMBrrAY",
        "outputId": "15e1819c-fa7d-49ab-b944-d5f5110459b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "last_fc_layer = model.fc\n",
        "\n",
        "input_features = last_fc_layer.in_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqf7iroOwvq2",
        "outputId": "e133fb06-9868-4912-e836-80b9f9f293d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全连接层结构： Linear(in_features=512, out_features=4, bias=True)\n",
            "全连接层权重形状： torch.Size([4, 512])\n",
            "全连接层偏置形状： torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "fc_layer = model.fc\n",
        "\n",
        "print(\"全连接层结构：\", fc_layer)\n",
        "print(\"全连接层权重形状：\", fc_layer.weight.shape)\n",
        "print(\"全连接层偏置形状：\", fc_layer.bias.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1UnM4ToMPXv"
      },
      "source": [
        "Check:(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWh-kHp1vNb",
        "outputId": "dbac08e4-05f8-40f4-d882-200e045c7e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "tensor(1.5868, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, label = next(dataiter)\n",
        "\n",
        "#print(\"Inputs:\", images[0])       # 显示输入数据\n",
        "      # 只处理第一个 batch 后退出循环\n",
        "\n",
        "type(images[0])\n",
        "\n",
        "\n",
        "input_tensor = torch.cat((images[0], images[1]), dim=0)\n",
        "import torch\n",
        "\n",
        "\n",
        "labels = torch.cat((label, label), dim=0)\n",
        "#print(labels)\n",
        "\n",
        "outputs = model(input_tensor)\n",
        "#print(outputs)\n",
        "\n",
        "print(len(outputs))\n",
        "print(len(labels))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jMXI2Dukty",
        "outputId": "04a13456-1823-485e-a009-ce4c51837bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7cd3252a3d60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "test = torch.load('/content/drive/MyDrive/ip/testdata.pt')\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hSVD3wsqim"
      },
      "source": [
        "check an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOpFA1vlUXy",
        "outputId": "022b77ae-f4ec-46ef-c2a4-51696568a29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取第一个 batch\n",
        "first_batch = next(iter(trainloader))\n",
        "\n",
        "# 打印第一个 batch\n",
        "# print(first_batch)\n",
        "\n",
        "print(len(first_batch[0][1]))\n",
        "print(len(first_batch[0][0]))\n",
        "\n",
        "# batch_size个\n",
        "\n",
        "\n",
        "# for i, items in enumerate(trainloader, 0):\n",
        "#  print(i, items)\n",
        "#  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModifiedResNet\n"
      ],
      "metadata": {
        "id": "pgY9MuCX8xzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JeRhqEhNW7D4",
        "outputId": "dd7122f6-a2e1-4418-f1cc-5d7d9edbef4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'first_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b4ede2f49613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.cat((first_batch[0][0], first_batch[0][1]), dim=0)\n",
        "labels = torch.cat((first_batch[1], first_batch[1]), dim=0)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(input_tensor.shape[0])\n",
        "print(labels.shape)\n",
        "#input_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train process"
      ],
      "metadata": {
        "id": "RTaK4QPx86Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdykKpAdrrCz",
        "outputId": "16ca98b5-5d29-4022-ac41-520c242bc1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "11it [07:23, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [11/198], Loss: 1.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:57, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [22/198], Loss: 0.6445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:22, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [33/198], Loss: 0.4303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:54, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [44/198], Loss: 0.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:29, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [55/198], Loss: 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:59, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [66/198], Loss: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:32, 41.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [77/198], Loss: 0.1903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:09, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [88/198], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [99/198], Loss: 0.1815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:02, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [110/198], Loss: 0.1576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:38, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [121/198], Loss: 0.1529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:14, 40.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [132/198], Loss: 0.1419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:45, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [143/198], Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:20, 41.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [154/198], Loss: 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:51, 41.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [165/198], Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:16, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [176/198], Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:39, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [187/198], Loss: 0.0940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:00, 40.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [198/198], Loss: 0.0900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "11it [07:30, 40.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [11/198], Loss: 0.0390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:50, 40.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [22/198], Loss: 0.0359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [33/198], Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:35, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [44/198], Loss: 0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [36:59, 40.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [55/198], Loss: 0.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:22, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [66/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [51:46, 40.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [77/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:10, 40.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [88/198], Loss: 0.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:06:34, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [99/198], Loss: 0.0300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:06, 41.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [110/198], Loss: 0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:21:36, 40.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [121/198], Loss: 0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:07, 40.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [132/198], Loss: 0.0299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:36:37, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [143/198], Loss: 0.0309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:09, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [154/198], Loss: 0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:51:42, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [165/198], Loss: 0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:14, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [176/198], Loss: 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:06:46, 41.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [187/198], Loss: 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:14, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [198/198], Loss: 0.0209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:15, 40.68s/it]\n",
            "11it [07:32, 40.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [11/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:58, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [22/198], Loss: 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:30, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [33/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:55, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [44/198], Loss: 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:20, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [55/198], Loss: 0.0084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:48, 40.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [66/198], Loss: 0.0086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:14, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [77/198], Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:48, 40.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [88/198], Loss: 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:16, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [99/198], Loss: 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:49, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [110/198], Loss: 0.0072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:17, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [121/198], Loss: 0.0077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:46, 40.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [132/198], Loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:18, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [143/198], Loss: 0.0064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:43, 40.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [154/198], Loss: 0.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:10, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [165/198], Loss: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:40, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [176/198], Loss: 0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:06, 40.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [187/198], Loss: 0.0068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:33, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [198/198], Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:34, 40.78s/it]\n",
            "11it [07:41, 41.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [11/198], Loss: 0.0058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:13, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [22/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:44, 40.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [33/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:16, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [44/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:40, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [55/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:09, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [66/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:35, 40.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [77/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:10, 41.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [88/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [99/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:13, 41.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [110/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:47, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [121/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:16, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [132/198], Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:43, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [143/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:16, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [154/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:45, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [165/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:13, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [176/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:50, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [187/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:26, 41.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [198/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:27, 41.05s/it]\n",
            "11it [07:41, 41.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [11/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:20, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [22/198], Loss: 0.0048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:58, 41.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [33/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:37, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [44/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [55/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:50, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [66/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:27, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [77/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:01:08, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [88/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:39, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [99/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:16, 41.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [110/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:52, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [121/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:20, 40.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [132/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:53, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [143/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:27, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [154/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:04, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [165/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:42, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [176/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:21, 41.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [187/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:56, 41.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [198/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:57, 41.50s/it]\n",
            "11it [07:44, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [11/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:25, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [22/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [33/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:34, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [44/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:05, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [55/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:32, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [66/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:05, 41.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [77/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:39, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [88/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:15, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [99/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:47, 40.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [110/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:19, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [121/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:55, 41.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [132/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:29, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [143/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:06, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [154/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:43, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [165/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:11, 40.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [176/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:42, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [187/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:24, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [198/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:25, 41.34s/it]\n",
            "11it [07:35, 40.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [11/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:06, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [22/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:47, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [33/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:19, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:57, 41.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [55/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:34, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [66/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:14, 41.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [77/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:47, 41.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [88/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:20, 41.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [99/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:04, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:41, 41.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [121/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:21, 41.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [132/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:39:00, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [143/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:33, 41.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [154/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:02, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [165/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:35, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [176/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:04, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [187/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:42, 41.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [198/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:43, 41.43s/it]\n",
            "11it [07:45, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [11/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:21, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [22/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [33/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:33, 41.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [55/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:46, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [66/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:22, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [77/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:51, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [88/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:14, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [99/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:46, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:22, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [121/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:58, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [132/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:33, 41.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [143/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:11, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [154/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:46, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [165/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [176/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:41, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [187/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "189it [2:10:05, 41.73s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "modified_model=modified_model.to(device)\n",
        "modified_model=modified_model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "            for j in range(batch_size):\n",
        "                y = items[1][j].to(device)           # Class label\n",
        "                images1 = items[0][0][j].to(device)  # First image\n",
        "                images2 = items[0][1][j].to(device)  # Second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                lam_loss = 0.0\n",
        "                for k in range(512):\n",
        "                    w = fc_layer.weight[y, k] ** 2\n",
        "                    dst = (f1[0, k, 0, 0] - f2[0, k, 0, 0]) ** 2\n",
        "                    lam_loss += w * dst\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i+1) %  11== 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/11))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/model_weights_output_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLMZjBCqaZ6"
      },
      "outputs": [],
      "source": [
        "training_data = torch.tensor(data)\n",
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIsQ3KbelCN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/ip/model_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For similar pairs:"
      ],
      "metadata": {
        "id": "WuiZXWkG9DYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8dm1j-oLek0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        images = sample[0]\n",
        "        label = sample[1]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgQkyrjuTOzE",
        "outputId": "f44e879e-5462-47f6-8ccf-405a069a2bfa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1308, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1308 (delta 26), reused 37 (delta 24), pack-reused 1259\u001b[K\n",
            "Receiving objects: 100% (1308/1308), 1.08 MiB | 25.81 MiB/s, done.\n",
            "Resolving deltas: 100% (763/763), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hHEyvVUR1FiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b3a6e3-e3ba-4297-b0d5-f59ea5d8d072"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "tPvrKUMIlyOS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog = np.load('/content/drive/MyDrive/ip1/bull_pairs.npy')\n",
        "dachshund = np.load('/content/drive/MyDrive/ip1/dach_pairs.npy')\n",
        "labrador = np.load('/content/drive/MyDrive/ip1/labra_pairs.npy')\n",
        "corgi = np.load('/content/drive/MyDrive/ip1/corgi_pairs.npy')\n",
        "\n",
        "data = np.concatenate((bulldog, dachshund, labrador, corgi), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n"
      ],
      "metadata": {
        "id": "ri6sHwqW_ZP2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpICfzTu_8lz",
        "outputId": "a4b4aab4-29c2-4315-d1b5-8f04f00cf305"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12272, 2, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_np = np.array(training_data)"
      ],
      "metadata": {
        "id": "QZqVwTaN_-wT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VacjYLOu3rn",
        "outputId": "e7eec574-2123-4151-f0ee-e926ce9e7351"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12272, 2, 3, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/easy_0.85.npy', training_data_np)"
      ],
      "metadata": {
        "id": "U2vsi013i2lD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ],
      "metadata": {
        "id": "sfaoAaUBTXh3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNWe9eClKJiM",
        "outputId": "33ca26c6-9cd8-4b25-ebb5-a3b9f60642c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wilds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7zf-uSjUbI",
        "outputId": "e4053cdb-6f1f-419e-8f4d-5acbb47a65cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "sNhLjU5krDYu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBGtMHhpzKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dachshund_medium2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium2.npy')\n",
        "dachshund_medium1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium1.npy')\n",
        "bulldog_medium1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium1.npy')\n",
        "bulldog_medium2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium2.npy')\n",
        "corgi_medium1 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium1.npy')\n",
        "corgi_medium2 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium2.npy')\n",
        "labrador_medium2 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium2.npy')\n",
        "labrador_medium1 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium1.npy')\n",
        "\n",
        "labrador_medium = np.concatenate((labrador_medium1, labrador_medium2), axis=0)\n",
        "bulldog_medium = np.concatenate((bulldog_medium1, bulldog_medium2), axis=0)\n",
        "corgi_medium = np.concatenate((corgi_medium1, corgi_medium2), axis=0)\n",
        "dachshund_medium = np.concatenate((dachshund_medium1, dachshund_medium2), axis=0)\n",
        "\n",
        "data_medium = np.concatenate((labrador_medium, bulldog_medium, corgi_medium, dachshund_medium), axis=0)\n",
        "training_data_medium = torch.tensor(data_medium)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.load('/content/drive/MyDrive/ip1/O2O_training/training_data_hard.npy')"
      ],
      "metadata": {
        "id": "quVzjbVK3c_l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lipfY6ZIuxro",
        "outputId": "33164d2a-00df-452d-ae9c-35df637e1f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "           1.4611696 ,  1.4611696 ],\n",
              "         ...,\n",
              "         [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "          -0.37117907, -0.37117907],\n",
              "         [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "          -0.38830382, -0.38830382],\n",
              "         [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "          -0.38830382, -0.37117907]],\n",
              " \n",
              "        [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         ...,\n",
              "         [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "          -0.35504198, -0.35504198],\n",
              "         [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897],\n",
              "         [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897]],\n",
              " \n",
              "        [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "           2.1519828 ,  2.2042704 ],\n",
              "         [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         ...,\n",
              "         [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "          -0.21838771, -0.21838771],\n",
              "         [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.23581691],\n",
              "         [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              " array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "           0.72480524,  0.74193   ],\n",
              "         [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "           0.74193   ,  0.7590547 ],\n",
              "         [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "           0.7761795 ,  0.7761795 ],\n",
              "         ...,\n",
              "         [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "          -1.5699118 , -1.5699118 ],\n",
              "         [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "          -1.5699118 , -1.5527872 ],\n",
              "         [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "          -1.5870366 , -1.5356624 ]],\n",
              " \n",
              "        [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "           0.87044823,  0.88795525],\n",
              "         [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "           0.88795525,  0.90546227],\n",
              "         [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "           0.9229692 ,  0.9229692 ],\n",
              "         ...,\n",
              "         [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "          -1.4754901 , -1.4754901 ],\n",
              "         [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "          -1.4754901 , -1.457983  ],\n",
              "         [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "          -1.4929972 , -1.4404761 ]],\n",
              " \n",
              "        [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "           1.0888019 ,  1.1062311 ],\n",
              "         [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "           1.1062311 ,  1.1236603 ],\n",
              "         [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "           1.1410894 ,  1.1410894 ],\n",
              "         ...,\n",
              "         [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "          -1.2467101 , -1.2467101 ],\n",
              "         [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "          -1.2467101 , -1.229281  ],\n",
              "         [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "          -1.2641394 , -1.2118517 ]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 将每个 data 转换为所需的形式\n",
        "training_data = [transform_data(data) for data in training_data]\n",
        "training_data[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = []\n",
        "for i in range(len(training_data)):\n",
        "  if (i+1) % 508 != 0:\n",
        "    new_data.append(training_data[i])\n",
        "\n",
        "print(len(new_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM-vz5rhJL7-",
        "outputId": "c60f659f-9d93-4790-8406-9ad0ad9bf63b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTtNaRpmCpd",
        "outputId": "f14aa66d-432f-4185-b7ab-b2a6b130cc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 定义每个类别的名称和数量\n",
        "labels = []\n",
        "\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(507):\n",
        "    labels.extend([3])\n",
        "for _ in range(507):\n",
        "    labels.extend([0])\n",
        "for _ in range(507):\n",
        "    labels.extend([1])\n",
        "for _ in range(507):\n",
        "    labels.extend([2])\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels))\n",
        "labels[507]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "# 0: bulldog 2: dachshund 3: labrador 1:corgi\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(3068):\n",
        "    labels.extend([0])\n",
        "for _ in range(3068):\n",
        "    labels.extend([2])\n",
        "for _ in range(3068):\n",
        "    labels.extend([3])\n",
        "for _ in range(3068):\n",
        "    labels.extend([1])\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels)) #12272"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rkB2cYAjpF6",
        "outputId": "f9712699-d0c8-4f7f-cf08-293d059fdb94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hS8AgE4pKyv",
        "outputId": "47f86b04-fadd-4cfa-94ec-ca8a40cbb698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2028\n"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train = list(zip(new_data, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train))  # 应该打印出 2032\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bjA_xicqu-q",
        "outputId": "6f0dbb19-e2c3-4bf6-d553-5aa6815cb254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150528"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# prompt: 给出trainingdata中单个图像的分辨率\n",
        "example_image_path = training_data[0][0]\n",
        "\n",
        "example_image_path.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHc6RZzlfZAD",
        "outputId": "1d3a184a-7d5f-480b-eff4-386b1aa96b02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "            1.4611696 ,  1.4611696 ],\n",
              "          ...,\n",
              "          [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "           -0.37117907, -0.37117907],\n",
              "          [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "           -0.38830382, -0.38830382],\n",
              "          [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "           -0.38830382, -0.37117907]],\n",
              "  \n",
              "         [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          ...,\n",
              "          [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "           -0.35504198, -0.35504198],\n",
              "          [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897],\n",
              "          [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897]],\n",
              "  \n",
              "         [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "            2.1519828 ,  2.2042704 ],\n",
              "          [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          ...,\n",
              "          [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "           -0.21838771, -0.21838771],\n",
              "          [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.23581691],\n",
              "          [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              "  array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "            0.72480524,  0.74193   ],\n",
              "          [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "            0.74193   ,  0.7590547 ],\n",
              "          [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "            0.7761795 ,  0.7761795 ],\n",
              "          ...,\n",
              "          [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "           -1.5699118 , -1.5699118 ],\n",
              "          [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "           -1.5699118 , -1.5527872 ],\n",
              "          [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "           -1.5870366 , -1.5356624 ]],\n",
              "  \n",
              "         [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "            0.87044823,  0.88795525],\n",
              "          [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "            0.88795525,  0.90546227],\n",
              "          [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "            0.9229692 ,  0.9229692 ],\n",
              "          ...,\n",
              "          [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "           -1.4754901 , -1.4754901 ],\n",
              "          [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "           -1.4754901 , -1.457983  ],\n",
              "          [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "           -1.4929972 , -1.4404761 ]],\n",
              "  \n",
              "         [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "            1.0888019 ,  1.1062311 ],\n",
              "          [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "            1.1062311 ,  1.1236603 ],\n",
              "          [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "            1.1410894 ,  1.1410894 ],\n",
              "          ...,\n",
              "          [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "           -1.2467101 , -1.2467101 ],\n",
              "          [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "           -1.2467101 , -1.229281  ],\n",
              "          [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "           -1.2641394 , -1.2118517 ]]], dtype=float32)],\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "custom_dataset = CustomDataset(combined_train)\n",
        "custom_dataset[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zihO8aa0cjKh"
      },
      "outputs": [],
      "source": [
        "# 导入需要的库\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "trainloader = DataLoader(custom_dataset, batch_size=127, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SGwJcfPBE2G",
        "outputId": "615f0ca0-cdf4-4d04-e071-d961f00db085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "print(f1.shape)\n",
        "f1_squared = torch.pow(f1, 2)\n",
        "print(f1_squared.shape)\n",
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5a5RVH2yT5G",
        "outputId": "abfb6b9f-5eaa-45c1-c502-2271b45a4617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8c9wMs83eX",
        "outputId": "07840e10-8594-44b7-f34f-7e43503a35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "print(f1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGEKEWSuorD",
        "outputId": "237061d1-0de8-457d-fdc7-743052b7066f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "fc_layer = modified_model.final_layer\n",
        "print(fc_layer.weight.shape)\n",
        "w = fc_layer.weight[1]**2\n",
        "\n",
        "print(w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJHhdBkAIYm",
        "outputId": "a6f09fc0-7e39-4e99-d8fb-8807e06b1517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1103,  0.0845, -1.4639,  0.0241],\n",
            "        [-0.1507, -0.0891, -0.3924,  0.3247]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([1, 3], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "image1 = torch.randn(3, 224, 224)  # 假设图片1的形状为 [3, 224, 224]\n",
        "image2 = torch.randn(3, 224, 224)  # 假设图片2的形状为 [3, 224, 224]\n",
        "\n",
        "input_tensor = torch.cat((image1.unsqueeze(0), image2.unsqueeze(0)), dim=0)\n",
        "input_tensor\n",
        "y=modified_model(input_tensor.to(device))[1]\n",
        "print(y)\n",
        "predicted = torch.argmax(y, dim=1)\n",
        "print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90F789NYgK0e",
        "outputId": "c3c19d1f-5526-431d-d306-f502ef8790fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 213MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.final_layer = list(model.children())[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features_flattened = features.view( x.shape[0], -1)\n",
        "        final_output = self.final_layer(features_flattened)\n",
        "\n",
        "        return features, final_output\n",
        "\n",
        "\n",
        "modified_model = ModifiedResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBmyZK2PrrEX",
        "outputId": "eb14bbac-fbe8-458c-ab15-e7147f9b0397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "39it [01:50,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Step [39/39], Loss: 0.3359, Accuracy: 88.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:46,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/15], Step [39/39], Loss: 0.0754, Accuracy: 97.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/15], Step [39/39], Loss: 0.0276, Accuracy: 99.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/15], Step [39/39], Loss: 0.0101, Accuracy: 99.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/15], Step [39/39], Loss: 0.0058, Accuracy: 99.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/15], Step [39/39], Loss: 0.0034, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/15], Step [39/39], Loss: 0.0032, Accuracy: 99.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/15], Step [39/39], Loss: 0.0026, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/15], Step [39/39], Loss: 0.0023, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/15], Step [39/39], Loss: 0.0021, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/15], Step [39/39], Loss: 0.0021, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/15], Step [39/39], Loss: 0.0021, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/15], Step [39/39], Loss: 0.0021, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/15], Step [39/39], Loss: 0.0020, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "39it [01:47,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/15], Step [39/39], Loss: 0.0019, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 52\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "modified_model=modified_model.to(device).train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "\n",
        "            for j in range(batch_size):\n",
        "\n",
        "                y = items[1][j].to(device)           # jth class label\n",
        "                images1 = items[0][0][j].to(device)  # jth first image\n",
        "                images2 = items[0][1][j].to(device)  # jth second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                w = fc_layer.weight[y] ** 2\n",
        "                diff = torch.squeeze(torch.pow(f1- f2, 2))\n",
        "                lam_loss = torch.sum(torch.mul(diff, w))\n",
        "\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all # set to 0 for only ERM\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i+1) %  39== 0:\n",
        "                accuracy = 100 * correct / total\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/39, accuracy))\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip1/model/model_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34hKBm823Sg",
        "outputId": "33d97c95-184f-44d0-c828-a84b813ea673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25344"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "testdata = torch.load('/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt')\n",
        "len(testdata)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "GAWgmfNd25rs",
        "outputId": "bc306d17-5b00-4239-8ce9-d007867d2fcc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/model/020_50_easy.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0e541128882a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodified_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ip1/model/020_50_easy.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip1/model/020_50_easy.pth'"
          ]
        }
      ],
      "source": [
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/model/020_50_easy.pth'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Releases all unoccupied cached memory\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "48ovcK_tTkUj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "tEy8VCn39eGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOJujGudYhYa",
        "outputId": "6225ac63-ba50-43d9-d9e1-4d1cb1845f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 198/198 [4:42:29<00:00, 85.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分类任务的准确率: 91.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/model/model_epoch_15.pth'))\n",
        "modified_model = modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "# 将测试数据集转化为 DataLoader\n",
        "test_loader = DataLoader(testdata, batch_size=128, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = modified_model(images)[1]\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1ygIB_HDyY",
        "outputId": "12c8fef2-8817-435e-bd66-336564f8ea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [3:22:21<00:00, 61.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分类任务的准确率: 75.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "\n",
        "# 加载.pt文件\n",
        "\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = modified_model(images)[1]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n",
        "0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28HS3FWGtR8s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset:\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index][0], self.data[index][1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_tensor(self):\n",
        "        tensor_data = []\n",
        "        for image, label in self.data:\n",
        "            tensor_data.append((torch.tensor(image), label))\n",
        "\n",
        "        return tensor_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hFvXsW8SrYFM",
        "outputId": "a7ffd795-e2a5-499c-b0be-f80562e9f7a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c8bbd58e4b7a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ip/training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtensor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),                     # 调整图像短边至 256 像素\n",
        "    transforms.CenterCrop(224),                 # 中心裁剪图像为 224x224\n",
        "    transforms.ToTensor(),                      # 转换图像为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像数据\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 加载自定义数据集\n",
        "dataset = CustomDataset(npy_file=\"/content/drive/MyDrive/ip/training_data.npy\", transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 创建 DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztB9GY4v4yo",
        "outputId": "3392943a-290f-4547-8cb4-cef983a10d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Type: <class '__main__.CustomDataset'>\n",
            "Dataset Dimension: (25344, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset_type = type(dataset)\n",
        "print(\"Dataset Type:\", dataset_type)\n",
        "\n",
        "# 获取数据集的维度\n",
        "dataset_dimension = dataset.data.shape\n",
        "print(\"Dataset Dimension:\", dataset_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EOBx1nCxuCsC",
        "outputId": "ac4a35e3-ae9c-450d-84a0-d76fc73641c0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unexpected type <class 'tuple'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d57b01628137>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 获取 DataLoader 中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 打印第一个批次的输入数据和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected type {type(img)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'tuple'>"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch 是一个列表，包含了一个批次的样本数据\n",
        "    # 在这里你可以自定义处理逻辑，将样本转换为张量形式\n",
        "\n",
        "    # 假设 batch 中的每个元素是一个元组，其中包含输入数据和对应的标签\n",
        "    inputs = [item[0] for item in batch]  # 提取输入数据\n",
        "    labels = [item[1] for item in batch]  # 提取标签\n",
        "\n",
        "    # 将输入数据和标签转换为张量形式\n",
        "    inputs_tensor = torch.tensor(inputs)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    return inputs_tensor, labels_tensor\n",
        "\n",
        "# 定义 DataLoader，指定 collate_fn 参数为自定义的 collate_fn 函数\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 获取 DataLoader 中的数据\n",
        "inputs, labels = next(iter(data_loader))\n",
        "\n",
        "# 打印第一个批次的输入数据和标签\n",
        "print(\"First Batch Inputs:\", inputs)\n",
        "print(\"First Batch Labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsUjsKgl-2i",
        "outputId": "012f56c5-3a7e-4912-ad02-2443ff0d8f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (25344, 2)\n",
            "Train Y shape: (25344,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for element in array:\n",
        "\n",
        "    sample, label = element\n",
        "\n",
        "    train_x.append(sample)\n",
        "    train_y.append(label)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHRm6Ylmz7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpL-8JSj55R",
        "outputId": "9512c9a5-a704-4b99-b006-6df0900056bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('corgi_2105.png', 'corgi_954.png'), 'corgi'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYXYu7OrxQc",
        "outputId": "bfdbc041-8821-4b96-9dc4-c915662440e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder contains 3168 images.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# 指定文件夹路径\n",
        "folder_path = '/content/drive/MyDrive/ip/SpawriousImages/bulldog'\n",
        "\n",
        "# 使用glob.glob获取所有图片文件的路径，并计算数量\n",
        "num_images = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
        "print(f'The folder contains {num_images} images.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFzy3YrH9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rx8CzfX9rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGjjkXis9rpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce:\n"
      ],
      "metadata": {
        "id": "r69Yy9KS9r3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFjpaL71qgR",
        "outputId": "25c3c22d-1295-431c-de66-aeedc0711426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3864667587  0.3897000789  0.3901163938  0.3981846882  0.3810416256  0.4013417522  0.0000000000  1.5313433409  5.6991815567  0             27.390903472 \n",
            "0.7663247189  0.7667719021  0.9904320379  0.9861878453  0.9788913001  0.9668508287  1.2625764451  0.1483003787  5.7843055725  100           0.6112645364 \n",
            "0.7623791675  0.7582872928  0.9927993687  0.9881610103  0.9869796804  0.9798737174  2.5251528901  0.0304591087  5.7843055725  200           0.6120824623 \n",
            "0.8103176169  0.8086029992  0.9964490037  0.9881610103  0.9929966463  0.9798737174  3.7877293352  0.0201038574  5.7843055725  300           0.6128335547 \n",
            "0.7342177944  0.7229676401  0.9921088972  0.9881610103  0.9876701519  0.9731649566  5.0503057802  0.0166535372  5.7843055725  400           0.6066111851 \n",
            "0.7267705662  0.7213891081  0.9958571710  0.9909234412  0.9922075360  0.9763220205  6.3128822253  0.0185868401  5.7843055725  500           0.6118927002 \n",
            "0.7765831525  0.7778216259  0.9984217794  0.9925019732  0.9967449201  0.9818468824  7.5754586703  0.0134620355  5.7843055725  600           0.6051793170 \n",
            "0.7576938252  0.7480268350  0.9978299467  0.9936858721  0.9957585323  0.9842146803  8.8380351154  0.0087729464  5.7843055725  700           0.6085211968 \n",
            "0.7600611560  0.7563141279  0.9984217794  0.9925019732  0.9962517262  0.9818468824  10.100611560  0.0123126021  5.7843055725  800           0.6048365140 \n",
            "0.7093115013  0.7091554854  0.9961530874  0.9885556433  0.9950680608  0.9818468824  11.363188005  0.0064040128  5.7843055725  900           0.6142849422 \n",
            "0.7815150917  0.7792028414  0.9968435589  0.9901341752  0.9906293154  0.9790844515  12.625764450  0.0093996652  5.7843055725  1000          0.6039929366 \n",
            "0.7462024068  0.7490134175  0.9994081673  0.9921073402  0.9986190570  0.9834254144  13.888340895  0.0092029764  5.7843055725  1100          0.6129468703 \n",
            "0.8009469323  0.7959747435  0.9992108897  0.9928966062  0.9991122509  0.9857932123  15.150917340  0.0058361374  5.7843055725  1200          0.6129310250 \n",
            "0.7381633458  0.7391475927  0.9972381140  0.9897395422  0.9964490037  0.9802683504  16.413493785  0.0065432409  5.7843055725  1300          0.6122647572 \n",
            "0.6935292957  0.6906077348  0.9981258631  0.9913180742  0.9978299467  0.9802683504  17.676070230  0.0046631041  5.7843055725  1400          0.6144099188 \n",
            "0.6489938844  0.6475927388  0.9986190570  0.9940805051  0.9951666995  0.9786898185  18.938646675  0.0084209092  5.7843055725  1500          0.6136151099 \n",
            "0.7438350760  0.7450670876  0.9994081673  0.9913180742  0.9993095285  0.9869771113  20.201223120  0.0082047096  5.7843055725  1600          0.6134618235 \n",
            "0.7649437759  0.7588792423  0.9970408365  0.9885556433  0.9971394752  0.9794790845  21.463799566  0.0020670449  5.7843055725  1700          0.6151823425 \n",
            "0.8479976327  0.8433307024  0.9973367528  0.9893449092  0.9966462813  0.9767166535  22.726376011  0.0058088228  5.7843055725  1800          0.6114165998 \n",
            "0.7854113237  0.7847277032  0.9984217794  0.9921073402  0.9957585323  0.9814522494  23.988952456  0.0053677419  5.7843055725  1900          0.6099036169 \n",
            "0.7859538370  0.7786108919  0.9989149734  0.9917127072  0.9975340304  0.9834254144  25.251528901  0.0037218446  5.7843055725  2000          0.6132613826 \n",
            "0.6918524364  0.6793606946  0.9976326692  0.9897395422  0.9973367528  0.9830307814  26.514105346  0.0072307730  5.7843055725  2100          0.6134376049 \n",
            "0.7332314066  0.7269139700  0.9992108897  0.9948697711  0.9986190570  0.9802683504  27.776681791  0.0073834352  5.7843055725  2200          0.6204751110 \n",
            "0.7945847307  0.7878847672  0.9979285855  0.9913180742  0.9969421977  0.9818468824  29.039258236  0.0084000665  5.7843055725  2300          0.6125090265 \n",
            "0.7764845137  0.7647987372  1.0000000000  0.9917127072  0.9999013612  0.9834254144  30.301834681  0.0061496431  5.7843055725  2400          0.6324354410 \n",
            "0.6687216413  0.6590370955  0.9953639771  0.9834254144  0.9920102584  0.9767166535  31.564411126  0.0049843378  5.7843055725  2500          0.6270753837 \n",
            "0.7318011442  0.7241515391  0.9984217794  0.9889502762  0.9978299467  0.9814522494  32.826987571  0.0057329830  5.7843055725  2600          0.6227247167 \n",
            "0.7836851450  0.7756511444  0.9999013612  0.9944751381  0.9992108897  0.9838200474  34.089564016  0.0009479631  5.7843055725  2700          0.6132366180 \n",
            "0.7607023081  0.7576953433  0.9985204182  0.9925019732  0.9973367528  0.9802683504  35.352140461  0.0028693231  5.7843055725  2800          0.6186019158 \n",
            "0.7607516275  0.7513812155  0.9984217794  0.9885556433  0.9939830341  0.9767166535  36.614716906  0.0079865522  5.7843055725  2900          0.6299188948 \n",
            "0.7857072401  0.7758484609  0.9998027224  0.9909234412  0.9995068061  0.9846093133  37.877293351  0.0030832417  5.7843055725  3000          0.6098960829 \n",
            "0.7091635431  0.6939621152  0.9978299467  0.9885556433  0.9969421977  0.9771112865  39.139869796  0.0061063865  5.7843055725  3100          0.6046432948 \n",
            "0.7215427106  0.7095501184  0.9965476425  0.9893449092  0.9955612547  0.9806629834  40.402446241  0.0045622018  5.7843055725  3200          0.6033505225 \n",
            "0.7802821069  0.7715074980  0.9998027224  0.9925019732  0.9990136122  0.9881610103  41.665022686  0.0067104823  5.7843055725  3300          0.6084430003 \n",
            "0.7143420793  0.7109313339  0.9959558098  0.9869771113  0.9970408365  0.9782951855  42.927599132  0.0011498852  5.7843055725  3400          0.6063428593 \n",
            "0.6730124285  0.6653512234  0.9973367528  0.9889502762  0.9950680608  0.9739542226  44.190175577  0.0085864400  5.7843055725  3500          0.6008972216 \n",
            "0.6958966266  0.6898184688  0.9998027224  0.9921073402  0.9996054449  0.9857932123  45.452752022  0.0064733884  5.7843055725  3600          0.6162673044 \n",
            "0.7082757940  0.7028413575  1.0000000000  0.9956590371  0.9999013612  0.9889502762  46.715328467  0.0012216950  5.7843055725  3700          0.6148056483 \n",
            "0.7186328664  0.7099447514  1.0000000000  0.9944751381  1.0000000000  0.9889502762  47.977904912  0.0000642128  5.7843055725  3800          0.6070259309 \n",
            "0.7200631288  0.7113259669  0.9997040836  0.9921073402  0.9998027224  0.9861878453  49.240481357  0.0027398469  5.7843055725  3900          0.6156265235 \n",
            "0.7058591438  0.7091554854  0.9995068061  0.9940805051  0.9994081673  0.9881610103  50.503057802  0.0021378895  5.7843055725  4000          0.6109139323 \n",
            "0.6887453147  0.6779794791  0.9994081673  0.9917127072  0.9993095285  0.9861878453  51.765634247  0.0059131746  5.7843055725  4100          0.6170952582 \n",
            "0.6611757743  0.6572612470  0.9973367528  0.9913180742  0.9970408365  0.9806629834  53.028210692  0.0104169882  5.7843055725  4200          0.6217965150 \n",
            "0.6604853028  0.6515390687  0.9982245019  0.9905288082  0.9955612547  0.9763220205  54.290787137  0.0042702924  5.7843055725  4300          0.6096786547 \n",
            "0.7143913987  0.7036306235  0.9992108897  0.9936858721  0.9978299467  0.9802683504  55.553363582  0.0065798409  5.7843055725  4400          0.6024882984 \n",
            "0.7114815545  0.7056037885  0.9999013612  0.9952644041  0.9997040836  0.9917127072  56.815940027  0.0049846871  5.7843055725  4500          0.6199430537 \n",
            "0.6791773525  0.6659431728  0.9992108897  0.9928966062  0.9990136122  0.9806629834  58.078516472  0.0005054018  5.7843055725  4600          0.6146416759 \n",
            "0.7630203196  0.7582872928  0.9999013612  0.9956590371  1.0000000000  0.9869771113  59.341092917  0.0010236725  5.7843055725  4700          0.6122219038 \n",
            "0.7570033537  0.7513812155  0.9999013612  0.9952644041  0.9999013612  0.9881610103  60.603669362  0.0000619924  5.7843055725  4800          0.6136543655 \n",
            "0.6861807063  0.6712707182  0.9983231407  0.9889502762  0.9973367528  0.9810576164  61.866245807  0.0034500310  5.7843055725  4900          0.6070861173 \n",
            "0.6905208128  0.6902131018  0.9999013612  0.9952644041  0.9989149734  0.9822415154  63.128822252  0.0057498560  5.7843055725  5000          0.6079993272 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647,\\\n",
        "        \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLCqJpRpZla",
        "outputId": "1a0e5102-ef83-43f2-d0eb-2034bc3093f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        71.1 +/- 0.0               71.1                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        69.1 +/- 0.0               69.1                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSJ6vNQiFYD",
        "outputId": "6a81e146-dd33-456a-c9e6-95da2b3fd601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_medium/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 107MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3137699744  0.3155090766  0.4236535806  0.4340962904  0.4138883409  0.4352801894  0.0000000000  1.5721870661  5.6991815567  0             121.17406868 \n",
            "0.6615210101  0.6598263615  0.9904320379  0.9889502762  0.9813572697  0.9790844515  1.2625764451  0.1269948081  5.7843055725  100           0.5992083979 \n",
            "0.6557999605  0.6521310182  0.9934898402  0.9928966062  0.9871769580  0.9810576164  2.5251528901  0.0242757843  5.7843055725  200           0.6010344815 \n",
            "0.7217893076  0.7209944751  0.9941803117  0.9901341752  0.9905306767  0.9822415154  3.7877293352  0.0248986174  5.7843055725  300           0.6032668781 \n",
            "0.6864766226  0.6795580110  0.9990136122  0.9976322021  0.9960544486  0.9857932123  5.0503057802  0.0148176499  5.7843055725  400           0.6020192647 \n",
            "0.7547346617  0.7531570639  0.9977313080  0.9940805051  0.9947721444  0.9857932123  6.3128822253  0.0099429032  5.7843055725  500           0.6023221374 \n",
            "0.6849477214  0.6823204420  0.9983231407  0.9960536701  0.9959558098  0.9822415154  7.5754586703  0.0127289780  5.7843055725  600           0.5986590838 \n",
            "0.6821365161  0.6754143646  0.9976326692  0.9940805051  0.9963503650  0.9853985793  8.8380351154  0.0070593210  5.7843055725  700           0.5992206550 \n",
            "0.7350562241  0.7342146803  0.9992108897  0.9964483031  0.9980272243  0.9877663773  10.100611560  0.0090081152  5.7843055725  800           0.5954315782 \n",
            "0.6724699152  0.6637726914  0.9995068061  0.9956590371  0.9983231407  0.9877663773  11.363188005  0.0071447303  5.7843055725  900           0.5991444755 \n",
            "0.7353521405  0.7310576164  0.9983231407  0.9964483031  0.9978299467  0.9873717443  12.625764450  0.0082690991  5.7843055725  1000          0.6007423878 \n",
            "0.7047247978  0.6971191792  0.9989149734  0.9952644041  0.9990136122  0.9861878453  13.888340895  0.0095554909  5.7843055725  1100          0.5999678946 \n",
            "0.7175478398  0.7115232833  0.9984217794  0.9956590371  0.9976326692  0.9850039463  15.150917340  0.0074848697  5.7843055725  1200          0.6209489059 \n",
            "0.6003156441  0.5935280189  0.9908265930  0.9846093133  0.9845137108  0.9739542226  16.413493785  0.0061670831  5.7843055725  1300          0.6227960443 \n",
            "0.7109883606  0.6983030781  0.9990136122  0.9932912391  0.9984217794  0.9877663773  17.676070230  0.0095289110  5.7843055725  1400          0.6323509693 \n",
            "0.7592227264  0.7523677979  0.9981258631  0.9956590371  0.9963503650  0.9846093133  18.938646675  0.0060454098  5.7843055725  1500          0.6389152265 \n",
            "0.7201617676  0.7127071823  0.9993095285  0.9956590371  0.9986190570  0.9889502762  20.201223120  0.0078355287  5.7843055725  1600          0.6430245256 \n",
            "0.7292858552  0.7211917916  0.9998027224  0.9956590371  0.9997040836  0.9925019732  21.463799566  0.0018214593  5.7843055725  1700          0.6293191934 \n",
            "0.7227756954  0.7123125493  0.9999013612  0.9968429361  0.9999013612  0.9893449092  22.726376011  0.0015204751  5.7843055725  1800          0.6129930377 \n",
            "0.6896823831  0.6892265193  0.9999013612  0.9964483031  0.9998027224  0.9897395422  23.988952456  0.0028037445  5.7843055725  1900          0.6100966716 \n",
            "0.7653383310  0.7582872928  0.9993095285  0.9964483031  0.9994081673  0.9932912391  25.251528901  0.0004546101  5.7843055725  2000          0.6023241353 \n",
            "0.7000887749  0.6896211523  0.9985204182  0.9936858721  0.9977313080  0.9865824783  26.514105346  0.0064458975  5.7843055725  2100          0.5988242507 \n",
            "0.6427303216  0.6410812944  0.9988163346  0.9968429361  0.9988163346  0.9873717443  27.776681791  0.0060048382  5.7843055725  2200          0.5992763162 \n",
            "0.7598638785  0.7527624309  1.0000000000  0.9988161010  0.9998027224  0.9905288082  29.039258236  0.0023152082  5.7843055725  2300          0.5971370530 \n",
            "0.6899289801  0.6874506709  0.9981258631  0.9913180742  0.9959558098  0.9873717443  30.301834681  0.0050733112  5.7843055725  2400          0.5996246147 \n",
            "0.7281515092  0.7239542226  0.9898402052  0.9767166535  0.9817518248  0.9723756906  31.564411126  0.0072616203  5.7843055725  2500          0.5943894243 \n",
            "0.7001380943  0.6992896606  0.9995068061  0.9956590371  0.9988163346  0.9881610103  32.826987571  0.0440309145  5.7843055725  2600          0.6050425506 \n",
            "0.7320970606  0.7237569061  0.9992108897  0.9956590371  0.9990136122  0.9905288082  34.089564016  0.0048803466  5.7843055725  2700          0.6109957647 \n",
            "0.6917044782  0.6831097080  0.9991122509  0.9932912391  0.9984217794  0.9846093133  35.352140461  0.0067349893  5.7843055725  2800          0.6111056709 \n",
            "0.7432432432  0.7421073402  1.0000000000  0.9984214680  0.9995068061  0.9893449092  36.614716906  0.0033565566  5.7843055725  2900          0.6050006723 \n",
            "0.6926415467  0.6876479874  0.9998027224  0.9952644041  0.9990136122  0.9857932123  37.877293351  0.0042016615  5.7843055725  3000          0.6177810144 \n",
            "0.7025547445  0.6949486977  0.9993095285  0.9976322021  0.9993095285  0.9897395422  39.139869796  0.0010211611  5.7843055725  3100          0.6140088010 \n",
            "0.7367330834  0.7367797948  0.9998027224  0.9972375691  0.9999013612  0.9893449092  40.402446241  0.0002262877  5.7843055725  3200          0.6185925364 \n",
            "0.7027027027  0.7020520916  1.0000000000  0.9976322021  1.0000000000  0.9913180742  41.665022686  0.0000888569  5.7843055725  3300          0.6096006036 \n",
            "0.6934306569  0.6850828729  0.9984217794  0.9952644041  0.9978299467  0.9865824783  42.927599132  0.0015141229  5.7843055725  3400          0.6194707274 \n",
            "0.7383113040  0.7346093133  0.9997040836  0.9972375691  0.9996054449  0.9901341752  44.190175577  0.0052019510  5.7843055725  3500          0.6134506059 \n",
            "0.7237127639  0.7231649566  1.0000000000  0.9980268350  0.9997040836  0.9865824783  45.452752022  0.0014862453  5.7843055725  3600          0.6209367180 \n",
            "0.7188794634  0.7131018153  1.0000000000  0.9972375691  1.0000000000  0.9921073402  46.715328467  0.0002694762  5.7843055725  3700          0.6362010550 \n",
            "0.7268692050  0.7259273875  0.9997040836  0.9940805051  0.9994081673  0.9897395422  47.977904912  0.0023738948  5.7843055725  3800          0.6051948500 \n",
            "0.7473367528  0.7415153907  0.9980272243  0.9940805051  0.9964490037  0.9838200474  49.240481357  0.0045498827  5.7843055725  3900          0.6058934021 \n",
            "0.7382126652  0.7344119968  0.9985204182  0.9968429361  0.9986190570  0.9869771113  50.503057802  0.0044438702  5.7843055725  4000          0.5994641709 \n",
            "0.6705464589  0.6643646409  0.9996054449  0.9925019732  0.9985204182  0.9850039463  51.765634247  0.0016873248  5.7843055725  4100          0.6027762508 \n",
            "0.7104458473  0.7071823204  0.9964490037  0.9877663773  0.9947721444  0.9822415154  53.028210692  0.0083639084  5.7843055725  4200          0.6098940921 \n",
            "0.7332807260  0.7302683504  1.0000000000  0.9972375691  1.0000000000  0.9905288082  54.290787137  0.0016600816  5.7843055725  4300          0.6013520265 \n",
            "0.7476326692  0.7407261247  0.9999013612  0.9948697711  0.9993095285  0.9897395422  55.553363582  0.0006339125  5.7843055725  4400          0.6025332189 \n",
            "0.7573979089  0.7525651144  0.9995068061  0.9980268350  0.9997040836  0.9877663773  56.815940027  0.0026876356  5.7843055725  4500          0.6076181936 \n",
            "0.6943677254  0.6925808998  0.9982245019  0.9936858721  0.9981258631  0.9842146803  58.078516472  0.0067190079  5.7843055725  4600          0.6034590435 \n",
            "0.7445255474  0.7391475927  0.9998027224  0.9976322021  0.9998027224  0.9909234412  59.341092917  0.0018836914  5.7843055725  4700          0.6027166390 \n",
            "0.7162655356  0.7067876875  1.0000000000  0.9964483031  0.9995068061  0.9885556433  60.603669362  0.0002436092  5.7843055725  4800          0.6082473326 \n",
            "0.7426020911  0.7385556433  0.9997040836  0.9948697711  0.9996054449  0.9905288082  61.866245807  0.0029796615  5.7843055725  4900          0.6071765113 \n",
            "0.7145393569  0.7097474349  0.9997040836  0.9944751381  0.9995068061  0.9897395422  63.128822252  0.0053898869  5.7843055725  5000          0.5998121667 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_medium/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuk-R16KzgOs",
        "outputId": "88244172-31ce-4811-8014-0c01efa9820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_hard/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 122MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             115.15087747 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.6141159964 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6257791138 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6224927640 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6194511318 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6173342490 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6224610925 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6156367707 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6182522154 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6168373513 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6274501014 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6201179457 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6196286297 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6265635109 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6200313568 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6176273632 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6281948471 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6170152378 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6204898381 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6164195275 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6218380213 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6168248272 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6204351020 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6241048074 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6225018644 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6205320001 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6193700123 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6194021606 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6208199739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6187628269 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6196645617 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6212025905 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6200934267 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6221250558 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6164404726 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6187021542 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6219896412 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6192560601 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6193850613 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6188530970 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6250334597 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6187652969 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6202621436 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6278406334 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6186798120 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6220876169 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6206880021 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6187240529 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6160216904 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6204047894 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6245353127 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_hard/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3W8kEpoNLl",
        "outputId": "3aafe63a-379d-4388-d85e-894fe453b5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/5 [00:00<?, ?it/s]\r                                                                                \rTotal records: 162\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.1 +/- 0.0               76.5 +/- 0.0               62.0 +/- 0.0               69.9                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        69.1 +/- 0.0               71.5 +/- 0.0               65.6 +/- 0.0               68.7                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtUrzrD4gOn",
        "outputId": "5a15d81f-aaee-46da-c1e9-64ebe124f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3447425528  0.3441199684  0.4174393371  0.4167324388  0.3603274808  0.3756906077  0.0000000000  1.5444172621  5.6991815567  0             92.626631498 \n",
            "0.8121424344  0.8239936859  0.9850069047  0.9790844515  0.9830341290  0.9818468824  1.2625764451  0.1916547985  5.7843055725  100           0.6161201310 \n",
            "0.7284474255  0.7334254144  0.9866837641  0.9790844515  0.9876701519  0.9822415154  2.5251528901  0.0378335118  5.7843055725  200           0.6242212915 \n",
            "0.7226277372  0.7243488556  0.9810613533  0.9629044988  0.9826395739  0.9763220205  3.7877293352  0.0316097732  5.7843055725  300           0.6324607801 \n",
            "0.7568553955  0.7604577743  0.9951666995  0.9865824783  0.9946735056  0.9861878453  5.0503057802  0.0218457361  5.7843055725  400           0.6257872558 \n",
            "0.7536003156  0.7574980268  0.9976326692  0.9877663773  0.9951666995  0.9897395422  6.3128822253  0.0149130280  5.7843055725  500           0.6235587239 \n",
            "0.7291378970  0.7357932123  0.9983231407  0.9893449092  0.9986190570  0.9936858721  7.5754586703  0.0117882919  5.7843055725  600           0.6279401875 \n",
            "0.7667192740  0.7693370166  0.9972381140  0.9869771113  0.9940816729  0.9889502762  8.8380351154  0.0145306918  5.7843055725  700           0.6247380352 \n",
            "0.7499506806  0.7573007103  0.9987176958  0.9901341752  0.9971394752  0.9913180742  10.100611560  0.0118083848  5.7843055725  800           0.6312047601 \n",
            "0.7436871178  0.7490134175  0.9961530874  0.9853985793  0.9956598935  0.9897395422  11.363188005  0.0109967921  5.7843055725  900           0.6202681732 \n",
            "0.7388044979  0.7474348856  0.9984217794  0.9905288082  0.9988163346  0.9932912391  12.625764450  0.0094502301  5.7843055725  1000          0.6276606607 \n",
            "0.7751035707  0.7717048145  0.9973367528  0.9822415154  0.9943775893  0.9869771113  13.888340895  0.0125363544  5.7843055725  1100          0.6285728884 \n",
            "0.7802327875  0.7839384373  0.9979285855  0.9877663773  0.9977313080  0.9889502762  15.150917340  0.0060999116  5.7843055725  1200          0.6247079110 \n",
            "0.7494081673  0.7580899763  0.9963503650  0.9881610103  0.9939830341  0.9850039463  16.413493785  0.0112833397  5.7843055725  1300          0.6322773695 \n",
            "0.7387551785  0.7470402526  0.9997040836  0.9932912391  0.9991122509  0.9925019732  17.676070230  0.0054056202  5.7843055725  1400          0.6218444490 \n",
            "0.7769283882  0.7778216259  0.9954626159  0.9830307814  0.9946735056  0.9869771113  18.938646675  0.0055534037  5.7843055725  1500          0.6221671605 \n",
            "0.7031958966  0.7073796369  0.9993095285  0.9861878453  0.9988163346  0.9936858721  20.201223120  0.0049165712  5.7843055725  1600          0.6286919904 \n",
            "0.7267705662  0.7241515391  0.9984217794  0.9885556433  0.9983231407  0.9905288082  21.463799566  0.0085521347  5.7843055725  1700          0.6241571999 \n",
            "0.6414973368  0.6497632202  0.9959558098  0.9869771113  0.9966462813  0.9869771113  22.726376011  0.0072744866  5.7843055725  1800          0.6317688847 \n",
            "0.7176464786  0.7237569061  0.9986190570  0.9889502762  0.9985204182  0.9885556433  23.988952456  0.0103979792  5.7843055725  1900          0.6230329943 \n",
            "0.7049713948  0.7058011050  0.9990136122  0.9877663773  0.9986190570  0.9897395422  25.251528901  0.0090116992  5.7843055725  2000          0.6276224732 \n",
            "0.7456105741  0.7494080505  0.9995068061  0.9940805051  0.9988163346  0.9925019732  26.514105346  0.0028007768  5.7843055725  2100          0.6244829988 \n",
            "0.7336752811  0.7395422257  0.9983231407  0.9909234412  0.9982245019  0.9897395422  27.776681791  0.0026261529  5.7843055725  2200          0.6262957954 \n",
            "0.7256362202  0.7332280979  0.9992108897  0.9901341752  0.9988163346  0.9925019732  29.039258236  0.0057956400  5.7843055725  2300          0.6327015185 \n",
            "0.7500986388  0.7533543804  0.9999013612  0.9913180742  0.9996054449  0.9917127072  30.301834681  0.0036455327  5.7843055725  2400          0.6239596629 \n",
            "0.7312586309  0.7320441989  0.9995068061  0.9921073402  0.9990136122  0.9901341752  31.564411126  0.0055238133  5.7843055725  2500          0.6324523091 \n",
            "0.6998421779  0.7042225730  0.9975340304  0.9850039463  0.9986190570  0.9897395422  32.826987571  0.0033805106  5.7843055725  2600          0.6255412984 \n",
            "0.7127638587  0.7168508287  0.9993095285  0.9905288082  0.9987176958  0.9928966062  34.089564016  0.0076531138  5.7843055725  2700          0.6293179131 \n",
            "0.7118761097  0.7156669298  0.9982245019  0.9897395422  0.9994081673  0.9913180742  35.352140461  0.0009840014  5.7843055725  2800          0.6253333163 \n",
            "0.6811008088  0.6838989740  0.9984217794  0.9897395422  0.9981258631  0.9877663773  36.614716906  0.0084054508  5.7843055725  2900          0.6237844157 \n",
            "0.6834188203  0.6831097080  0.9950680608  0.9798737174  0.9948707832  0.9857932123  37.877293351  0.0044238523  5.7843055725  3000          0.6262417722 \n",
            "0.6974748471  0.6994869771  0.9990136122  0.9921073402  0.9991122509  0.9897395422  39.139869796  0.0053147116  5.7843055725  3100          0.6270702934 \n",
            "0.7625764451  0.7665745856  0.9983231407  0.9857932123  0.9987176958  0.9913180742  40.402446241  0.0073252049  5.7843055725  3200          0.6314353418 \n",
            "0.7540935096  0.7634175217  0.9960544486  0.9826361484  0.9956598935  0.9861878453  41.665022686  0.0049057113  5.7843055725  3300          0.6251897311 \n",
            "0.7499506806  0.7535516969  0.9972381140  0.9834254144  0.9981258631  0.9917127072  42.927599132  0.0060753603  5.7843055725  3400          0.6289313126 \n",
            "0.7582363385  0.7586819258  0.9996054449  0.9909234412  0.9991122509  0.9893449092  44.190175577  0.0043921365  5.7843055725  3500          0.6250557089 \n",
            "0.7938942592  0.7989344909  0.9983231407  0.9881610103  0.9973367528  0.9913180742  45.452752022  0.0058474739  5.7843055725  3600          0.6268724537 \n",
            "0.7414677451  0.7472375691  0.9993095285  0.9909234412  0.9994081673  0.9921073402  46.715328467  0.0069936835  5.7843055725  3700          0.6215211320 \n",
            "0.7010258434  0.7063930545  0.9998027224  0.9925019732  0.9993095285  0.9928966062  47.977904912  0.0050067931  5.7843055725  3800          0.6244132352 \n",
            "0.7601104754  0.7582872928  0.9984217794  0.9869771113  0.9954626159  0.9873717443  49.240481357  0.0033604602  5.7843055725  3900          0.6313518667 \n",
            "0.7292365358  0.7352012628  1.0000000000  0.9960536701  1.0000000000  0.9917127072  50.503057802  0.0013490497  5.7843055725  4000          0.6236331105 \n",
            "0.7278062734  0.7357932123  0.9999013612  0.9917127072  0.9997040836  0.9921073402  51.765634247  0.0003818883  5.7843055725  4100          0.6287024641 \n",
            "0.7287926613  0.7336227309  0.9989149734  0.9853985793  0.9990136122  0.9913180742  53.028210692  0.0050014239  5.7843055725  4200          0.6291932082 \n",
            "0.7303215624  0.7377663773  0.9999013612  0.9889502762  0.9997040836  0.9901341752  54.290787137  0.0019504495  5.7843055725  4300          0.6304660201 \n",
            "0.7283487867  0.7322415154  1.0000000000  0.9921073402  0.9992108897  0.9921073402  55.553363582  0.0029379294  5.7843055725  4400          0.6251601553 \n",
            "0.7387058591  0.7399368587  0.9985204182  0.9885556433  0.9974353916  0.9913180742  56.815940027  0.0021374228  5.7843055725  4500          0.6251562452 \n",
            "0.6670447820  0.6708760852  0.9999013612  0.9932912391  0.9989149734  0.9897395422  58.078516472  0.0064164825  5.7843055725  4600          0.6286752725 \n",
            "0.7800848294  0.7833464878  0.9954626159  0.9830307814  0.9954626159  0.9885556433  59.341092917  0.0082279910  5.7843055725  4700          0.6250292301 \n",
            "0.6997435392  0.7042225730  0.9991122509  0.9925019732  0.9993095285  0.9925019732  60.603669362  0.0060093180  5.7843055725  4800          0.6258044958 \n",
            "0.7043795620  0.7111286504  0.9996054449  0.9917127072  0.9991122509  0.9928966062  61.866245807  0.0029612238  5.7843055725  4900          0.6235942554 \n",
            "0.7195699349  0.7170481452  0.9990136122  0.9909234412  0.9976326692  0.9877663773  63.128822252  0.0055418774  5.7843055725  5000          0.6231913924 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVSmQgNyig5",
        "outputId": "d6ede5dd-1397-4f48-f18f-ba33b2f2faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3572696784  0.3620757695  0.4539356875  0.4613259669  0.4520615506  0.4723756906  0.0000000000  1.6331243515  5.6991815567  0             55.661369085 \n",
            "0.4934405208  0.4964483031  0.9753403038  0.9688239937  0.9762280529  0.9723756906  1.2625764451  0.1566427394  5.7843055725  100           0.6162090135 \n",
            "0.5097159203  0.5185477506  0.9811599921  0.9775059195  0.9777076346  0.9668508287  2.5251528901  0.0377939333  5.7843055725  200           0.6225361347 \n",
            "0.5271256658  0.5380820837  0.9936871178  0.9881610103  0.9930952851  0.9861878453  3.7877293352  0.0288028434  5.7843055725  300           0.6236338639 \n",
            "0.4824422963  0.4968429361  0.9942789505  0.9877663773  0.9955612547  0.9909234412  5.0503057802  0.0388437792  5.7843055725  400           0.6268619251 \n",
            "0.5513908069  0.5586029992  0.9965476425  0.9869771113  0.9954626159  0.9869771113  6.3128822253  0.0148880032  5.7843055725  500           0.6201543760 \n",
            "0.4632570527  0.4727703236  0.9920102584  0.9794790845  0.9947721444  0.9857932123  7.5754586703  0.0180947598  5.7843055725  600           0.6200311804 \n",
            "0.3317715526  0.3326756117  0.9895442888  0.9767166535  0.9944762281  0.9893449092  8.8380351154  0.0098999443  5.7843055725  700           0.6183829451 \n",
            "0.4919609390  0.4948697711  0.9970408365  0.9865824783  0.9965476425  0.9857932123  10.100611560  0.0145966782  5.7843055725  800           0.6291699719 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUY2J85V-Ad",
        "outputId": "9e6fcdee-21bb-48d4-e2a2-b3f4f60d6298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.9 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.9 +/- 0.0               72.9                      \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.0 +/- 0.0               72.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output_M2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFubiAzerSGY",
        "outputId": "f7a88181-e706-4af8-a327-0b1490d252a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                    | 0/13 [00:00<?, ?it/s]\r                                                                                \rTotal records: 53\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               76.5 +/- 0.0               76.6                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               71.5 +/- 0.0               74.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2WzQYG9FSV",
        "outputId": "66d56659-a265-45fe-fb14-15d19d5c51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: train_output\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             99.749756574 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.5983280587 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6206359911 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6142829299 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6070183587 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6080141449 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6082016397 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6092026901 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6103980064 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6360183382 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6049654841 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6108168197 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6118657756 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6163139319 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6108947682 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6053397083 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6072963905 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6118159246 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6154971886 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6100856686 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6081331706 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6135662699 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6160948730 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6087784386 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6098929572 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6067762327 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6125501800 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6110928893 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6085288739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6073611617 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6072861338 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6083596730 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6128425336 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6068048215 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6056645203 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6041939640 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6081425190 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6051037884 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6070308352 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6057835174 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6114358330 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6085151696 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6074985671 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6056443095 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6110575628 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6077594399 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6041522574 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6092551422 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6140078497 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6102016497 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6084288812 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0 \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyPsM8-qTs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/train_output /content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeSXi_BAsw2",
        "outputId": "f8a407f0-e5b5-4577-e522-74fb8eb078eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 102\n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        76.5 +/- 0.0               62.0 +/- 0.0               69.3                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.5 +/- 0.0               65.6 +/- 0.0               68.5                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxPRKSpd7tW",
        "outputId": "e0a98e3b-2119-4b5a-d89a-0b08cc774ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
            "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
            "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
            "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 78, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
            "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
            "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
            "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/stringpict.py\", line 15, in <module>\n",
            "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Colab执行train.py脚本\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py\\\n",
        "        --data_dir=./domainbed/data/MNIST/\\\n",
        "        --algorithm IGA\\\n",
        "        --dataset ColoredMNIST\\\n",
        "        --test_env 2\n",
        "\n",
        "#启动python3解释器，并且执行名为train.py的python脚本\n",
        "#--data_dir, --algorithm, --dataset, --text_env是train.py文件中的命令行参数，命令行参数用来制定程序或脚本执行书所需要的配置，选项或参数。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXA5s87_0FX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 读取图像\n",
        "img = cv2.imread('input_image.jpg')\n",
        "\n",
        "# 创建与输入图像相同大小的掩码\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "\n",
        "# 创建前景和背景模型\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "# 定义一个矩形ROI，用于指定图像中的前景对象\n",
        "rect = (50,50,450,290)\n",
        "\n",
        "# 使用GrabCut算法进行图像分割\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# 将掩码中的可能的前景和可能的背景区域设置为0和2\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# 将原始图像与掩码相乘以获取前景对象\n",
        "img = img*mask2[:,:,np.newaxis]\n",
        "\n",
        "# 显示结果\n",
        "cv2.imshow('Result', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8MAbsYPTOg",
        "outputId": "4e5ff9f9-5fbd-4dbc-8b46-79903673f419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=\"/env/python:/content/DomainBed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tbOpWGPat2",
        "outputId": "f18a4248-822b-47e9-ae93-45ef19092c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLo5O4wdhf9",
        "outputId": "2f40c461-8185-4792-f68e-3a0b676773ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a5269aa7743b791c64ed6649418c057a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 575962639\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/173bf54d6d078902e3c95d84cd058342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 177603528\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/35d2062ac241826e2573114eb184c10b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1731344775\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 7.625215427542097e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.00047223799345445756\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/30fd34e2f4f278867b6ff5b3217c9af4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1643360463\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/93cbbc15feea120dcb5ef40876e5d339\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1552394041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b85999a8f7f51d5d4618de70657b6458\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 872123425\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7c7b782b06a6e854e2a90f87af941fab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1532722295\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ad9ee36f7c977d2e63461bd67f281f65\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1348154927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c6917ed9721df5093c80bb496ec569e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1049203149\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 12\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e09d3ae124ba408cc7b777e802abfc3b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 820509365\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.0061945703598755e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0003150750110930775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ec6ad8a352a25d018524a0799865c9c7\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 305456027\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a12555295bb7c7f7b16f49fa46aa6d43\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 335001469\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3933a42f4a7daf484c66126f193511cd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1090282834\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e0caf4e9b7f63f5f2e9dfc9c2cbd706f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 707756686\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.7028930742148706e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00044832883881609976\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a8bfbb8d29ad30056577251d58640c92\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1803180728\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3e97244e0bba4eff7f3112b1a237b744\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 988398352\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.5948054187960416e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.2409030903340844e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c56965d1318c614519d8d1aeeec2acc0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1033766585\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/359830bd171b960b8f49828cf7daea45\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1062091682\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c71071003a4a8e03d31fbc73dc56b251\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1323517681\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c21df39fbbbbff9e17a2219b8a0bdb4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 899531956\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.1059719178287245e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0226894592810383e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/144f7e007023484daf0f1835e105fa02\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1174342691\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00028242988155030726\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.0915251755880437e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/60e1b946d5dfb28c75817cb3b0f37895\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 894262147\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 15\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.768725917122619e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.692204119563736e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9e4750f5e7cdef36d12c41b1a6b11d8b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 430670040\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/d407d5a24ac774b5d0e87374d7bb0dcc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 939727439\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9b1089b3fd6bf0f3ece44fc77e993b3e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 406951466\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/eb213ec0817439be32acdbd077992b09\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 471015569\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa8f08ae34d3dae732c41aa5d02c8316\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 534836152\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/48d90e374515bb88643f4e2e9410980b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1405017170\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.456280188921339e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.005463379786545902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/123c1a60dc113b3ef130905aab29cf61\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1450517853\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/6830b2706bf869ab62120c8ec8a3d902\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1428592723\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3826168925328977e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.615900325399353e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a928b33eb83a3c2cd3efa5ea3f1ea8d9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1629628786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/476612568012d54c53a90e62b696d7bb\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1884237580\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 19\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f87bb4114b1895f7916f2b4ffc4cb860\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 536959106\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 11\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.323285967621206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.046120234156778e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b796a096bf44125b17789f4408dca06b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1903818547\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2eee150674bdf7a82d8c51eb4b1ce04a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 23433006\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/abc93fad1fd1056001dbadf8a1ca9e19\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1664885690\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1d6201f69bb66d8b6e489eda38dccc2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1064525671\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/61034eaa8320196809d9f605b075ea24\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 95358269\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a2a7ca35a2f50073f1242eb91762424c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1823278137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/09c50cd0748144c2769d47af395d8a2f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 809856719\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4134e9367b6221b835b22b88489a951d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 164181522\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dff4b52c83c4125df3323fd2db2b9f81\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 275388093\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b91c3a1a306c19c073d526f06d69ba03\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 216618918\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2c1b55962114ca954a4293b359288011\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 441369813\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5f9a4b767b89224a4075aee4b86b6256\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2034037337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002383446436179699\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 6.431270010222042e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/8b64798c53a5a1bba405d5c75dbf27e9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 693005437\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4b0c702dd74c39ad2ca842e5f3fc8ffc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1721323264\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5c18fb7899bf0c12dc359ebe9c1081d6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 244140596\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a44e96d250f70e7917800a5786e1f2fe\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 338717337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7d28429d6d35cc9f06f22e3a55845051\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1588968328\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002748180350891229\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.9000025480760227e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/991425b1146b1f446d84b36c087a6ef2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 895393786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/23a434a5febeed79a9ed9afeeb610ea9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1005706515\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e31aa2e37b983f5aa514b6243bb897e4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 539823350\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/97caedc9c298c79240b7148e65bd4864\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 848241137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/37de55f16c6cadbf954bb9c28018c6c9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1441525987\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1b86d2e19fa131d32841fa95fc15428\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1025341559\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.079846025444368e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.634713155314057e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84459224cbcb079b22304c4ca0337b15\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 658930196\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/840cda333a109b446d2d0be1aec01f44\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 797173368\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/0db98c8fc5bbd3ad85f5198cd2a9e242\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1690752950\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/00bb81be3e5faa7fa0e06a3d1b9fc214\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 640543768\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 35\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.203148467315319e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.5941595326730853e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a3cf6270845a5d9f19504a02c74d48d8\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 527331476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b719be2f2334c73ca22825242a857d83\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 794168150\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84dc1acf1587fab8013f239b8ee2a854\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 140411788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3b7e19147f067cefd3e300112c5744d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 889114309\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2bd0763b666af3a8b7180488e49f5df1\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1600026954\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ee01751ed5822f49800f2dff6d39011c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 652031788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a1fc347c08f7519f1a9885e2e4e1cc5a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2028568414\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3967520349d463cc0f4b42aa0e5a3cdc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2011109722\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a068a437f435df1e975b81101ea52090\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 887238287\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dcded23bc701bc64d1143bea8426fa7a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 874017095\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b338ef7ae36014cea7290002c49cdeab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 397958724\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7fcd0102087c6411f477f01e6e94adcd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1653294381\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f5541915a154a7ea2d59d32511dca70e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1008122992\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f4402201077fefda135d3f266680fb9d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1974935474\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fef9439cc09895fc8d5ed384d557aa2e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1905078720\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/21ce002219dcf5223be83527bc032575\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 16214241\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fae278ee4d6005566e976812d300076e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1838315136\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/15aef282c233ccf23bb82500660e4a85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1806374394\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/95dcaf3d7552b20d324e650e8344e391\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2139648535\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b59d08c5158891d095647c260599df72\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 863415268\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/396a66c0e9a33f42933162e9e157a7f6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1028178153\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/40a2ab0a6403041f72bcd672cd9685a6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2114559099\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dd31f52ac86bba2d9ad1ffdeee34c342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2029184004\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9cb8aefc8442b126f9c05a7cce526779\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 902654909\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/398e724ba11d5f6f2445d5b356ace1b0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1764407478\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4256491a7b9ddea5fd4f3b9404ed7948\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1041059927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa922f8e301f7a452a7d7802449b8900\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1622227716\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/bc89363eaa59127ca10cf772d2c57263\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1192519524\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/56102dff2a7005ef5db4c5933673ea85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 152054124\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 21\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00011281359420053416\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 5.000446907120253e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3f28d0e95f209ff5df269857a136372\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 472711008\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4514b27fbe9c296ab91cd05de3734f5e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1704833476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00015197093111758464\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0329604555494109e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9222fb7e414cd07468f4347ff233885d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 463949901\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4d35045a63b1eff681e8a628d2988b23\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 37332015\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.1375153221880086e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 6.326696718610415e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f936c2b44cc3dab85a923d914871cc4a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1141715041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c08bd5bdc0e4a927433e11e6f552089e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1353102125\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/205162f67cb34c386d1288cf23a3e73f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1743459794\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Launched 360 jobs!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.sweep launch\\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224\\\n",
        "       --output_dir=/content/MyDrive/ip/sweep_output\\\n",
        "       --command_launcher local\\\n",
        "       --algorithms ERM\\\n",
        "       --datasets SpawriousO2O_easy\\\n",
        "       --skip_confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr393evgOlTE",
        "outputId": "ace5ca35-edc0-49e3-ff67-4f086f769414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in directory: /content/domainbed/data\n",
            "MNIST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 指定要查看的目录路径\n",
        "data_dir = '/content/domainbed/data'  # 这里替换为你下载数据的目录路径\n",
        "\n",
        "# 列出指定目录下的文件和文件夹\n",
        "files_and_folders = os.listdir(data_dir)\n",
        "\n",
        "# 输出文件和文件夹列表\n",
        "print(\"Files and folders in directory:\", data_dir)\n",
        "for item in files_and_folders:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLTQ7T-5lgV"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peRMyZEz54u3",
        "outputId": "4d3a351e-775f-465a-a50d-86f28087b753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnjVjGVkZAQy"
      },
      "source": [
        "将所有图片转换成rgb形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZYfhASF-6u"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hzsjtd9Fn2k"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/ip/spawrious224/\"\n",
        "hparams = {\"data_augmentation\": True}\n",
        "test_envs = 0\n",
        "spawrious_o2o_easy = SpawriousO2O_easy(root_dir, test_envs, hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ByCqk5tsF2L8",
        "outputId": "bee03919-976b-48c0-fa21-5842a7b81a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'build_type1_combination' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-d9a268ae9e32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_type1_combination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_type1_combination' is not defined"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_o2o_easy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "8bwrHD3Qsnwv",
        "outputId": "2062da6d-58a0-4ecd-e19d-3fbc65dac0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [01:48<00:00, 29.17it/s]\n",
            "  4%|▍         | 136/3168 [00:32<12:02,  4.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-115b0497dc50>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0munloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk43pd2wZJ0M"
      },
      "source": [
        "寻找corgi类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUk9545INv",
        "outputId": "1c907d20-5c53-4e72-a511-78a91db9bbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corgi_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2441.png', 'drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2.png'), 'corgi')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "\n",
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/corgi/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "\n",
        "corgi_image_pairs = []\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, 'corgi'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "\n",
        "# 将 corgi_image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(corgi_image_pairs, f)\n",
        "\n",
        "print(\"Corgi_image pairs saved successfully.\")\n",
        "print(corgi_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeA1A4ALZNYR"
      },
      "source": [
        "寻找bulldog类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyT3OSv5IQT",
        "outputId": "585e03c4-a5f5-45a1-c88f-c595dffa4f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Bulldog_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/bulldog/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    bulldog_image_pairs.append((image_pair, 'bulldog'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(bulldog_image_pairs, f)\n",
        "\n",
        "print(\"Bulldog_image pairs saved successfully.\")\n",
        "print(bulldog_image_pairs[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZakjqAa0mfd",
        "outputId": "cb31c59b-f8c1-4cdc-c285-42c4174ee333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulldog\n"
          ]
        }
      ],
      "source": [
        "print(bulldog_image_pairs[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5rsjqJZRZA"
      },
      "source": [
        "寻找dachshund类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECFZVVm5ISR",
        "outputId": "4ae21f17-ad08-4abf-b6b4-32a0599c1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Dachshund_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/dachshund/jungle_dachshund_2902.png', 'drive/MyDrive/ip/spawrious224/0/dirt/dachshund/dirt_dachshund_343.png'), 'dachshund')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/dachshund/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, 'dachshund'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(dachshund_image_pairs, f)\n",
        "\n",
        "print(\"Dachshund_image pairs saved successfully.\")\n",
        "print(dachshund_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rg9-OhsZW5L"
      },
      "source": [
        "寻找labrador类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJlI-7ZYi36",
        "outputId": "46c742ff-2dfa-4b2b-b784-b0159d897f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "labrador_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_1201.png', 'drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_563.png'), 'labrador')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/labrador/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, 'labrador'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(labrador_image_pairs, f)\n",
        "\n",
        "print(\"labrador_image pairs saved successfully.\")\n",
        "print(labrador_image_pairs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZrnXz155UP",
        "outputId": "53e9bcbf-5edf-4b44-ca94-7e3105e3d6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_84.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1530.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_767.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1743.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2387.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_760.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_277.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_726.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2953.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_108.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3163.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2315.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2777.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1187.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_453.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_15.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2413.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_561.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_924.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_232.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1990.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1076.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_72.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1741.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2743.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_239.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_325.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1091.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_570.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_358.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_892.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3150.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2448.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3015.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_186.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1691.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1509.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_642.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1888.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_150.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2282.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3003.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1379.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2980.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2456.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2364.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2308.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_248.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2026.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2679.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_307.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2849.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1887.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3136.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2786.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3000.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_470.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2965.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_791.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2599.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3161.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1707.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1886.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_830.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2378.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_916.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_768.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2295.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2137.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1126.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2966.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1845.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_232.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2885.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1513.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2699.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1051.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_159.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2067.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2853.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_98.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2226.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1131.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1441.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2613.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2625.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_877.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_424.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2505.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2908.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_535.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1043.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_663.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1536.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1818.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1616.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2796.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_376.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1318.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_261.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1939.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1933.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2282.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1356.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_6.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_222.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2452.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2738.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1883.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2041.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_895.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3084.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_167.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2461.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2204.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1463.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2982.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_541.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1523.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2483.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1299.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_867.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2379.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_1309.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2053.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2740.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_920.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_2389.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2985.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_2435.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_803.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1697.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_291.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1006.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1563.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1796.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1753.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2466.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_935.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2864.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1505.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_772.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1364.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3008.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2936.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_364.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1347.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_797.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1124.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1574.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1934.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2514.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_52.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1388.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2320.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2129.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_3076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1084.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_329.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2630.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_2588.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2372.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_730.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2140.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2166.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3046.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1634.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1942.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_839.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_473.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_420.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_30.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2847.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2576.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2185.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_923.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1769.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_508.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_486.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_3099.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1973.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_244.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2066.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3054.png'), 'bulldog')]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 打开 .pkl 文件\n",
        "file_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 查看文件中的数据\n",
        "print(data[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaxZX0939Vu",
        "outputId": "88087c2c-bcfe-4b6a-a3f4-22a7b0ea6311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png',\n",
              "  'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'),\n",
              " 'bulldog')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 定义一个函数来加载单个 .pkl 文件\n",
        "def load_pkl(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 定义多个 .pkl 文件夹的路径\n",
        "file1='drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "file2='drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "file3='drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "file4='drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "file_paths = [file1, file2, file3, file4]\n",
        "\n",
        "# 合并\n",
        "merged_data = []\n",
        "for file_path in file_paths:\n",
        "    data = load_pkl(file_path)\n",
        "    merged_data.extend(data)\n",
        "\n",
        "\n",
        "merged_data[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG4ZrbJW7gNT"
      },
      "source": [
        "定义图像变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fnPAS-3b7ff1",
        "outputId": "3a41426e-6d81-4bfb-b9cb-59838d2ff4ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 62094/152064 [15:29<22:26, 66.80it/s]    \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c26271761609>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtransformed_image_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 定义图像变换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整大小为 224x224\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 对 merged_data 中所有图片路径应用变换\n",
        "transformed_data = []\n",
        "for image_pair, category in tqdm(merged_data):\n",
        "    transformed_image_pair = (transform(Image.open(image_pair[0])), transform(Image.open(image_pair[1])))\n",
        "    transformed_data.append((transformed_image_pair, category))\n",
        "\n",
        "# 输出变换后的数据\n",
        "print(transformed_data[1])\n",
        "\n",
        "\n",
        "dataloader = DataLoader(transformed_data, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsDg8lb7Lo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "# 定义自定义数据集类\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义 ResNet18 模型\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)  # 修改最后一层全连接层，输出为2类（假设是二分类任务）\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 准备数据集\n",
        "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', ...]  # 假设这里是你的图像数据集路径列表\n",
        "transform = transforms.Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "dataset = CustomDataset(image_paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch_images in enumerate(dataloader):\n",
        "        inputs = batch_images\n",
        "        labels = torch.randint(0, 2, (batch_images.size(0),))  # 假设这里是随机生成的标签\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # 每 10 个 mini-batch 输出一次损失值\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR2Se1J7LrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCvom3K7LtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dSlXY-7LvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar0YMs7R7LxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW2CdWBYwpu",
        "outputId": "c5e3a98e-6ec4-445d-b016-181739cbdc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image size is 224 pixels wide by 224 pixels high.\n"
          ]
        }
      ],
      "source": [
        "# 替换下面的路径为你图像的实际路径\n",
        "image_path = '/content/drive/My Drive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png'\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# 获取图像的大小\n",
        "width, height = img.size\n",
        "\n",
        "# 打印图像的大小\n",
        "print(f'The image size is {width} pixels wide by {height} pixels high.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiRyFGtY8iJ",
        "outputId": "5bc07ce5-0670-4e35-910a-e2d5bbc58c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'spawrious224_rgb': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56vrZ45Ywri"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 提取特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 定义图像预处理步骤\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整图像大小为 ResNet18 模型的输入大小\n",
        "    transforms.ToTensor(),  # 将图像转换为 Tensor 格式\n",
        "])\n",
        "\n",
        "# 加载 RGB 图像并进行预处理\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 添加 batch 维度，变成一个大小为 (1, C, H, W) 的 Tensor\n",
        "\n",
        "# 将图像输入到 ResNet18 模型中，并提取全局平均池化层的输出\n",
        "with torch.no_grad():\n",
        "    features = feature_extractor(input_batch)\n",
        "\n",
        "# 将特征转换为一个向量（reshape 为 (1, num_features)）\n",
        "global_avg_pooling_output = features.view(features.size(0), -1)\n",
        "\n",
        "# 输出向量的大小\n",
        "print(\"Global Average Pooling Output Shape:\", global_avg_pooling_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHUMXcfxBRH",
        "outputId": "5023f978-9943-4b52-db95-3917306e8d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape: torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH72AAHsxBTv",
        "outputId": "a309654e-c496-4611-d74e-d199df8e5239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape (with pooling): torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp4djmqsxBWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ7JRGRmxBYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sOryq0lgGL",
        "outputId": "aef2dd6a-3c69-42b0-e04c-713082b138eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
            "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
            "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
            "        ...,\n",
            "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
            "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
            "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]],\n",
            "       requires_grad=True)\n",
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# 加载预训练的 ResNet-18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 截取特征提取器部分（不包括最后的全连接层）\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "weights=model.fc.weight\n",
        "print(weights)\n",
        "print(len(weights))\n",
        "\n",
        "\n",
        "\n",
        "# 加载并预处理上传的两张图片数据\n",
        "image1_path = 'path/to/your/first/image.jpg'\n",
        "image2_path = 'path/to/your/second/image.jpg'\n",
        "image1 = preprocess_image(image1_path)\n",
        "image2 = preprocess_image(image2_path)\n",
        "\n",
        "# 提取图片的特征向量\n",
        "with torch.no_grad():\n",
        "    feature1 = feature_extractor(image1)\n",
        "    feature2 = feature_extractor(image2)\n",
        "\n",
        "# 对提取的特征向量进行全局平均池化操作\n",
        "global_avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "feature1_vector = global_avg_pool(feature1).squeeze()\n",
        "feature2_vector = global_avg_pool(feature2).squeeze()\n",
        "\n",
        "# 打印两个特征向量\n",
        "print(\"Feature vector for image 1:\", feature1_vector)\n",
        "print(\"Feature vector for image 2:\", feature2_vector)\n",
        "\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#定义损失函数\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "\n",
        "        # 自定义损失函数的计算过程，这里假设是平方误差损失\n",
        "        loss = torch.mean((output - target)**2)\n",
        "        return loss\n",
        "\n",
        "#定义损失函数\n",
        "def loss():\n",
        "  lam_loss_all=0\n",
        "  for i in range(batch_size):\n",
        "\toriginal=Feature map[i]\n",
        "\tpair=Feature map[10+i]\n",
        "        y_1=y[i]\n",
        "        w=Classification head weight[y_1]**2\n",
        "\tdistance=(original-pair)**2\n",
        "        lam_loss=0\n",
        "        For k 1to 2048:\n",
        "              lam_loss+=w[I]*distance[I]\n",
        "\tlam_loss_all+=lam_loss\n",
        "\n",
        "lam_loss_all/=10\n",
        "\n",
        "loss=erm_loss+lambda*lam_loss_all\n",
        "\n",
        "#开始训练\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # 解压当前 batch 中的图片对\n",
        "        images1, images2 = batch\n",
        "\n",
        "        # 前向传播\n",
        "        outputs1 = model(images1)\n",
        "        outputs2 = model(images2)\n",
        "\n",
        "        feature1 = feature_extractor(images1)\n",
        "        feature2 = feature_extractor(images2)\n",
        "\n",
        "        # 计算损失\n",
        "        loss = loss_fn(outputs1, outputs2)\n",
        "\n",
        "        # 反向传播与参数更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 打印当前损失\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# 定义优化器，并将所有参数添加到优化器中\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 训练过程中的损失计算示例\n",
        "# 假设 inputs 是模型的输入数据，targets 是真实标签\n",
        "#outputs = model(inputs)\n",
        "\n",
        "\n",
        "#loss = criterion(outputs, targets)\n",
        "\n",
        "# 反向传播与参数更新\n",
        "#optimizer.zero_grad()\n",
        "#loss.backward()\n",
        "#optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8AYk6QV59s0",
        "outputId": "1d1fd7af-edde-41d9-f342-9d9d3297ec39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "images = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png\")\n",
        "inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "image_features = model.get_image_features(**inputs)\n",
        "image_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRBhDp1-EQK",
        "outputId": "db7e1d1e-4b2b-46dc-db74-248de8d8e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8947], grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_6.png\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "other_features = model.get_image_features(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "similarity = torch.cosine_similarity(image_features, other_features, dim=1)\n",
        "print(similarity)\n",
        "\n",
        "#similar_images.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNpx89JdYAW"
      },
      "outputs": [],
      "source": [
        "# tensor --> numpy array\n",
        "# 10*768 --> 10*10\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "pairwise_cos=cosine_similarity(all_features_image0, all_features_image0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzY4-Bg9amE0",
        "outputId": "2c8648e7-753e-4e45-f242-874989629e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The path of the file is: /content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 要查找的文件名\n",
        "filename = 'train.py'\n",
        "\n",
        "# 使用 os.walk() 函数遍历文件系统，查找文件\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        print(\"The path of the file is:\", file_path)\n",
        "        break\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4ydb8Tf1ZL"
      },
      "outputs": [],
      "source": [
        "import domainbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHz6ikvEbKB4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# 将当前工作目录添加到模块搜索路径中\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXILhm1Z5Lu",
        "outputId": "bc18d9c5-2477-4aec-db5a-4a9f44a6515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    from domainbed import datasets\n",
            "ModuleNotFoundError: No module named 'domainbed'\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/DomainBed/domainbed/scripts')\n",
        "\n",
        "\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py  --data_dir=./domainbed/data/mnist_data/MNIST/MNIST/raw\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHZs22kIHITz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEui0DbG2T-"
      },
      "outputs": [],
      "source": [
        "import domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ccrCEUpIe3U",
        "outputId": "973b3d5a-7e54-40c2-c79f-c33db6b566b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import domainbed.scripts.train\n",
        "print(domainbed.scripts.train.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_8DJU6GQkP",
        "outputId": "647d4860-e9ce-4939-ed22-e6fbcbf2c271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6nF9hh2B20I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed/domainbed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpBUtnGDDP_T",
        "outputId": "e0bdf4c4-f6a2-4ee1-c05c-469b1ac9223c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "domainbed 模块已经上传到 Colab 环境中。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 列出当前目录下的文件和文件夹\n",
        "files_and_folders = os.listdir()\n",
        "\n",
        "# 检查是否有 domainbed 相关的文件或者文件夹存在\n",
        "if 'DomainBed' in files_and_folders:\n",
        "    print(\"domainbed 模块已经上传到 Colab 环境中。\")\n",
        "else:\n",
        "    print(\"domainbed 模块未上传到 Colab 环境中，请上传该模块。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "U73FCwSYCtHs",
        "outputId": "9eedd15b-ca7a-44e8-9c8a-62b6fc3c7c1e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'DomainBed.scripts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-671f19c45cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDomainBed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DomainBed.scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import DomainBed.scripts.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104WHdolBMr9",
        "outputId": "9532160a-2771-495f-edbe-236058077489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/DomainBed/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-wDOYOGcrBd",
        "outputId": "1c155a51-cb25-4d33-cef8-b9d66beba886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CODE_OF_CONDUCT.md  CONTRIBUTING.md  domainbed\tLICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tpA8g5crEd",
        "outputId": "4c37650f-6c66-41ca-a43b-a054019e7395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed\n"
          ]
        }
      ],
      "source": [
        "%cd domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpMP-JYcrG8",
        "outputId": "a5671b8c-1378-43db-800d-025f0fd06a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/DomainBed/domainbed/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9j-jXU4qnV",
        "outputId": "9a47a5e4-38bc-4ad0-9e0a-116112baebe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c2d66b9d68e869eab2d7fb0ceb797bc93c5a2eba8da460ac75e6fa1222eaeafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Pwi1MG4s0Q"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLqCJYk6Z-H"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(\"local\", \"Example App\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoTkcfW9crKX",
        "outputId": "51c83067-2d6c-4cfe-ab10-a058f03451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = sc.parallelize(range(1, 100))\n",
        "t = 50\n",
        "B = A.filter(lambda x: x < t)\n",
        "B.cache()\n",
        "t = 10\n",
        "\n",
        "C = B.filter(lambda x: x > t)\n",
        "\n",
        "print(C.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722a2LCPcrMx",
        "outputId": "dc6f003d-0d78-4ad2-94f9-3dddb67f9ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product: 233\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "def dot_product(rdd1, rdd2):\n",
        "  zipped_rdd = rdd1.zip(rdd2)\n",
        "  dot_product = zipped_rdd.map(lambda x: x[0]*x[1]).reduce(lambda x,y:x+y)\n",
        "  return dot_product\n",
        "\n",
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "result = dot_product(r1, r2)\n",
        "print(\"Dot product:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pdehnc-7kN6",
        "outputId": "0bfc6140-a0ec-4ffd-895c-cef3f0637ee2"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e471822f655>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the total dot product by summing up the partial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtotal_dot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot product:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_dot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "# Induce a different partitioning\n",
        "r2 = r2.flatMap(lambda x: [] if x == 1 else [x])\\\n",
        "       .flatMap(lambda x: [9, 9] if x == 9 else [x])\n",
        "\n",
        "def compute_dot_product(partition):\n",
        "    partial_sum = 0\n",
        "    for x, y in partition:\n",
        "        partial_sum += x * y\n",
        "    yield partial_sum\n",
        "\n",
        "dot_product_rdd = r1.zip(r2).mapPartitions(compute_dot_product)\n",
        "\n",
        "# Compute the total dot product by summing up the partial results\n",
        "total_dot_product = dot_product_rdd.reduce(lambda x, y: x + y)\n",
        "\n",
        "print(\"Dot product:\", total_dot_product)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13af87f2c8324581bd9f46ec89021fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4f18ac33c1c422285be743c98061adc",
              "IPY_MODEL_44bcd236741f482ab47931207aba574a",
              "IPY_MODEL_8a566ac1b65c49e2ab73d4b6cfff2e34"
            ],
            "layout": "IPY_MODEL_9ee4e698d268447fac1c3ee92d95411d"
          }
        },
        "d4f18ac33c1c422285be743c98061adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c536fab538490583199cd268783dca",
            "placeholder": "​",
            "style": "IPY_MODEL_fa1ee5dd8b134b0e94451a222b46839c",
            "value": "config.json: 100%"
          }
        },
        "44bcd236741f482ab47931207aba574a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af14a07d61d4ef1ae01b544dbd3a5b1",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87801aa7d35e4e7189a6b085ae1dfb68",
            "value": 4186
          }
        },
        "8a566ac1b65c49e2ab73d4b6cfff2e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_707daa8dfecf4d4f80003d5075523e41",
            "placeholder": "​",
            "style": "IPY_MODEL_ff563ca8d7d343a688d33be98daa23a6",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 317kB/s]"
          }
        },
        "9ee4e698d268447fac1c3ee92d95411d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c536fab538490583199cd268783dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa1ee5dd8b134b0e94451a222b46839c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af14a07d61d4ef1ae01b544dbd3a5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87801aa7d35e4e7189a6b085ae1dfb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "707daa8dfecf4d4f80003d5075523e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff563ca8d7d343a688d33be98daa23a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2747a1020114b0f9d06c6a1106a0713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b269ec6eb724e1b85e03aeed185d9d3",
              "IPY_MODEL_30d60635407542e6b554d75c385fbe8a",
              "IPY_MODEL_e193fcc2d94046b6a8fef6cad7e67300"
            ],
            "layout": "IPY_MODEL_b31d1d9f1b284f509c311ec8e358e611"
          }
        },
        "0b269ec6eb724e1b85e03aeed185d9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8613db8ed4e44ad295f70a9971ee7cce",
            "placeholder": "​",
            "style": "IPY_MODEL_19c8dbc899c7434487873d1f05a98aa1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "30d60635407542e6b554d75c385fbe8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b12649ad7c246ea904a1a73c4fd0744",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aea355581a5b4fa8b245ab89994a1b33",
            "value": 605247071
          }
        },
        "e193fcc2d94046b6a8fef6cad7e67300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1188bc8f2e684eaaa47f7b70fbdc8629",
            "placeholder": "​",
            "style": "IPY_MODEL_53d6e534c5974eddad7c28b08a343145",
            "value": " 605M/605M [00:02&lt;00:00, 336MB/s]"
          }
        },
        "b31d1d9f1b284f509c311ec8e358e611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8613db8ed4e44ad295f70a9971ee7cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c8dbc899c7434487873d1f05a98aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b12649ad7c246ea904a1a73c4fd0744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea355581a5b4fa8b245ab89994a1b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1188bc8f2e684eaaa47f7b70fbdc8629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d6e534c5974eddad7c28b08a343145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d48610cd04c0414e8969c450f0093c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de6325a3356c4fa7b3240b8507916771",
              "IPY_MODEL_609c3c5ddcf84744bb8868eccdcba82b",
              "IPY_MODEL_0bb20509e2674c08a60e286dff677f55"
            ],
            "layout": "IPY_MODEL_85e0ddbe144c46cea745f2aef93fa604"
          }
        },
        "de6325a3356c4fa7b3240b8507916771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8267386b63074894844d8d43c46702dc",
            "placeholder": "​",
            "style": "IPY_MODEL_5dde775d992e4fdcb53cb98e97cb12c7",
            "value": "config.json: 100%"
          }
        },
        "609c3c5ddcf84744bb8868eccdcba82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62da91797130404f81c6b35bcbb49675",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3df8ed4247284715b56add188894d194",
            "value": 4186
          }
        },
        "0bb20509e2674c08a60e286dff677f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ef7828d66f42d39247a65e543d627d",
            "placeholder": "​",
            "style": "IPY_MODEL_fc44b5d9e39644e2a4f7b72be24ee8b3",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 304kB/s]"
          }
        },
        "85e0ddbe144c46cea745f2aef93fa604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8267386b63074894844d8d43c46702dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dde775d992e4fdcb53cb98e97cb12c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62da91797130404f81c6b35bcbb49675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df8ed4247284715b56add188894d194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08ef7828d66f42d39247a65e543d627d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc44b5d9e39644e2a4f7b72be24ee8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f42bbeebeec34811946f0f81e3ebefe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5df2e94ce1bf4a699a4a2a2f4fbe0705",
              "IPY_MODEL_61041f90f7324994a0d9a046d279f1c2",
              "IPY_MODEL_26643df9223942e9b0543e65c3356f10"
            ],
            "layout": "IPY_MODEL_e17320efe8da4d6a975af85ab0e06ec6"
          }
        },
        "5df2e94ce1bf4a699a4a2a2f4fbe0705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174a5648a1e84f3d834506a643560f99",
            "placeholder": "​",
            "style": "IPY_MODEL_3493e422359e4c7da44cd5284e44d8c1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "61041f90f7324994a0d9a046d279f1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8844f88681e640839cbd4bf3b039397d",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6577bd5578ea478586fc10488c53c600",
            "value": 605247071
          }
        },
        "26643df9223942e9b0543e65c3356f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5e32770f7ea495cb6d31abcf138e9e7",
            "placeholder": "​",
            "style": "IPY_MODEL_0fc4679fe68a4f91ae0d89806ebf7d2a",
            "value": " 605M/605M [00:09&lt;00:00, 56.0MB/s]"
          }
        },
        "e17320efe8da4d6a975af85ab0e06ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174a5648a1e84f3d834506a643560f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3493e422359e4c7da44cd5284e44d8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8844f88681e640839cbd4bf3b039397d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6577bd5578ea478586fc10488c53c600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5e32770f7ea495cb6d31abcf138e9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc4679fe68a4f91ae0d89806ebf7d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}