{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzVjng0cq4V",
        "outputId": "547ab4a4-bc06-421f-8326-da2d1aede073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1308, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1308 (delta 26), reused 24 (delta 11), pack-reused 1259\u001b[K\n",
            "Receiving objects: 100% (1308/1308), 1.09 MiB | 12.35 MiB/s, done.\n",
            "Resolving deltas: 100% (764/764), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HApsEKnU5rM2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxCp4JTdivj",
        "outputId": "445bfd56-efca-45a1-945e-08f57b788298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjylGMPbTZEl",
        "outputId": "a8fb21f9-5f50-44a0-e73a-c6e68b496650"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa_F2E_wzly"
      },
      "source": [
        "Convert images to /content/...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_g-N8vfERdY",
        "outputId": "1ce6b251-b814-4e4a-fea6-bb62131849cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wilds\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.25.2)\n",
            "Collecting ogb>=1.2.6 (from wilds)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outdated>=0.2.0 (from wilds)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (9.4.0)\n",
            "Requirement already satisfied: pytz>=2020.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (2023.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from wilds) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from wilds) (1.11.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.2.6->wilds) (2.0.7)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->wilds) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->wilds) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->wilds) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->wilds)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->wilds) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->wilds)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->wilds) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->wilds) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->wilds) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb, wilds\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wilds\n",
        "# 安装wilds模块\n",
        "# 使用wilds可以帮助研究人员更好地评估他们的机器学习算法在实际应用中的性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r_kfReEsJhNO"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NQUkwkKPp6Us"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from download import download_spawrious"
      ],
      "metadata": {
        "id": "QcFueQOivecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-gdbwEqDy2A"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/ip1\"\n",
        "# 制定下载数据集所需要的目录\n",
        "\n",
        "download_spawrious(data_dir)\n",
        "# 使用download模块中的download_spawrious下载函数下载数据集，指定路径为data_dir\n",
        "# 调用其他函数下载其他数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG-PvtDxJOTD"
      },
      "outputs": [],
      "source": [
        "# 创建 SpawriousO2O_easy 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "\n",
        "spawrious_easy = SpawriousO2O_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousO2O_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousO2O_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#创建 SpawriousM2M 类的实例\n",
        "root_dir=\"/content/drive/MyDrive/ip1/spawrious224\"\n",
        "spawrious_easy = SpawriousM2M_easy(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_medium = SpawriousM2M_medium(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n",
        "spawrious_hard = SpawriousM2M_hard(root_dir, test_envs=[0], hparams={'data_augmentation': True})\n"
      ],
      "metadata": {
        "id": "G5UXya1ngdo8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5Us1_27TKM0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9efqXNB2K5Pe",
        "outputId": "85b2ba53-f02c-4cf9-be7d-43a0ef69d737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8IZdwtDLlbsq"
      },
      "outputs": [],
      "source": [
        "env1 = spawrious_easy[1]\n",
        "env2 = spawrious_easy[2]\n",
        "test = spawrious_easy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "avZK4NVnUZxW"
      },
      "outputs": [],
      "source": [
        "env1_medium = spawrious_medium[1]\n",
        "env2_medium = spawrious_medium[2]\n",
        "test_medium = spawrious_medium[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAxRKr-oNWHg",
        "outputId": "20769803-b3cd-481c-ea05-620a47825068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12672\n",
            "12672\n",
            "25344\n"
          ]
        }
      ],
      "source": [
        "env1_hard = spawrious_hard[1]\n",
        "env2_hard = spawrious_hard[2]\n",
        "test_hard = spawrious_hard[0]\n",
        "\n",
        "print(len(env1_hard))\n",
        "print(len(env2_hard))\n",
        "print(len(test_hard))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obs19CK7hOHN"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt'\n",
        "torch.save(test_hard, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZFQQiRyNN71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVYsqDeDtlGw"
      },
      "outputs": [],
      "source": [
        "torch.save(test, '/content/drive/MyDrive/ip/testdata.pt')\n",
        "torch.save(test_medium, '/content/drive/MyDrive/ip/testdata_medium.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksWtjDTrG4ho"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:\n"
      ],
      "metadata": {
        "id": "JKGmsTaZZV_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "FTvxrF-j-BTL",
        "outputId": "7bb54939-79d6-4444-839c-341cdc721628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_tensor = env1_hard[3072][0]\n",
        "label = env1_hard[3072][1]\n",
        "\n",
        "image_array = image_tensor.numpy()\n",
        "image_array_rgb = np.transpose(image_array, (1, 2, 0))\n",
        "plt.imshow(image_array_rgb)\n",
        "plt.axis('off')  # 关闭坐标轴\n",
        "plt.show()\n",
        "print(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_medium1 = []\n",
        "bulldog_medium2 = []\n",
        "for i in range(0, 3072):\n",
        "  bulldog_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(0, 2756):\n",
        "  bulldog_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "f9TleOcUiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulldog_filter_medium1 = []\n",
        "bulldog_filter_medium2 = []\n",
        "for i in range(12288, 12288+96):\n",
        "  bulldog_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024, 11024+412):\n",
        "  bulldog_filter_medium2.append(env2_medium[i][0])\n"
      ],
      "metadata": {
        "id": "EIMPsQZtZcI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkefLJvgPCDC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "bulldog_filter_medium1_np = np.array(bulldog_filter_medium1)\n",
        "bulldog_filter_medium2_np = np.array(bulldog_filter_medium2)\n",
        "\n",
        "\n",
        "# 保存为 .npy 格式\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium1.npy', bulldog_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_filter_medium2.npy', bulldog_filter_medium2_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6X3shuzsRIJ",
        "outputId": "dd8eb974-8984-4071-9b8c-05d05675bf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "412\n"
          ]
        }
      ],
      "source": [
        "bulldog_medium1_np = np.array(bulldog_medium1)\n",
        "bulldog_medium2_np = np.array(bulldog_medium2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium1.npy', bulldog_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_medium2.npy', bulldog_medium2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dachshund_filter_medium1 = []\n",
        "dachshund_filter_medium2 = []\n",
        "for i in range(12288+96, 12288+96*2):\n",
        "  dachshund_filter_medium1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412, 11024+412*2):\n",
        "  dachshund_filter_medium2.append(env2_medium[i][0])"
      ],
      "metadata": {
        "id": "sWIoCKWbiw6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-neQ3YR2Ewg"
      },
      "outputs": [],
      "source": [
        "dachshund1 = []\n",
        "dachshund2 = []\n",
        "for i in range(3072, 3072+3072):\n",
        "  dachshund1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756, 2756+2756):\n",
        "  dachshund2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dachshund_filter_medium1_np = np.array(dachshund_filter_medium1)\n",
        "dachshund_filter_medium2_np = np.array(dachshund_filter_medium2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium1.npy', dachshund_filter_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_filter_medium2.npy', dachshund_filter_medium2_np)\n",
        "\n",
        "dachshund_medium1_np = np.array(dachshund1)\n",
        "dachshund_medium2_np = np.array(dachshund2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium1.npy', dachshund_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_medium2.npy', dachshund_medium2_np)\n"
      ],
      "metadata": {
        "id": "JAPYDkGXULGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ftTNGcd2m0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNUdbmZ2m45"
      },
      "outputs": [],
      "source": [
        "labrador_filter1 = []\n",
        "labrador_filter2 = []\n",
        "for i in range(12288+96*2, 12288+96*3):\n",
        "  labrador_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*2, 11024+412*3):\n",
        "  labrador_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwSyffW2m9D"
      },
      "outputs": [],
      "source": [
        "labrador1 = []\n",
        "labrador2 = []\n",
        "for i in range(3072*2, 3072*3):\n",
        "  labrador1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*2, 2756*3):\n",
        "  labrador2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save labrador\n",
        "\n",
        "import numpy as np\n",
        "labrador_filter1_np = np.array(labrador_filter1)\n",
        "labrador_filter2_np = np.array(labrador_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium1.npy', labrador_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_filter_medium2.npy', labrador_filter2_np)\n",
        "\n",
        "labrador_medium1_np = np.array(labrador1)\n",
        "labrador_medium2_np = np.array(labrador2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium1.npy', labrador_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_medium2.npy', labrador_medium2_np)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2wi1WcfVMwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQtiHE4WDbfZ"
      },
      "outputs": [],
      "source": [
        "corgi_filter1 = []\n",
        "corgi_filter2 = []\n",
        "for i in range(12288+96*3, 12288+96*4):\n",
        "  corgi_filter1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(11024+412*3, 11024+412*4):\n",
        "  corgi_filter2.append(env2_medium[i][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7IptW5pIsFD"
      },
      "outputs": [],
      "source": [
        "corgi1 = []\n",
        "corgi2 = []\n",
        "for i in range(3072*3, 3072*4):\n",
        "  corgi1.append(env1_medium[i][0])\n",
        "\n",
        "for i in range(2756*3, 2756*4):\n",
        "  corgi2.append(env2_medium[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save corgi\n",
        "\n",
        "import numpy as np\n",
        "corgi_filter1_np = np.array(corgi_filter1)\n",
        "corgi_filter2_np = np.array(corgi_filter2)\n",
        "\n",
        "# Save as .npy format\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium1.npy', corgi_filter1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_filter_medium2.npy', corgi_filter2_np)\n",
        "\n",
        "corgi_medium1_np = np.array(corgi1)\n",
        "corgi_medium2_np = np.array(corgi2)\n",
        "\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium1.npy', corgi_medium1_np)\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_medium2.npy', corgi_medium2_np)\n"
      ],
      "metadata": {
        "id": "O5DYMDBHV5cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOYWgQ7GsbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSt-PjHa0vxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189d9eae-d5d3-4107-c1aa-a8c447d28b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDkvJ3N9HlQq",
        "outputId": "9ecd4e4a-ae00-415f-8360-419403e2c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49q4nMcrOk7q"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQyAlC-VAall"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_hard1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_hard2.npy')\n",
        "corgi_filter1 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard1.npy')\n",
        "corgi_filter2 = np.load('/content/drive/MyDrive/ip1/corgi_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZwOYqQjbC7l"
      },
      "outputs": [],
      "source": [
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_hard1.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_hard2.npy')\n",
        "labrador_filter1 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard1.npy')\n",
        "labrador_filter2 = np.load('/content/drive/MyDrive/ip1/labrador_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504i9eqpyujC"
      },
      "outputs": [],
      "source": [
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_hard1.npy')\n",
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_hard2.npy')\n",
        "dachshund_filter1 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard1.npy')\n",
        "dachshund_filter2 = np.load('/content/drive/MyDrive/ip1/dachshund_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaok8gKyvUb"
      },
      "outputs": [],
      "source": [
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_hard1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_hard2.npy')\n",
        "bulldog_filter1 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard1.npy')\n",
        "bulldog_filter2 = np.load('/content/drive/MyDrive/ip1/bulldog_filter_hard2.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um-nuTB-_Rp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from transformers import CLIPModel\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check:"
      ],
      "metadata": {
        "id": "nrEh7ntajEry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX1xyS2g-QEt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "faf0203ade3e4d6d95de506945873501",
            "2473c911f9934e4ab801f1e91dd49182",
            "dc04e368de3e48b4b2837591490e1bc1",
            "7f9931b24ac44650b3652d44d6cf0aa4",
            "98ce801c92a240f2ab8b887f6c42145f",
            "595a936ef28246309976d12e3aa84168",
            "d24e944b880c49728193b32a79ddf541",
            "3dda789eab754f2c8607c93c867c348a",
            "7015de9f4e974759ba4d63683a026711",
            "82eafc40c2e546d787830b1203f30c9c",
            "dcb9f02ac3a348f7ad96a3adfa757934",
            "556464689c8d4e218b42c74e17cc9915",
            "f08024ab1c6e4ae8a67abe3557c67330",
            "68de135480854c139c5099eb157ca40a",
            "b7f4bb79f0534854b07904889e6ecf3f",
            "26c378ba460243ac99cfa9ac6df6172c",
            "f889a2302ed041df8eb8b0ffe1744504",
            "65a83793b69e4e5d859405944642c501",
            "51769e5b2c3742fa85bf1c7acb3c8d6c",
            "58dcbfcb64184f3596903ae08236d284",
            "ff7e7eee1fa24b5faed7fae7530d5aa2",
            "4b704eca4f374935b0124622d1217ff8"
          ]
        },
        "outputId": "86510f2c-536e-47f1-f650-9e255a68cb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf0203ade3e4d6d95de506945873501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "556464689c8d4e218b42c74e17cc9915"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# generate semantic sharing pairs using cosine similarity\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "def similar_pair(i, class_filter, class_tensor):\n",
        "  similarity = 0\n",
        "  with torch.no_grad():\n",
        "    inputs1 = torch.tensor(class_filter[i]).unsqueeze(0).to(device)\n",
        "    features1 = model.get_image_features(inputs1)\n",
        "    for j in range(len(class_tensor)):\n",
        "      inputs2 = torch.tensor(class_tensor[j]).unsqueeze(0).to(device)\n",
        "      features2 = model.get_image_features(inputs2)\n",
        "      res = F.cosine_similarity(features1, features2).item()\n",
        "      if res > similarity:\n",
        "        similarity = res\n",
        "        index = j\n",
        "\n",
        "    pair1 = class_filter[i]\n",
        "    pair2 = class_tensor[index]\n",
        "    image_pair = (pair1, pair2)\n",
        "\n",
        "    return image_pair\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4KmCdocQh8h",
        "outputId": "59727623-3b75-410e-9033-fb773fa16db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [42:00<00:00, 26.26s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs1 = []\n",
        "for i in tqdm(range(len(corgi_filter1))):\n",
        "    pair = similar_pair(i, corgi_filter1, corgi1)\n",
        "    corgi_pairs1.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PRdG5HFlcK"
      },
      "outputs": [],
      "source": [
        "corgi_pairs1_np = np.array(corgi_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs1.npy', corgi_pairs1_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjoN6G33F179",
        "outputId": "8ac13ca2-d7ef-4afe-90f5-ac8e78c03ba5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:38:22<00:00, 23.06s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corgi_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(corgi_filter2))):\n",
        "    pair = similar_pair(i, corgi_filter2, corgi2)\n",
        "    corgi_pairs2.append(pair)\n",
        "\n",
        "\n",
        "corgi_pairs2_np = np.array(corgi_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/corgi_pairs2.npy', corgi_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkONXq1cJ6w",
        "outputId": "78d06744-03e0-4d0b-eba3-012d7bf197d9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:02<00:00, 25.65s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter1, labrador1)\n",
        "    labrador_pairs1.append(pair)\n",
        "\n",
        "labrador_pairs1_np = np.array(labrador_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs1.npy', labrador_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygDEfA1mB4H",
        "outputId": "95232c28-3bf8-44a0-8b19-0a5907c4850c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:36:51<00:00, 22.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labrador_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(labrador_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, labrador_filter2, labrador2)\n",
        "    labrador_pairs2.append(pair)\n",
        "\n",
        "labrador_pairs2_np = np.array(labrador_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/labrador_pairs2.npy', labrador_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0zPieI6Qh-j",
        "outputId": "623e8156-6be9-4be3-a9c4-ea3733ce3886"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [40:54<00:00, 25.57s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter1, bulldog1)\n",
        "    bulldog_pairs1.append(pair)\n",
        "\n",
        "bulldog_pairs1_np = np.array(bulldog_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs1.npy', bulldog_pairs1_np)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUl4yFAKFDQ",
        "outputId": "934b6e3b-db43-4376-9f1e-0389d05bcb8b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [2:39:22<00:00, 23.21s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bulldog_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(bulldog_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, bulldog_filter2, bulldog2)\n",
        "    bulldog_pairs2.append(pair)\n",
        "\n",
        "bulldog_pairs2_np = np.array(bulldog_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/bulldog_pairs2.npy', bulldog_pairs2_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKWFg-QXE7m",
        "outputId": "7a83c0ee-7d90-4338-dc90-501fcbb8a848"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [41:44<00:00, 26.09s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs1 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter1))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter1, dachshund1)\n",
        "    dachshund_pairs1.append(pair)\n",
        "\n",
        "dachshund_pairs1_np = np.array(dachshund_pairs1)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs1.npy', dachshund_pairs1_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhmg9gwwAbAd",
        "outputId": "dde5b7da-17f2-41fb-d1d1-80f084afe701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 412/412 [2:57:25<00:00, 25.84s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dachshund_pairs2 = []\n",
        "\n",
        "for i in tqdm(range(len(dachshund_filter2))):\n",
        "\n",
        "    pair = similar_pair(i, dachshund_filter2, dachshund2)\n",
        "    dachshund_pairs2.append(pair)\n",
        "\n",
        "dachshund_pairs2_np = np.array(dachshund_pairs2)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/dachshund_pairs2.npy', dachshund_pairs2_np)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0U6fMo5WkK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKAgASqCmOKe"
      },
      "outputs": [],
      "source": [
        "dachshund2 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs2.npy')\n",
        "dachshund1 = np.load('/content/drive/MyDrive/ip1/dachshund_pairs1.npy')\n",
        "bulldog1 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs1.npy')\n",
        "bulldog2 = np.load('/content/drive/MyDrive/ip1/bulldog_pairs2.npy')\n",
        "corgi1 = np.load('/content/drive/MyDrive/ip1/corgi_pairs1.npy')\n",
        "corgi2 = np.load('/content/drive/MyDrive/ip1/corgi_pairs2.npy')\n",
        "labrador2 = np.load('/content/drive/MyDrive/ip1/labrador_pairs2.npy')\n",
        "labrador1 = np.load('/content/drive/MyDrive/ip1/labrador_pairs1.npy')\n",
        "\n",
        "labrador = np.concatenate((labrador1, labrador2), axis=0)\n",
        "bulldog = np.concatenate((bulldog1, bulldog2), axis=0)\n",
        "corgi = np.concatenate((corgi1, corgi2), axis=0)\n",
        "dachshund = np.concatenate((dachshund1, dachshund2), axis=0)\n",
        "\n",
        "data = np.concatenate((labrador, bulldog, corgi, dachshund), axis=0)\n",
        "\n",
        "training_data = torch.tensor(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFrOE3RrLiG",
        "outputId": "2c079d89-33bd-41a3-98f3-30bfe0ed1462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PMu7dA7nNUM"
      },
      "outputs": [],
      "source": [
        "training_data_np = np.array(training_data)\n",
        "\n",
        "# 保存为 .npy 文件\n",
        "np.save('/content/drive/MyDrive/ip1/training_data_hard.npy', training_data_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-NrGu-LoTCz",
        "outputId": "2941f1f6-9d5a-4ae6-b1b8-7e86a7e6bfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2032"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0PdbNapNHB",
        "outputId": "54030c5e-e6fa-4299-e4f1-09c1a40ecede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "张量的形状： torch.Size([2032, 2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKslUAPyprb4",
        "outputId": "c6a75294-c4b4-4b19-f372-2a3842a347c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_easy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BAHgrw9bePe"
      },
      "source": [
        "convert all images into RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt50-fATZa32",
        "outputId": "ce1f6d76-1c38-4738-a51d-9cff9eff7433"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:07<00:00, 400.32it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.64it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.75it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.36it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.11it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.11it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.44it/s] \n",
            "100%|██████████| 3168/3168 [00:42<00:00, 73.81it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.81it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.29it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 85.98it/s] \n",
            "100%|██████████| 3168/3168 [00:41<00:00, 76.55it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.96it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.95it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.51it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.09it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:45<00:00, 69.65it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.34it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.47it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.75it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.43it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.11it/s] \n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:40<00:00, 78.95it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.92it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.40it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.98it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.35it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.39it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.18it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 82.05it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.91it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.46it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 80.48it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 86.66it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:37<00:00, 85.47it/s] \n",
            "100%|██████████| 3168/3168 [00:38<00:00, 83.05it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 89.02it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.07it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.99it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.61it/s] \n",
            "100%|██████████| 3168/3168 [00:39<00:00, 79.41it/s] \n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.99it/s] \n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [00:35<00:00, 88.86it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 84.81it/s] \n",
            "100%|██████████| 3168/3168 [00:36<00:00, 87.70it/s] \n",
            "100%|██████████| 3168/3168 [00:37<00:00, 83.88it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "所有图片转换完成！\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ip/spawrious224'\n",
        "\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "        file_path = os.path.join(root, file)\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "            image.save(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRV3cb6FnoSX",
        "outputId": "c81a4785-7144-48f0-9653-fe0e26a6a245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bulldog', 'corgi', 'dachshund', 'labrador']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spawrious_easy.class_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swUTlzMZbAvm"
      },
      "source": [
        "find corgi images in env1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBlgf9kbPo1"
      },
      "source": [
        "find all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "MLAL0885BH2w",
        "outputId": "b23aef31-8b4b-429d-aad9-ff796f29b36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1826/12672 [02:35<15:20, 11.78it/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e8a513c52f61>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspawrious_easy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bulldog\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbulldog_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DomainBed/domainbed/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "corgi_images = []\n",
        "bulldog_images = []\n",
        "dachshund_images = []\n",
        "labrador_images = []\n",
        "\n",
        "\n",
        "for image, label in tqdm(env1):\n",
        "  if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images.append(image)\n",
        "\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images.append(image)\n",
        "\n",
        "  if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images.append(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbcjhnlAXcZ",
        "outputId": "1f6b6fa3-702d-455e-815e-e80510a09565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3168\n",
            "3168\n",
            "3168\n",
            "3168\n"
          ]
        }
      ],
      "source": [
        "print(len(corgi_images))\n",
        "print(len(bulldog_images))\n",
        "print(len(dachshund_images))\n",
        "print(len(labrador_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrz3aOyDbV9M"
      },
      "source": [
        "find all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvFOg-czCymV",
        "outputId": "5b34ec3d-e0b2-4def-ea7e-51e8af9cf95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12672/12672 [1:20:01<00:00,  2.64it/s]\n"
          ]
        }
      ],
      "source": [
        "corgi_images2 = []\n",
        "bulldog_images2 = []\n",
        "dachshund_images2 = []\n",
        "labrador_images2 = []\n",
        "\n",
        "for image, label in tqdm(env2):\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"corgi\":\n",
        "        corgi_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"bulldog\":\n",
        "        bulldog_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"dachshund\":\n",
        "        dachshund_images2.append(image)\n",
        "\n",
        "    if spawrious_easy.class_list[label] == \"labrador\":\n",
        "        labrador_images2.append(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKi8m9ibmRg"
      },
      "source": [
        "save all classes images in env1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fGtK1RWUk7p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "def save_images(image_list, folder_path, label):\n",
        "    # 检查目标文件夹是否存在，不存在则创建\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # 遍历图像列表，保存每张图像\n",
        "    for idx, tensor in enumerate(image_list):\n",
        "        image = TF.to_pil_image(tensor)                               # 将 tensor 转换为 PIL 图像\n",
        "        image_path = os.path.join(folder_path, f\"{label}_{idx}.png\")  # 定义图像的保存路径\n",
        "        image.save(image_path)                                        # 保存图像\n",
        "\n",
        "# Google Drive 挂载路径\n",
        "drive_path = \"/content/drive/MyDrive/ip/SpawriousImages\"\n",
        "\n",
        "# 分别保存每种类别的图像\n",
        "save_images(bulldog_images, os.path.join(drive_path, 'bulldog'), 'bulldog')\n",
        "save_images(dachshund_images, os.path.join(drive_path, 'dachshund'), 'dachshund')\n",
        "save_images(labrador_images, os.path.join(drive_path, 'labrador'), 'labrador')\n",
        "save_images(corgi_images, os.path.join(drive_path, 'corgi'), 'corgi')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ELr3P6bt2K"
      },
      "source": [
        "save all classes images in env2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFFo56kXnMc"
      },
      "outputs": [],
      "source": [
        "save_images(bulldog_images2, os.path.join(drive_path, 'bulldog2'), 'bulldog')\n",
        "save_images(dachshund_images2, os.path.join(drive_path, 'dachshund2'), 'dachshund')\n",
        "save_images(labrador_images2, os.path.join(drive_path, 'labrador2'), 'labrador')\n",
        "save_images(corgi_images2, os.path.join(drive_path, 'corgi2'), 'corgi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClB9-zM4fGNx",
        "outputId": "a7af8175-f2df-4362-d221-0e0215af6bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Dictionary: {'bulldog': 0, 'corgi': 1, 'dachshund': 2, 'labrador': 3}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_list = [\"bulldog\", \"corgi\", \"dachshund\", \"labrador\"]\n",
        "\n",
        "# 将列表转换为字典，键是标签，值是索引\n",
        "class_dict = {class_name: index for index, class_name in enumerate(class_list)}\n",
        "\n",
        "# 打印转换后的字典\n",
        "print(\"Class Dictionary:\", class_dict)\n",
        "class_dict['bulldog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GwhB5ObypD"
      },
      "source": [
        "create random pairs of bulldog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE-q9MMaxtcQ",
        "outputId": "e613c57a-2c52-4e32-c420-daa56f69c1b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 697747.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/bulldog/bulldog_2213.png',\n",
              "  '/content/SpawriousImages/bulldog2/bulldog_2962.png'),\n",
              " 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder1_path = \"/content/SpawriousImages/bulldog\"\n",
        "folder2_path = \"/content/SpawriousImages/bulldog2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # Randomly pair\n",
        "    bulldog_image_pairs.append((image_pair, class_dict['bulldog']))\n",
        "\n",
        "bulldog_image_pairs[200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4lJvdadb88y"
      },
      "source": [
        "create random pairs of corgi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW8hN7jvyClr",
        "outputId": "95523183-db68-4d8e-dee9-6b4275c1ec7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 817519.62it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_208.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_3064.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/corgi\"\n",
        "folder2_path = \"/content/SpawriousImages/corgi2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "corgi_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, class_dict['corgi']))\n",
        "\n",
        "corgi_image_pairs[1093]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmwyYjK7cDoq"
      },
      "source": [
        "create random pairs of dachshund"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4alSoc414EiM",
        "outputId": "de3c8564-b5d9-4dbd-87eb-f64d0cd25426"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 800262.29it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/dachshund/dachshund_2053.png',\n",
              "  '/content/SpawriousImages/dachshund2/dachshund_1682.png'),\n",
              " 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/dachshund\"\n",
        "folder2_path = \"/content/SpawriousImages/dachshund2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "\n",
        "# 将文件名转换为完整的文件路径\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, class_dict['dachshund']))\n",
        "\n",
        "dachshund_image_pairs[100]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8VW1QOicJPa"
      },
      "source": [
        "Create random pairs of labrador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcVbDd94K2U",
        "outputId": "ba1ae18c-d68b-4151-8c77-74a069314f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6336/6336 [00:00<00:00, 733835.26it/s]\n"
          ]
        }
      ],
      "source": [
        "folder1_path = \"/content/SpawriousImages/labrador\"\n",
        "folder2_path = \"/content/SpawriousImages/labrador2\"\n",
        "\n",
        "# 获取文件夹中的所有图片文件名列表\n",
        "folder1_images = os.listdir(folder1_path)\n",
        "folder2_images = os.listdir(folder2_path)\n",
        "\n",
        "# 将文件名列表合并\n",
        "all_images = [os.path.join(folder1_path, file) for file in folder1_images] + [os.path.join(folder2_path, file) for file in folder2_images]\n",
        "\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in tqdm(all_images):\n",
        "    image_pair = (image_path, random.choice(all_images))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, class_dict['labrador']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fejvc8A3cM7p"
      },
      "source": [
        "merge all four classes images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBx_U4Dw4Tpe",
        "outputId": "4f6c1004-2f97-4611-ded4-a06ede1873d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(('/content/SpawriousImages/corgi/corgi_2342.png',\n",
              "  '/content/SpawriousImages/corgi2/corgi_2470.png'),\n",
              " 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = labrador_image_pairs + dachshund_image_pairs + corgi_image_pairs + bulldog_image_pairs\n",
        "\n",
        "# 打乱合并后的列表\n",
        "random.shuffle(training_data)\n",
        "\n",
        "print(len(training_data))\n",
        "\n",
        "training_data[981]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I1hM69h4ZxK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 明确指定数组的数据类型为 object\n",
        "training_array = np.array(training_data, dtype=object)\n",
        "\n",
        "# 指定保存文件的路径和文件名\n",
        "save_path = \"/content/training_data.npy\"\n",
        "\n",
        "# 将 NumPy 数组保存为 .npy 文件\n",
        "np.save(save_path, training_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCZHUx14Z3I",
        "outputId": "18ca66d3-0b33-41fa-de18-91c66657593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (25344, 2)\n",
            "Size: 50688\n",
            "[('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            " 3]\n",
            "('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png')\n",
            "/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 加载 .npy 文件\n",
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# 查看数组的形状和大小\n",
        "print(\"Shape:\", array.shape)\n",
        "print(\"Size:\", array.size)\n",
        "\n",
        "\n",
        "print(array[1])\n",
        "print(array[1][0])\n",
        "print(array[1][0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check an example\n"
      ],
      "metadata": {
        "id": "70s-6zucXos1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Axn7L7Sqruo",
        "outputId": "578daa98-81ed-4e89-deb7-97b93674d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2737.png', '/content/drive/MyDrive/ip/SpawriousImages/labrador/labrador_2396.png'),\n",
              "       3], dtype=object)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.load(\"/content/drive/MyDrive/ip/training_data.npy\", allow_pickle=True)\n",
        "array[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "942VqoXnP0OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image_paths = sample[0]\n",
        "        label = sample[1]\n",
        "        images = [Image.open(path) for path in image_paths]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ip1/training_data_easy.npy\"\n",
        "custom_dataset = CustomDataset(data_path, transform=transform)\n",
        "trainloader = DataLoader(custom_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kezAlnNFwESe",
        "outputId": "1bff5902-46d5-466a-f900-5aaa006b432e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EI82mktkohs"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJN4vrei4Ag",
        "outputId": "a8a5a118-71f5-4f8a-e94e-12f6841a9b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "([tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]]), tensor([[[ 0.2967,  0.1426, -0.0116,  ..., -1.7240, -1.9467,  2.1462],\n",
            "         [ 0.4337,  0.5193,  0.0741,  ...,  2.1462,  1.9235,  1.9920],\n",
            "         [ 0.4337,  0.5193,  0.1426,  ...,  2.0777,  1.9920,  1.8550],\n",
            "         ...,\n",
            "         [ 2.1975,  1.8208,  1.6667,  ..., -1.6727, -1.5870, -1.5870],\n",
            "         [ 1.8893,  1.4440,  1.3755,  ...,  1.8893,  2.0434, -2.1179],\n",
            "         [ 1.5982,  1.4440,  1.3755,  ...,  1.8208,  1.8208,  1.9749]],\n",
            "\n",
            "        [[ 2.3060,  2.2360,  1.9909,  ...,  0.2052, -0.2675, -0.4951],\n",
            "         [-1.9307, -2.0182,  1.9909,  ..., -0.4251, -0.7402, -0.6527],\n",
            "         [-1.9307, -2.0182,  2.1485,  ..., -0.5826, -0.6527, -0.9678],\n",
            "         ...,\n",
            "         [-1.3179, -1.8606,  2.3761,  ..., -0.8452, -0.7752, -0.6176],\n",
            "         [-1.9482,  2.1485,  1.9209,  ..., -1.8606, -1.7031, -1.3880],\n",
            "         [ 2.3060,  2.0609,  1.9209,  ..., -2.0182, -2.0182, -1.8606]],\n",
            "\n",
            "        [[-0.8981, -1.0550, -1.2119,  ...,  1.5594,  1.0888,  0.8622],\n",
            "         [-0.6541, -0.7413, -1.2119,  ...,  1.0191,  0.6182,  0.7054],\n",
            "         [-0.6541, -0.7413, -1.0550,  ...,  0.7751,  0.7751,  0.4614],\n",
            "         ...,\n",
            "         [ 0.0605, -0.4798, -0.7064,  ...,  0.6182,  0.7576,  0.7576],\n",
            "         [-0.4798, -0.9330, -1.2467,  ..., -0.3927, -0.0790, -0.0092],\n",
            "         [-0.7064, -1.0201, -1.2467,  ..., -0.6367, -0.4798, -0.4798]]])], 1)\n"
          ]
        }
      ],
      "source": [
        "# 数据集的长度，一共有25344对图像\n",
        "print(len(custom_dataset))\n",
        "\n",
        "\n",
        "print(custom_dataset[3])\n",
        "\n",
        "# pairs\n",
        "#print(custom_dataset[3][0])\n",
        "\n",
        "# label\n",
        "#print(custom_dataset[3][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPLwSINk_IW"
      },
      "outputs": [],
      "source": [
        "batch_size= 10\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwbKV4Ay7Rq",
        "outputId": "98059a33-0549-48c3-a035-348232838ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.2318, -2.0665, -1.9295,  ...,  2.0777,  2.1633, -2.0665],\n",
            "         [ 1.8550,  2.1633, -1.9980,  ...,  2.2318, -2.0665, -2.0665],\n",
            "         [ 0.5193,  1.6324, -1.9295,  ..., -2.0665, -2.0665,  2.1633],\n",
            "         ...,\n",
            "         [ 1.6324,  1.8550,  1.9407,  ...,  2.1633, -1.7069, -1.6213],\n",
            "         [ 0.8961,  1.2557,  1.6324,  ...,  2.1633, -1.8439, -1.5528],\n",
            "         [ 0.3652,  0.5878,  1.3413,  ..., -1.9980, -1.7069, -1.3302]],\n",
            "\n",
            "        [[-1.8606, -1.7031, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 2.2360, -1.9307, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         [ 0.9055,  2.0784, -1.6155,  ..., -2.0182, -2.0182, -2.0182],\n",
            "         ...,\n",
            "         [ 1.8333,  2.0784,  2.1485,  ..., -1.8606, -1.2304, -1.0728],\n",
            "         [ 1.0630,  1.2906,  1.8333,  ..., -1.8606, -1.3179, -0.9153],\n",
            "         [ 0.5903,  0.7479,  1.5357,  ..., -1.6155, -1.1604, -0.6877]],\n",
            "\n",
            "        [[ 1.1934,  1.1934,  1.2805,  ...,  0.7402,  0.8099,  0.8099],\n",
            "         [ 0.8797,  1.1934,  1.1934,  ...,  0.8099,  0.8099,  0.9668],\n",
            "         [-0.1138,  0.8099,  1.2805,  ...,  0.8797,  0.8797,  0.8797],\n",
            "         ...,\n",
            "         [ 0.2696,  0.4962,  0.6531,  ...,  0.8099,  1.1934,  1.2805],\n",
            "         [-0.3578,  0.0431,  0.4962,  ...,  0.8099,  1.0365,  1.2805],\n",
            "         [-0.8110, -0.5147,  0.1128,  ...,  0.9668,  1.1237,  1.4374]]])\n"
          ]
        }
      ],
      "source": [
        "first_batch = next(iter(trainloader))\n",
        "first_data = first_batch[0][0]  # 获取第一个数据样本\n",
        "print(first_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ83k-aWJrgv"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhU_0iIXJqpZ",
        "outputId": "4e97126e-6c72-43b0-cc6f-3462131d3cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25344\n",
            "2535\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(len(custom_dataset))\n",
        "print(len(trainloader))\n",
        "print(type(trainloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSIKQNL6rpCw"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Erge4frq72"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nZFFBiirq-R",
        "outputId": "3dc54f4b-67a6-4e40-e482-55c7405ba0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkQM3HHBKFiE"
      },
      "source": [
        "Check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuuWRMBrrAY",
        "outputId": "15e1819c-fa7d-49ab-b944-d5f5110459b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "last_fc_layer = model.fc\n",
        "\n",
        "input_features = last_fc_layer.in_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqf7iroOwvq2",
        "outputId": "e133fb06-9868-4912-e836-80b9f9f293d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全连接层结构： Linear(in_features=512, out_features=4, bias=True)\n",
            "全连接层权重形状： torch.Size([4, 512])\n",
            "全连接层偏置形状： torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "fc_layer = model.fc\n",
        "\n",
        "print(\"全连接层结构：\", fc_layer)\n",
        "print(\"全连接层权重形状：\", fc_layer.weight.shape)\n",
        "print(\"全连接层偏置形状：\", fc_layer.bias.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1UnM4ToMPXv"
      },
      "source": [
        "Check:(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWh-kHp1vNb",
        "outputId": "dbac08e4-05f8-40f4-d882-200e045c7e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "tensor(1.5868, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, label = next(dataiter)\n",
        "\n",
        "#print(\"Inputs:\", images[0])       # 显示输入数据\n",
        "      # 只处理第一个 batch 后退出循环\n",
        "\n",
        "type(images[0])\n",
        "\n",
        "\n",
        "input_tensor = torch.cat((images[0], images[1]), dim=0)\n",
        "import torch\n",
        "\n",
        "\n",
        "labels = torch.cat((label, label), dim=0)\n",
        "#print(labels)\n",
        "\n",
        "outputs = model(input_tensor)\n",
        "#print(outputs)\n",
        "\n",
        "print(len(outputs))\n",
        "print(len(labels))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jMXI2Dukty",
        "outputId": "04a13456-1823-485e-a009-ce4c51837bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7cd3252a3d60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "test = torch.load('/content/drive/MyDrive/ip/testdata.pt')\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5hSVD3wsqim"
      },
      "source": [
        "check an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOpFA1vlUXy",
        "outputId": "022b77ae-f4ec-46ef-c2a4-51696568a29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 获取第一个 batch\n",
        "first_batch = next(iter(trainloader))\n",
        "\n",
        "# 打印第一个 batch\n",
        "# print(first_batch)\n",
        "\n",
        "print(len(first_batch[0][1]))\n",
        "print(len(first_batch[0][0]))\n",
        "\n",
        "# batch_size个\n",
        "\n",
        "\n",
        "# for i, items in enumerate(trainloader, 0):\n",
        "#  print(i, items)\n",
        "#  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ModifiedResNet\n"
      ],
      "metadata": {
        "id": "pgY9MuCX8xzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JeRhqEhNW7D4",
        "outputId": "dd7122f6-a2e1-4418-f1cc-5d7d9edbef4f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'first_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b4ede2f49613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
          ]
        }
      ],
      "source": [
        "input_tensor = torch.cat((first_batch[0][0], first_batch[0][1]), dim=0)\n",
        "labels = torch.cat((first_batch[1], first_batch[1]), dim=0)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(input_tensor.shape[0])\n",
        "print(labels.shape)\n",
        "#input_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train process"
      ],
      "metadata": {
        "id": "RTaK4QPx86Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdykKpAdrrCz",
        "outputId": "16ca98b5-5d29-4022-ac41-520c242bc1be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "11it [07:23, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [11/198], Loss: 1.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:57, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [22/198], Loss: 0.6445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:22, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [33/198], Loss: 0.4303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:54, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [44/198], Loss: 0.3336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:29, 41.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [55/198], Loss: 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:59, 41.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [66/198], Loss: 0.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:32, 41.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [77/198], Loss: 0.1903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:09, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [88/198], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [99/198], Loss: 0.1815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:02, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [110/198], Loss: 0.1576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:38, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [121/198], Loss: 0.1529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:14, 40.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [132/198], Loss: 0.1419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:45, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [143/198], Loss: 0.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:20, 41.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [154/198], Loss: 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:51, 41.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [165/198], Loss: 0.0932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:16, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [176/198], Loss: 0.0901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:39, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [187/198], Loss: 0.0940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:00, 40.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [198/198], Loss: 0.0900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "11it [07:30, 40.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [11/198], Loss: 0.0390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:50, 40.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [22/198], Loss: 0.0359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [33/198], Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:35, 40.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [44/198], Loss: 0.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [36:59, 40.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [55/198], Loss: 0.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:22, 40.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [66/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [51:46, 40.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [77/198], Loss: 0.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:10, 40.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [88/198], Loss: 0.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:06:34, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [99/198], Loss: 0.0300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:06, 41.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [110/198], Loss: 0.0279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:21:36, 40.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [121/198], Loss: 0.0356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:07, 40.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [132/198], Loss: 0.0299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:36:37, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [143/198], Loss: 0.0309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:09, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [154/198], Loss: 0.0259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:51:42, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [165/198], Loss: 0.0263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:14, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [176/198], Loss: 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:06:46, 41.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [187/198], Loss: 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:14, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Step [198/198], Loss: 0.0209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:15, 40.68s/it]\n",
            "11it [07:32, 40.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [11/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [14:58, 40.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [22/198], Loss: 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:30, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [33/198], Loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [29:55, 40.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [44/198], Loss: 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:20, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [55/198], Loss: 0.0084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [44:48, 40.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [66/198], Loss: 0.0086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:14, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [77/198], Loss: 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [59:48, 40.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [88/198], Loss: 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:16, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [99/198], Loss: 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:14:49, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [110/198], Loss: 0.0072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:17, 40.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [121/198], Loss: 0.0077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:29:46, 40.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [132/198], Loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:18, 41.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [143/198], Loss: 0.0064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:44:43, 40.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [154/198], Loss: 0.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:10, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [165/198], Loss: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [1:59:40, 40.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [176/198], Loss: 0.0083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:06, 40.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [187/198], Loss: 0.0068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:33, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Step [198/198], Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:14:34, 40.78s/it]\n",
            "11it [07:41, 41.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [11/198], Loss: 0.0058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:13, 41.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [22/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:44, 40.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [33/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:16, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [44/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:40, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [55/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:09, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [66/198], Loss: 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [52:35, 40.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [77/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:10, 41.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [88/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:07:39, 40.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [99/198], Loss: 0.0052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:13, 41.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [110/198], Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:22:47, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [121/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:16, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [132/198], Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:37:43, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [143/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:45:16, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [154/198], Loss: 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:52:45, 40.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [165/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:00:13, 40.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [176/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:07:50, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [187/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:26, 41.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Step [198/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:15:27, 41.05s/it]\n",
            "11it [07:41, 41.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [11/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:20, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [22/198], Loss: 0.0048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:58, 41.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [33/198], Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:37, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [44/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [55/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:50, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [66/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:27, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [77/198], Loss: 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:01:08, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [88/198], Loss: 0.0050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:39, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [99/198], Loss: 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:16, 41.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [110/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:52, 41.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [121/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:20, 40.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [132/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:53, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [143/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:27, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [154/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:04, 41.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [165/198], Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:42, 41.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [176/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:21, 41.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [187/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:56, 41.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Step [198/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:57, 41.50s/it]\n",
            "11it [07:44, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [11/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:25, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [22/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [33/198], Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:34, 40.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [44/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:05, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [55/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:32, 40.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [66/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:05, 41.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [77/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:39, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [88/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:15, 40.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [99/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:47, 40.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [110/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:19, 40.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [121/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:55, 41.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [132/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:29, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [143/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:06, 41.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [154/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:43, 41.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [165/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:11, 40.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [176/198], Loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:42, 40.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [187/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:24, 41.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Step [198/198], Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:25, 41.34s/it]\n",
            "11it [07:35, 40.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [11/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:06, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [22/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [22:47, 41.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [33/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:19, 41.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [37:57, 41.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [55/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:34, 41.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [66/198], Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:14, 41.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [77/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:47, 41.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [88/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:20, 41.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [99/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:16:04, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:41, 41.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [121/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:31:21, 41.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [132/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:39:00, 41.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [143/198], Loss: 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:33, 41.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [154/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:54:02, 40.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [165/198], Loss: 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:35, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [176/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:09:04, 41.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [187/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:42, 41.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Step [198/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "198it [2:16:43, 41.43s/it]\n",
            "11it [07:45, 41.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [11/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [15:21, 41.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [22/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [23:01, 41.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [33/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [30:33, 41.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [44/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "55it [38:17, 41.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [55/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "66it [45:46, 40.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [66/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "77it [53:22, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [77/198], Loss: 0.0037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "88it [1:00:51, 40.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [88/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [1:08:14, 40.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [99/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "110it [1:15:46, 41.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [110/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "121it [1:23:22, 41.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [121/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "132it [1:30:58, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [132/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "143it [1:38:33, 41.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [143/198], Loss: 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "154it [1:46:11, 41.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [154/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "165it [1:53:46, 41.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [165/198], Loss: 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "176it [2:01:10, 40.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [176/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "187it [2:08:41, 41.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Step [187/198], Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "189it [2:10:05, 41.73s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "modified_model=modified_model.to(device)\n",
        "modified_model=modified_model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "            for j in range(batch_size):\n",
        "                y = items[1][j].to(device)           # Class label\n",
        "                images1 = items[0][0][j].to(device)  # First image\n",
        "                images2 = items[0][1][j].to(device)  # Second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                lam_loss = 0.0\n",
        "                for k in range(512):\n",
        "                    w = fc_layer.weight[y, k] ** 2\n",
        "                    dst = (f1[0, k, 0, 0] - f2[0, k, 0, 0]) ** 2\n",
        "                    lam_loss += w * dst\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i+1) %  11== 0:\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/11))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip/model_weights_output_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akLMZjBCqaZ6"
      },
      "outputs": [],
      "source": [
        "training_data = torch.tensor(data)\n",
        "\n",
        "# 打印张量的形状，确认转换是否成功\n",
        "print(\"张量的形状：\", training_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIsQ3KbelCN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/ip/model_weights.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For similar pairs:"
      ],
      "metadata": {
        "id": "WuiZXWkG9DYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dm1j-oLek0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        images = sample[0]\n",
        "        label = sample[1]\n",
        "        if self.transform:\n",
        "            images = [self.transform(image) for image in images]\n",
        "        return images, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/DomainBed.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgQkyrjuTOzE",
        "outputId": "02c4d8f4-3ab9-4a7e-bb14-50a582791c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DomainBed'...\n",
            "remote: Enumerating objects: 1308, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1308 (delta 26), reused 24 (delta 11), pack-reused 1259\u001b[K\n",
            "Receiving objects: 100% (1308/1308), 1.08 MiB | 24.14 MiB/s, done.\n",
            "Resolving deltas: 100% (763/763), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "sys.path.append('/content/DomainBed/domainbed/datasets')\n",
        "sys.path.append('/content/DomainBed/domainbed')"
      ],
      "metadata": {
        "id": "sfaoAaUBTXh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hHEyvVUR1FiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1f9e72-f310-4735-a02e-48b5f0cdb118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNWe9eClKJiM",
        "outputId": "5a121851-4c64-49a0-9ef5-be9bc2166b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfBGtMHhpzKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dachshund_medium2 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium2.npy')\n",
        "dachshund_medium1 = np.load('/content/drive/MyDrive/ip/dachshund_pairs_medium1.npy')\n",
        "bulldog_medium1 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium1.npy')\n",
        "bulldog_medium2 = np.load('/content/drive/MyDrive/ip/bulldog_pairs_medium2.npy')\n",
        "corgi_medium1 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium1.npy')\n",
        "corgi_medium2 = np.load('/content/drive/MyDrive/ip/corgi_pairs_medium2.npy')\n",
        "labrador_medium2 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium2.npy')\n",
        "labrador_medium1 = np.load('/content/drive/MyDrive/ip/labrador_pairs_medium1.npy')\n",
        "\n",
        "labrador_medium = np.concatenate((labrador_medium1, labrador_medium2), axis=0)\n",
        "bulldog_medium = np.concatenate((bulldog_medium1, bulldog_medium2), axis=0)\n",
        "corgi_medium = np.concatenate((corgi_medium1, corgi_medium2), axis=0)\n",
        "dachshund_medium = np.concatenate((dachshund_medium1, dachshund_medium2), axis=0)\n",
        "\n",
        "data_medium = np.concatenate((labrador_medium, bulldog_medium, corgi_medium, dachshund_medium), axis=0)\n",
        "training_data_medium = torch.tensor(data_medium)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.load('/content/drive/MyDrive/ip1/training_data_hard.npy')"
      ],
      "metadata": {
        "id": "quVzjbVK3c_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lipfY6ZIuxro",
        "outputId": "28138d32-f817-4814-f14b-1d6894ee40b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "           1.4782944 ,  1.4782944 ],\n",
              "         [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "           1.4611696 ,  1.4611696 ],\n",
              "         ...,\n",
              "         [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "          -0.37117907, -0.37117907],\n",
              "         [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "          -0.38830382, -0.38830382],\n",
              "         [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "          -0.38830382, -0.37117907]],\n",
              " \n",
              "        [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "           1.7107843 ,  1.7107843 ],\n",
              "         ...,\n",
              "         [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "          -0.35504198, -0.35504198],\n",
              "         [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897],\n",
              "         [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "          -0.39005598, -0.37254897]],\n",
              " \n",
              "        [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "           2.1519828 ,  2.2042704 ],\n",
              "         [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "           2.1345534 ,  2.1519828 ],\n",
              "         ...,\n",
              "         [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "          -0.21838771, -0.21838771],\n",
              "         [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.23581691],\n",
              "         [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "          -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              " array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "           0.72480524,  0.74193   ],\n",
              "         [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "           0.74193   ,  0.7590547 ],\n",
              "         [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "           0.7761795 ,  0.7761795 ],\n",
              "         ...,\n",
              "         [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "          -1.5699118 , -1.5699118 ],\n",
              "         [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "          -1.5699118 , -1.5527872 ],\n",
              "         [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "          -1.5870366 , -1.5356624 ]],\n",
              " \n",
              "        [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "           0.87044823,  0.88795525],\n",
              "         [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "           0.88795525,  0.90546227],\n",
              "         [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "           0.9229692 ,  0.9229692 ],\n",
              "         ...,\n",
              "         [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "          -1.4754901 , -1.4754901 ],\n",
              "         [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "          -1.4754901 , -1.457983  ],\n",
              "         [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "          -1.4929972 , -1.4404761 ]],\n",
              " \n",
              "        [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "           1.0888019 ,  1.1062311 ],\n",
              "         [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "           1.1062311 ,  1.1236603 ],\n",
              "         [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "           1.1410894 ,  1.1410894 ],\n",
              "         ...,\n",
              "         [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "          -1.2467101 , -1.2467101 ],\n",
              "         [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "          -1.2467101 , -1.229281  ],\n",
              "         [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "          -1.2641394 , -1.2118517 ]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 定义一个函数将数据转换为所需的形式\n",
        "def transform_data(data):\n",
        "    return [data[0], data[1]]\n",
        "\n",
        "# 将每个 data 转换为所需的形式\n",
        "training_data = [transform_data(data) for data in training_data]\n",
        "training_data[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RTtNaRpmCpd",
        "outputId": "075fd625-4fe4-435a-d8f3-21218b5ad47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 定义每个类别的名称和数量\n",
        "labels = []\n",
        "\n",
        "# 使用循环添加每个类别的标签\n",
        "for _ in range(508):\n",
        "    labels.extend([3])  # 前508个为3\n",
        "for _ in range(508):\n",
        "    labels.extend([0])  # 508-508*2为0\n",
        "for _ in range(508):\n",
        "    labels.extend([1])  # 508*2-508*3为1\n",
        "for _ in range(508):\n",
        "    labels.extend([2])  # 508*3-508*4为2\n",
        "\n",
        "# 检查列表的长度是否正确\n",
        "print(len(labels))  # 应该打印出 2032\n",
        "labels[507]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hS8AgE4pKyv",
        "outputId": "008e9586-3620-4785-c47c-1d3cd868151b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2032\n"
          ]
        }
      ],
      "source": [
        "# 假设 training_data 和 labels 是已经定义好的列表\n",
        "\n",
        "# 将 training_data 和 labels 按顺序组合成元组，并放入新的列表中\n",
        "combined_train = list(zip(training_data, labels))\n",
        "\n",
        "# 打印新的列表的长度，确保每个数据都有对应的标签\n",
        "print(len(combined_train))  # 应该打印出 2032\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bjA_xicqu-q",
        "outputId": "6f0dbb19-e2c3-4bf6-d553-5aa6815cb254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150528"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# prompt: 给出trainingdata中单个图像的分辨率\n",
        "example_image_path = training_data[0][0]\n",
        "\n",
        "example_image_path.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHc6RZzlfZAD",
        "outputId": "46e69339-139e-46b5-d5ac-789f80f20dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[[ 1.4611696 ,  1.4611696 ,  1.4611696 , ...,  1.4954191 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4611696 ,  1.4611696 , ...,  1.4782944 ,\n",
              "            1.4782944 ,  1.4782944 ],\n",
              "          [ 1.42692   ,  1.4440448 ,  1.4440448 , ...,  1.4782944 ,\n",
              "            1.4611696 ,  1.4611696 ],\n",
              "          ...,\n",
              "          [-0.8506721 , -0.8506721 , -0.67942464, ..., -0.38830382,\n",
              "           -0.37117907, -0.37117907],\n",
              "          [-0.88492167, -0.9020464 , -0.78217316, ..., -0.38830382,\n",
              "           -0.38830382, -0.38830382],\n",
              "          [-0.91917115, -0.8677969 , -0.9362959 , ..., -0.38830382,\n",
              "           -0.38830382, -0.37117907]],\n",
              "  \n",
              "         [[ 1.6757703 ,  1.6932774 ,  1.7107843 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6757703 ,  1.6757703 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          [ 1.6757703 ,  1.6582633 ,  1.6582633 , ...,  1.7107843 ,\n",
              "            1.7107843 ,  1.7107843 ],\n",
              "          ...,\n",
              "          [-1.0378151 , -1.0203081 , -0.880252  , ..., -0.37254897,\n",
              "           -0.35504198, -0.35504198],\n",
              "          [-1.055322  , -1.0728291 , -0.9677871 , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897],\n",
              "          [-1.107843  , -0.9852941 , -1.160364  , ..., -0.39005598,\n",
              "           -0.39005598, -0.37254897]],\n",
              "  \n",
              "         [[ 2.1345534 ,  2.1345534 ,  2.1345534 , ...,  2.1519828 ,\n",
              "            2.1519828 ,  2.2042704 ],\n",
              "          [ 2.169412  ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          [ 2.1519828 ,  2.1345534 ,  2.1345534 , ...,  2.1345534 ,\n",
              "            2.1345534 ,  2.1519828 ],\n",
              "          ...,\n",
              "          [-1.3338562 , -1.3338562 , -1.1944225 , ..., -0.23581691,\n",
              "           -0.21838771, -0.21838771],\n",
              "          [-1.3512855 , -1.3687146 , -1.2815686 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.23581691],\n",
              "          [-1.3338562 , -1.3338562 , -1.4384314 , ..., -0.2532461 ,\n",
              "           -0.2532461 , -0.2532461 ]]], dtype=float32),\n",
              "  array([[[ 0.07406463,  0.07406463,  0.09118938, ...,  0.70768046,\n",
              "            0.72480524,  0.74193   ],\n",
              "          [ 0.09118938,  0.09118938,  0.10831413, ...,  0.7590547 ,\n",
              "            0.74193   ,  0.7590547 ],\n",
              "          [ 0.10831413,  0.09118938,  0.12543888, ...,  0.79330426,\n",
              "            0.7761795 ,  0.7761795 ],\n",
              "          ...,\n",
              "          [-0.35405433, -0.42255333, -0.5253019 , ..., -1.5870366 ,\n",
              "           -1.5699118 , -1.5699118 ],\n",
              "          [-0.7136741 , -0.88492167, -1.0390445 , ..., -1.5699118 ,\n",
              "           -1.5699118 , -1.5527872 ],\n",
              "          [-1.2445416 , -1.2616663 , -1.2959158 , ..., -1.5870366 ,\n",
              "           -1.5870366 , -1.5356624 ]],\n",
              "  \n",
              "         [[ 0.2051822 ,  0.2051822 ,  0.2226892 , ...,  0.8529412 ,\n",
              "            0.87044823,  0.88795525],\n",
              "          [ 0.2226892 ,  0.2226892 ,  0.2401962 , ...,  0.90546227,\n",
              "            0.88795525,  0.90546227],\n",
              "          [ 0.2401962 ,  0.2226892 ,  0.2577032 , ...,  0.94047624,\n",
              "            0.9229692 ,  0.9229692 ],\n",
              "          ...,\n",
              "          [-0.23249297, -0.30252096, -0.40756297, ..., -1.4929972 ,\n",
              "           -1.4754901 , -1.4754901 ],\n",
              "          [-0.60014   , -0.77521   , -0.93277305, ..., -1.4754901 ,\n",
              "           -1.4754901 , -1.457983  ],\n",
              "          [-1.1428571 , -1.160364  , -1.1953781 , ..., -1.4929972 ,\n",
              "           -1.4929972 , -1.4404761 ]],\n",
              "  \n",
              "         [[ 0.42649257,  0.42649257,  0.44392177, ...,  1.0713727 ,\n",
              "            1.0888019 ,  1.1062311 ],\n",
              "          [ 0.44392177,  0.44392177,  0.46135095, ...,  1.1236603 ,\n",
              "            1.1062311 ,  1.1236603 ],\n",
              "          [ 0.46135095,  0.44392177,  0.47878015, ...,  1.1585187 ,\n",
              "            1.1410894 ,  1.1410894 ],\n",
              "          ...,\n",
              "          [-0.0092374 , -0.07895417, -0.18352933, ..., -1.2641394 ,\n",
              "           -1.2467101 , -1.2467101 ],\n",
              "          [-0.37525046, -0.54954237, -0.7064052 , ..., -1.2467101 ,\n",
              "           -1.2467101 , -1.229281  ],\n",
              "          [-0.91555554, -0.9329847 , -0.9678431 , ..., -1.2641394 ,\n",
              "           -1.2641394 , -1.2118517 ]]], dtype=float32)],\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "custom_dataset = CustomDataset(combined_train)\n",
        "custom_dataset[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zihO8aa0cjKh"
      },
      "outputs": [],
      "source": [
        "# 导入需要的库\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 创建 DataLoader\n",
        "trainloader = DataLoader(custom_dataset, batch_size=127, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SGwJcfPBE2G",
        "outputId": "615f0ca0-cdf4-4d04-e071-d961f00db085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([1, 512, 1, 1])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "print(f1.shape)\n",
        "f1_squared = torch.pow(f1, 2)\n",
        "print(f1_squared.shape)\n",
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5a5RVH2yT5G",
        "outputId": "abfb6b9f-5eaa-45c1-c502-2271b45a4617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "f1_squared = torch.squeeze(f1_squared)\n",
        "print(f1_squared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8c9wMs83eX",
        "outputId": "07840e10-8594-44b7-f34f-7e43503a35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "print(f1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGEKEWSuorD",
        "outputId": "237061d1-0de8-457d-fdc7-743052b7066f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "fc_layer = modified_model.final_layer\n",
        "print(fc_layer.weight.shape)\n",
        "w = fc_layer.weight[1]**2\n",
        "\n",
        "print(w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJHhdBkAIYm",
        "outputId": "a6f09fc0-7e39-4e99-d8fb-8807e06b1517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1103,  0.0845, -1.4639,  0.0241],\n",
            "        [-0.1507, -0.0891, -0.3924,  0.3247]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([1, 3], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "image1 = torch.randn(3, 224, 224)  # 假设图片1的形状为 [3, 224, 224]\n",
        "image2 = torch.randn(3, 224, 224)  # 假设图片2的形状为 [3, 224, 224]\n",
        "\n",
        "input_tensor = torch.cat((image1.unsqueeze(0), image2.unsqueeze(0)), dim=0)\n",
        "input_tensor\n",
        "y=modified_model(input_tensor.to(device))[1]\n",
        "print(y)\n",
        "predicted = torch.argmax(y, dim=1)\n",
        "print(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90F789NYgK0e",
        "outputId": "ddb2cb2b-362b-4268-d42d-113ffe3a9ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 208MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4 classes\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.final_layer = list(model.children())[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features_flattened = features.view( x.shape[0], -1)\n",
        "        final_output = self.final_layer(features_flattened)\n",
        "\n",
        "        return features, final_output\n",
        "\n",
        "\n",
        "modified_model = ModifiedResNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBmyZK2PrrEX",
        "outputId": "c16ad7ee-a142-421f-ed53-6592ef18186d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [00:14,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [16/127], Loss: 0.8616, Accuracy: 64.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:26,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [32/127], Loss: 0.5792, Accuracy: 81.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:38,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [48/127], Loss: 0.9000, Accuracy: 71.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:51,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [64/127], Loss: 0.6752, Accuracy: 78.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:03,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [80/127], Loss: 0.3955, Accuracy: 84.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:15,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [96/127], Loss: 0.5488, Accuracy: 79.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:28,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [112/127], Loss: 0.4158, Accuracy: 84.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:39,  1.28it/s]\n",
            "16it [00:12,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [16/127], Loss: 0.5832, Accuracy: 79.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [32/127], Loss: 0.2979, Accuracy: 88.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [48/127], Loss: 0.4845, Accuracy: 85.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [64/127], Loss: 0.2933, Accuracy: 88.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [80/127], Loss: 0.2606, Accuracy: 91.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [96/127], Loss: 0.2809, Accuracy: 91.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [112/127], Loss: 0.3522, Accuracy: 88.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [16/127], Loss: 0.1380, Accuracy: 95.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [32/127], Loss: 0.1301, Accuracy: 95.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:37,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [48/127], Loss: 0.1396, Accuracy: 95.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [64/127], Loss: 0.1534, Accuracy: 94.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [80/127], Loss: 0.1357, Accuracy: 94.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [96/127], Loss: 0.1608, Accuracy: 94.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:26,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [112/127], Loss: 0.2093, Accuracy: 93.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [16/127], Loss: 0.0900, Accuracy: 96.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [32/127], Loss: 0.0879, Accuracy: 96.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [48/127], Loss: 0.1265, Accuracy: 95.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [64/127], Loss: 0.0770, Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [80/127], Loss: 0.0653, Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [96/127], Loss: 0.0736, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [112/127], Loss: 0.1112, Accuracy: 96.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [16/127], Loss: 0.0437, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [32/127], Loss: 0.0590, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [48/127], Loss: 0.0351, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [64/127], Loss: 0.0456, Accuracy: 98.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [80/127], Loss: 0.0573, Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [96/127], Loss: 0.0669, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [112/127], Loss: 0.0852, Accuracy: 97.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [16/127], Loss: 0.0539, Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [32/127], Loss: 0.0398, Accuracy: 99.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [48/127], Loss: 0.0370, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:48,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [64/127], Loss: 0.0367, Accuracy: 98.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [80/127], Loss: 0.0410, Accuracy: 98.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [96/127], Loss: 0.0813, Accuracy: 96.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [112/127], Loss: 0.0622, Accuracy: 98.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.31it/s]\n",
            "16it [00:12,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [16/127], Loss: 0.0621, Accuracy: 97.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [32/127], Loss: 0.0654, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [48/127], Loss: 0.0872, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [64/127], Loss: 0.1100, Accuracy: 96.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [80/127], Loss: 0.1185, Accuracy: 95.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [96/127], Loss: 0.0934, Accuracy: 96.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [112/127], Loss: 0.0711, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.31it/s]\n",
            "16it [00:12,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [16/127], Loss: 0.0266, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [32/127], Loss: 0.0388, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [48/127], Loss: 0.0180, Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [64/127], Loss: 0.0094, Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [80/127], Loss: 0.0184, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [96/127], Loss: 0.0363, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:26,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [112/127], Loss: 0.0203, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [16/127], Loss: 0.0294, Accuracy: 99.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [32/127], Loss: 0.0283, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [48/127], Loss: 0.0408, Accuracy: 98.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:49,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [64/127], Loss: 0.0204, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [80/127], Loss: 0.0354, Accuracy: 99.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [96/127], Loss: 0.0364, Accuracy: 98.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [112/127], Loss: 0.0614, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:37,  1.30it/s]\n",
            "16it [00:12,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [16/127], Loss: 0.0492, Accuracy: 99.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:24,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [32/127], Loss: 0.0283, Accuracy: 99.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "48it [00:36,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [48/127], Loss: 0.0185, Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "64it [00:48,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [64/127], Loss: 0.0285, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "80it [01:01,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [80/127], Loss: 0.0345, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "96it [01:13,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [96/127], Loss: 0.0332, Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "112it [01:25,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [112/127], Loss: 0.0254, Accuracy: 99.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [01:36,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 16\n",
        "\n",
        "# 创建 DataLoader 实例\n",
        "\n",
        "trainloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "optimizer = optim.SGD(modified_model.parameters(), lr=0.01, momentum=0.9)\n",
        "modified_model=modified_model.to(device).train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, items in tqdm(enumerate(trainloader, 0)):\n",
        "        try:\n",
        "            input_tensor = torch.cat((items[0][0], items[0][1]), dim=0).to(device)\n",
        "            labels = torch.cat((items[1], items[1]), dim=0).to(device)\n",
        "            outputs = modified_model(input_tensor)[1]\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            ERM_loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            lam_loss_all = 0.0\n",
        "            fc_layer = modified_model.final_layer\n",
        "\n",
        "            for j in range(batch_size):\n",
        "\n",
        "                y = items[1][j].to(device)           # jth class label\n",
        "                images1 = items[0][0][j].to(device)  # jth first image\n",
        "                images2 = items[0][1][j].to(device)  # jth second image\n",
        "\n",
        "                f1 = modified_model(images1.unsqueeze(0))[0]\n",
        "                f2 = modified_model(images2.unsqueeze(0))[0]\n",
        "\n",
        "                w = fc_layer.weight[y] ** 2\n",
        "                diff = torch.squeeze(torch.pow(f1- f2, 2))\n",
        "                lam_loss = torch.sum(torch.mul(diff, w))\n",
        "\n",
        "                lam_loss_all += lam_loss\n",
        "\n",
        "\n",
        "            lam_loss_all /= batch_size\n",
        "            loss = ERM_loss + 1 * lam_loss_all\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i+1) %  16== 0:\n",
        "                accuracy = 100 * correct / total\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, len(trainloader), running_loss/16, accuracy))\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred at epoch {epoch+1}, step {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    torch.save(modified_model.state_dict(), f\"/content/drive/MyDrive/ip1/output_O2O_resnet50_model/output_O2O_hard_epoch_{epoch+1}.pth\")\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34hKBm823Sg",
        "outputId": "c53f991f-43c9-4dbf-d087-7adaee269365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[-1.6213, -1.6727, -2.0665,  ..., -0.3369, -0.3541, -0.3369],\n",
            "         [-1.2445, -1.0904, -1.8782,  ..., -0.3369, -0.3369, -0.3198],\n",
            "         [-1.7240, -1.1075, -1.4329,  ..., -0.3198, -0.3541, -0.3369],\n",
            "         ...,\n",
            "         [-1.5528, -0.9020,  1.0673,  ..., -1.2959, -1.0219, -1.0904],\n",
            "         [ 0.7762,  1.7865,  1.4954,  ..., -1.1418, -1.3473, -1.5699],\n",
            "         [ 1.8379,  0.3481, -0.5767,  ...,  1.5297,  0.2624, -1.2959]],\n",
            "\n",
            "        [[-1.5455, -1.5980, -1.8606,  ...,  0.9755,  0.9405,  0.8880],\n",
            "         [-1.1253, -0.8978, -1.7381,  ...,  0.9755,  0.9580,  0.9055],\n",
            "         [-1.5980, -0.8978, -1.4055,  ...,  0.9930,  0.9755,  0.9230],\n",
            "         ...,\n",
            "         [-1.7556, -0.9503,  1.0280,  ..., -1.3704, -1.0728, -1.0903],\n",
            "         [ 0.7304,  1.7458,  1.5007,  ..., -1.1604, -1.3529, -1.5980],\n",
            "         [ 1.9384,  0.2227, -0.7052,  ...,  1.5882,  0.3627, -1.3354]],\n",
            "\n",
            "        [[-1.4733, -1.5779, -1.6127,  ...,  2.2391,  2.2043,  2.2217],\n",
            "         [-1.1421, -1.0027, -1.7173,  ...,  2.2391,  2.2217,  2.2566],\n",
            "         [-1.5604, -1.0376, -1.5081,  ...,  2.2391,  2.2391,  2.2740],\n",
            "         ...,\n",
            "         [-1.5256, -0.6890,  1.2457,  ..., -0.6890, -0.3753, -0.4101],\n",
            "         [ 0.7751,  1.8731,  1.7163,  ..., -0.0964, -0.6541, -1.0376],\n",
            "         [ 2.0823,  0.5659, -0.5495,  ...,  2.1520,  1.3677, -0.6541]]]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "testdata = torch.load('/content/drive/MyDrive/ip1/testdata_O2O/testdata_hard.pt')\n",
        "len(testdata)\n",
        "print(testdata[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAWgmfNd25rs",
        "outputId": "a2b99fbf-d8e2-4a52-f3a1-dd240630846a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/output_O2O_resnet50_model/output_O2O_hard_epoch_10.pth'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy"
      ],
      "metadata": {
        "id": "tEy8VCn39eGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOJujGudYhYa",
        "outputId": "ee4b1d2e-6ef4-49c4-ffc9-88178db43f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 198/198 [4:38:13<00:00, 84.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分类任务的准确率: 70.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip1/output_O2O_resnet50_model/output_O2O_hard_epoch_10.pth'))\n",
        "modified_model = modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "# 将测试数据集转化为 DataLoader\n",
        "test_loader = DataLoader(testdata, batch_size=128, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = modified_model(images)[1]\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1ygIB_HDyY",
        "outputId": "12c8fef2-8817-435e-bd66-336564f8ea96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [3:22:21<00:00, 61.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分类任务的准确率: 75.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "modified_model.load_state_dict(torch.load('/content/drive/MyDrive/ip/output_medium_epoch_10.pth'))\n",
        "modified_model.to(device)\n",
        "modified_model.eval()\n",
        "\n",
        "\n",
        "# 加载.pt文件\n",
        "\n",
        "test_loader_medium = DataLoader(testdata_medium, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader_medium):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = modified_model(images)[1]\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('分类任务的准确率: {:.2f}%'.format(accuracy * 100))\n",
        "0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28HS3FWGtR8s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset:\n",
        "    def __init__(self, npy_file, transform=None):\n",
        "        self.data = np.load(npy_file, allow_pickle=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index][0], self.data[index][1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def to_tensor(self):\n",
        "        tensor_data = []\n",
        "        for image, label in self.data:\n",
        "            tensor_data.append((torch.tensor(image), label))\n",
        "\n",
        "        return tensor_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hFvXsW8SrYFM",
        "outputId": "a7ffd795-e2a5-499c-b0be-f80562e9f7a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many dimensions 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c8bbd58e4b7a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ip/training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtensor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),                     # 调整图像短边至 256 像素\n",
        "    transforms.CenterCrop(224),                 # 中心裁剪图像为 224x224\n",
        "    transforms.ToTensor(),                      # 转换图像为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化图像数据\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 加载自定义数据集\n",
        "dataset = CustomDataset(npy_file=\"/content/drive/MyDrive/ip/training_data.npy\", transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 创建 DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MztB9GY4v4yo",
        "outputId": "3392943a-290f-4547-8cb4-cef983a10d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Type: <class '__main__.CustomDataset'>\n",
            "Dataset Dimension: (25344, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset_type = type(dataset)\n",
        "print(\"Dataset Type:\", dataset_type)\n",
        "\n",
        "# 获取数据集的维度\n",
        "dataset_dimension = dataset.data.shape\n",
        "print(\"Dataset Dimension:\", dataset_dimension)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EOBx1nCxuCsC",
        "outputId": "ac4a35e3-ae9c-450d-84a0-d76fc73641c0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unexpected type <class 'tuple'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d57b01628137>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 获取 DataLoader 中的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 打印第一个批次的输入数据和标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-0ebcb26d75fc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_dimensions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected type {type(img)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'tuple'>"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch 是一个列表，包含了一个批次的样本数据\n",
        "    # 在这里你可以自定义处理逻辑，将样本转换为张量形式\n",
        "\n",
        "    # 假设 batch 中的每个元素是一个元组，其中包含输入数据和对应的标签\n",
        "    inputs = [item[0] for item in batch]  # 提取输入数据\n",
        "    labels = [item[1] for item in batch]  # 提取标签\n",
        "\n",
        "    # 将输入数据和标签转换为张量形式\n",
        "    inputs_tensor = torch.tensor(inputs)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    return inputs_tensor, labels_tensor\n",
        "\n",
        "# 定义 DataLoader，指定 collate_fn 参数为自定义的 collate_fn 函数\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 获取 DataLoader 中的数据\n",
        "inputs, labels = next(iter(data_loader))\n",
        "\n",
        "# 打印第一个批次的输入数据和标签\n",
        "print(\"First Batch Inputs:\", inputs)\n",
        "print(\"First Batch Labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsUjsKgl-2i",
        "outputId": "012f56c5-3a7e-4912-ad02-2443ff0d8f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (25344, 2)\n",
            "Train Y shape: (25344,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "\n",
        "for element in array:\n",
        "\n",
        "    sample, label = element\n",
        "\n",
        "    train_x.append(sample)\n",
        "    train_y.append(label)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHRm6Ylmz7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpL-8JSj55R",
        "outputId": "9512c9a5-a704-4b99-b006-6df0900056bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([('corgi_2105.png', 'corgi_954.png'), 'corgi'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qYXYu7OrxQc",
        "outputId": "bfdbc041-8821-4b96-9dc4-c915662440e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder contains 3168 images.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# 指定文件夹路径\n",
        "folder_path = '/content/drive/MyDrive/ip/SpawriousImages/bulldog'\n",
        "\n",
        "# 使用glob.glob获取所有图片文件的路径，并计算数量\n",
        "num_images = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
        "print(f'The folder contains {num_images} images.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFzy3YrH9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rx8CzfX9rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGjjkXis9rpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproduce:\n"
      ],
      "metadata": {
        "id": "r69Yy9KS9r3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFjpaL71qgR",
        "outputId": "25c3c22d-1295-431c-de66-aeedc0711426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3864667587  0.3897000789  0.3901163938  0.3981846882  0.3810416256  0.4013417522  0.0000000000  1.5313433409  5.6991815567  0             27.390903472 \n",
            "0.7663247189  0.7667719021  0.9904320379  0.9861878453  0.9788913001  0.9668508287  1.2625764451  0.1483003787  5.7843055725  100           0.6112645364 \n",
            "0.7623791675  0.7582872928  0.9927993687  0.9881610103  0.9869796804  0.9798737174  2.5251528901  0.0304591087  5.7843055725  200           0.6120824623 \n",
            "0.8103176169  0.8086029992  0.9964490037  0.9881610103  0.9929966463  0.9798737174  3.7877293352  0.0201038574  5.7843055725  300           0.6128335547 \n",
            "0.7342177944  0.7229676401  0.9921088972  0.9881610103  0.9876701519  0.9731649566  5.0503057802  0.0166535372  5.7843055725  400           0.6066111851 \n",
            "0.7267705662  0.7213891081  0.9958571710  0.9909234412  0.9922075360  0.9763220205  6.3128822253  0.0185868401  5.7843055725  500           0.6118927002 \n",
            "0.7765831525  0.7778216259  0.9984217794  0.9925019732  0.9967449201  0.9818468824  7.5754586703  0.0134620355  5.7843055725  600           0.6051793170 \n",
            "0.7576938252  0.7480268350  0.9978299467  0.9936858721  0.9957585323  0.9842146803  8.8380351154  0.0087729464  5.7843055725  700           0.6085211968 \n",
            "0.7600611560  0.7563141279  0.9984217794  0.9925019732  0.9962517262  0.9818468824  10.100611560  0.0123126021  5.7843055725  800           0.6048365140 \n",
            "0.7093115013  0.7091554854  0.9961530874  0.9885556433  0.9950680608  0.9818468824  11.363188005  0.0064040128  5.7843055725  900           0.6142849422 \n",
            "0.7815150917  0.7792028414  0.9968435589  0.9901341752  0.9906293154  0.9790844515  12.625764450  0.0093996652  5.7843055725  1000          0.6039929366 \n",
            "0.7462024068  0.7490134175  0.9994081673  0.9921073402  0.9986190570  0.9834254144  13.888340895  0.0092029764  5.7843055725  1100          0.6129468703 \n",
            "0.8009469323  0.7959747435  0.9992108897  0.9928966062  0.9991122509  0.9857932123  15.150917340  0.0058361374  5.7843055725  1200          0.6129310250 \n",
            "0.7381633458  0.7391475927  0.9972381140  0.9897395422  0.9964490037  0.9802683504  16.413493785  0.0065432409  5.7843055725  1300          0.6122647572 \n",
            "0.6935292957  0.6906077348  0.9981258631  0.9913180742  0.9978299467  0.9802683504  17.676070230  0.0046631041  5.7843055725  1400          0.6144099188 \n",
            "0.6489938844  0.6475927388  0.9986190570  0.9940805051  0.9951666995  0.9786898185  18.938646675  0.0084209092  5.7843055725  1500          0.6136151099 \n",
            "0.7438350760  0.7450670876  0.9994081673  0.9913180742  0.9993095285  0.9869771113  20.201223120  0.0082047096  5.7843055725  1600          0.6134618235 \n",
            "0.7649437759  0.7588792423  0.9970408365  0.9885556433  0.9971394752  0.9794790845  21.463799566  0.0020670449  5.7843055725  1700          0.6151823425 \n",
            "0.8479976327  0.8433307024  0.9973367528  0.9893449092  0.9966462813  0.9767166535  22.726376011  0.0058088228  5.7843055725  1800          0.6114165998 \n",
            "0.7854113237  0.7847277032  0.9984217794  0.9921073402  0.9957585323  0.9814522494  23.988952456  0.0053677419  5.7843055725  1900          0.6099036169 \n",
            "0.7859538370  0.7786108919  0.9989149734  0.9917127072  0.9975340304  0.9834254144  25.251528901  0.0037218446  5.7843055725  2000          0.6132613826 \n",
            "0.6918524364  0.6793606946  0.9976326692  0.9897395422  0.9973367528  0.9830307814  26.514105346  0.0072307730  5.7843055725  2100          0.6134376049 \n",
            "0.7332314066  0.7269139700  0.9992108897  0.9948697711  0.9986190570  0.9802683504  27.776681791  0.0073834352  5.7843055725  2200          0.6204751110 \n",
            "0.7945847307  0.7878847672  0.9979285855  0.9913180742  0.9969421977  0.9818468824  29.039258236  0.0084000665  5.7843055725  2300          0.6125090265 \n",
            "0.7764845137  0.7647987372  1.0000000000  0.9917127072  0.9999013612  0.9834254144  30.301834681  0.0061496431  5.7843055725  2400          0.6324354410 \n",
            "0.6687216413  0.6590370955  0.9953639771  0.9834254144  0.9920102584  0.9767166535  31.564411126  0.0049843378  5.7843055725  2500          0.6270753837 \n",
            "0.7318011442  0.7241515391  0.9984217794  0.9889502762  0.9978299467  0.9814522494  32.826987571  0.0057329830  5.7843055725  2600          0.6227247167 \n",
            "0.7836851450  0.7756511444  0.9999013612  0.9944751381  0.9992108897  0.9838200474  34.089564016  0.0009479631  5.7843055725  2700          0.6132366180 \n",
            "0.7607023081  0.7576953433  0.9985204182  0.9925019732  0.9973367528  0.9802683504  35.352140461  0.0028693231  5.7843055725  2800          0.6186019158 \n",
            "0.7607516275  0.7513812155  0.9984217794  0.9885556433  0.9939830341  0.9767166535  36.614716906  0.0079865522  5.7843055725  2900          0.6299188948 \n",
            "0.7857072401  0.7758484609  0.9998027224  0.9909234412  0.9995068061  0.9846093133  37.877293351  0.0030832417  5.7843055725  3000          0.6098960829 \n",
            "0.7091635431  0.6939621152  0.9978299467  0.9885556433  0.9969421977  0.9771112865  39.139869796  0.0061063865  5.7843055725  3100          0.6046432948 \n",
            "0.7215427106  0.7095501184  0.9965476425  0.9893449092  0.9955612547  0.9806629834  40.402446241  0.0045622018  5.7843055725  3200          0.6033505225 \n",
            "0.7802821069  0.7715074980  0.9998027224  0.9925019732  0.9990136122  0.9881610103  41.665022686  0.0067104823  5.7843055725  3300          0.6084430003 \n",
            "0.7143420793  0.7109313339  0.9959558098  0.9869771113  0.9970408365  0.9782951855  42.927599132  0.0011498852  5.7843055725  3400          0.6063428593 \n",
            "0.6730124285  0.6653512234  0.9973367528  0.9889502762  0.9950680608  0.9739542226  44.190175577  0.0085864400  5.7843055725  3500          0.6008972216 \n",
            "0.6958966266  0.6898184688  0.9998027224  0.9921073402  0.9996054449  0.9857932123  45.452752022  0.0064733884  5.7843055725  3600          0.6162673044 \n",
            "0.7082757940  0.7028413575  1.0000000000  0.9956590371  0.9999013612  0.9889502762  46.715328467  0.0012216950  5.7843055725  3700          0.6148056483 \n",
            "0.7186328664  0.7099447514  1.0000000000  0.9944751381  1.0000000000  0.9889502762  47.977904912  0.0000642128  5.7843055725  3800          0.6070259309 \n",
            "0.7200631288  0.7113259669  0.9997040836  0.9921073402  0.9998027224  0.9861878453  49.240481357  0.0027398469  5.7843055725  3900          0.6156265235 \n",
            "0.7058591438  0.7091554854  0.9995068061  0.9940805051  0.9994081673  0.9881610103  50.503057802  0.0021378895  5.7843055725  4000          0.6109139323 \n",
            "0.6887453147  0.6779794791  0.9994081673  0.9917127072  0.9993095285  0.9861878453  51.765634247  0.0059131746  5.7843055725  4100          0.6170952582 \n",
            "0.6611757743  0.6572612470  0.9973367528  0.9913180742  0.9970408365  0.9806629834  53.028210692  0.0104169882  5.7843055725  4200          0.6217965150 \n",
            "0.6604853028  0.6515390687  0.9982245019  0.9905288082  0.9955612547  0.9763220205  54.290787137  0.0042702924  5.7843055725  4300          0.6096786547 \n",
            "0.7143913987  0.7036306235  0.9992108897  0.9936858721  0.9978299467  0.9802683504  55.553363582  0.0065798409  5.7843055725  4400          0.6024882984 \n",
            "0.7114815545  0.7056037885  0.9999013612  0.9952644041  0.9997040836  0.9917127072  56.815940027  0.0049846871  5.7843055725  4500          0.6199430537 \n",
            "0.6791773525  0.6659431728  0.9992108897  0.9928966062  0.9990136122  0.9806629834  58.078516472  0.0005054018  5.7843055725  4600          0.6146416759 \n",
            "0.7630203196  0.7582872928  0.9999013612  0.9956590371  1.0000000000  0.9869771113  59.341092917  0.0010236725  5.7843055725  4700          0.6122219038 \n",
            "0.7570033537  0.7513812155  0.9999013612  0.9952644041  0.9999013612  0.9881610103  60.603669362  0.0000619924  5.7843055725  4800          0.6136543655 \n",
            "0.6861807063  0.6712707182  0.9983231407  0.9889502762  0.9973367528  0.9810576164  61.866245807  0.0034500310  5.7843055725  4900          0.6070861173 \n",
            "0.6905208128  0.6902131018  0.9999013612  0.9952644041  0.9989149734  0.9822415154  63.128822252  0.0057498560  5.7843055725  5000          0.6079993272 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647,\\\n",
        "        \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLCqJpRpZla",
        "outputId": "1a0e5102-ef83-43f2-d0eb-2034bc3093f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        71.1 +/- 0.0               71.1                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          Avg                       \n",
            "ERM                        69.1 +/- 0.0               69.1                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSJ6vNQiFYD",
        "outputId": "6a81e146-dd33-456a-c9e6-95da2b3fd601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_medium/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 107MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3137699744  0.3155090766  0.4236535806  0.4340962904  0.4138883409  0.4352801894  0.0000000000  1.5721870661  5.6991815567  0             121.17406868 \n",
            "0.6615210101  0.6598263615  0.9904320379  0.9889502762  0.9813572697  0.9790844515  1.2625764451  0.1269948081  5.7843055725  100           0.5992083979 \n",
            "0.6557999605  0.6521310182  0.9934898402  0.9928966062  0.9871769580  0.9810576164  2.5251528901  0.0242757843  5.7843055725  200           0.6010344815 \n",
            "0.7217893076  0.7209944751  0.9941803117  0.9901341752  0.9905306767  0.9822415154  3.7877293352  0.0248986174  5.7843055725  300           0.6032668781 \n",
            "0.6864766226  0.6795580110  0.9990136122  0.9976322021  0.9960544486  0.9857932123  5.0503057802  0.0148176499  5.7843055725  400           0.6020192647 \n",
            "0.7547346617  0.7531570639  0.9977313080  0.9940805051  0.9947721444  0.9857932123  6.3128822253  0.0099429032  5.7843055725  500           0.6023221374 \n",
            "0.6849477214  0.6823204420  0.9983231407  0.9960536701  0.9959558098  0.9822415154  7.5754586703  0.0127289780  5.7843055725  600           0.5986590838 \n",
            "0.6821365161  0.6754143646  0.9976326692  0.9940805051  0.9963503650  0.9853985793  8.8380351154  0.0070593210  5.7843055725  700           0.5992206550 \n",
            "0.7350562241  0.7342146803  0.9992108897  0.9964483031  0.9980272243  0.9877663773  10.100611560  0.0090081152  5.7843055725  800           0.5954315782 \n",
            "0.6724699152  0.6637726914  0.9995068061  0.9956590371  0.9983231407  0.9877663773  11.363188005  0.0071447303  5.7843055725  900           0.5991444755 \n",
            "0.7353521405  0.7310576164  0.9983231407  0.9964483031  0.9978299467  0.9873717443  12.625764450  0.0082690991  5.7843055725  1000          0.6007423878 \n",
            "0.7047247978  0.6971191792  0.9989149734  0.9952644041  0.9990136122  0.9861878453  13.888340895  0.0095554909  5.7843055725  1100          0.5999678946 \n",
            "0.7175478398  0.7115232833  0.9984217794  0.9956590371  0.9976326692  0.9850039463  15.150917340  0.0074848697  5.7843055725  1200          0.6209489059 \n",
            "0.6003156441  0.5935280189  0.9908265930  0.9846093133  0.9845137108  0.9739542226  16.413493785  0.0061670831  5.7843055725  1300          0.6227960443 \n",
            "0.7109883606  0.6983030781  0.9990136122  0.9932912391  0.9984217794  0.9877663773  17.676070230  0.0095289110  5.7843055725  1400          0.6323509693 \n",
            "0.7592227264  0.7523677979  0.9981258631  0.9956590371  0.9963503650  0.9846093133  18.938646675  0.0060454098  5.7843055725  1500          0.6389152265 \n",
            "0.7201617676  0.7127071823  0.9993095285  0.9956590371  0.9986190570  0.9889502762  20.201223120  0.0078355287  5.7843055725  1600          0.6430245256 \n",
            "0.7292858552  0.7211917916  0.9998027224  0.9956590371  0.9997040836  0.9925019732  21.463799566  0.0018214593  5.7843055725  1700          0.6293191934 \n",
            "0.7227756954  0.7123125493  0.9999013612  0.9968429361  0.9999013612  0.9893449092  22.726376011  0.0015204751  5.7843055725  1800          0.6129930377 \n",
            "0.6896823831  0.6892265193  0.9999013612  0.9964483031  0.9998027224  0.9897395422  23.988952456  0.0028037445  5.7843055725  1900          0.6100966716 \n",
            "0.7653383310  0.7582872928  0.9993095285  0.9964483031  0.9994081673  0.9932912391  25.251528901  0.0004546101  5.7843055725  2000          0.6023241353 \n",
            "0.7000887749  0.6896211523  0.9985204182  0.9936858721  0.9977313080  0.9865824783  26.514105346  0.0064458975  5.7843055725  2100          0.5988242507 \n",
            "0.6427303216  0.6410812944  0.9988163346  0.9968429361  0.9988163346  0.9873717443  27.776681791  0.0060048382  5.7843055725  2200          0.5992763162 \n",
            "0.7598638785  0.7527624309  1.0000000000  0.9988161010  0.9998027224  0.9905288082  29.039258236  0.0023152082  5.7843055725  2300          0.5971370530 \n",
            "0.6899289801  0.6874506709  0.9981258631  0.9913180742  0.9959558098  0.9873717443  30.301834681  0.0050733112  5.7843055725  2400          0.5996246147 \n",
            "0.7281515092  0.7239542226  0.9898402052  0.9767166535  0.9817518248  0.9723756906  31.564411126  0.0072616203  5.7843055725  2500          0.5943894243 \n",
            "0.7001380943  0.6992896606  0.9995068061  0.9956590371  0.9988163346  0.9881610103  32.826987571  0.0440309145  5.7843055725  2600          0.6050425506 \n",
            "0.7320970606  0.7237569061  0.9992108897  0.9956590371  0.9990136122  0.9905288082  34.089564016  0.0048803466  5.7843055725  2700          0.6109957647 \n",
            "0.6917044782  0.6831097080  0.9991122509  0.9932912391  0.9984217794  0.9846093133  35.352140461  0.0067349893  5.7843055725  2800          0.6111056709 \n",
            "0.7432432432  0.7421073402  1.0000000000  0.9984214680  0.9995068061  0.9893449092  36.614716906  0.0033565566  5.7843055725  2900          0.6050006723 \n",
            "0.6926415467  0.6876479874  0.9998027224  0.9952644041  0.9990136122  0.9857932123  37.877293351  0.0042016615  5.7843055725  3000          0.6177810144 \n",
            "0.7025547445  0.6949486977  0.9993095285  0.9976322021  0.9993095285  0.9897395422  39.139869796  0.0010211611  5.7843055725  3100          0.6140088010 \n",
            "0.7367330834  0.7367797948  0.9998027224  0.9972375691  0.9999013612  0.9893449092  40.402446241  0.0002262877  5.7843055725  3200          0.6185925364 \n",
            "0.7027027027  0.7020520916  1.0000000000  0.9976322021  1.0000000000  0.9913180742  41.665022686  0.0000888569  5.7843055725  3300          0.6096006036 \n",
            "0.6934306569  0.6850828729  0.9984217794  0.9952644041  0.9978299467  0.9865824783  42.927599132  0.0015141229  5.7843055725  3400          0.6194707274 \n",
            "0.7383113040  0.7346093133  0.9997040836  0.9972375691  0.9996054449  0.9901341752  44.190175577  0.0052019510  5.7843055725  3500          0.6134506059 \n",
            "0.7237127639  0.7231649566  1.0000000000  0.9980268350  0.9997040836  0.9865824783  45.452752022  0.0014862453  5.7843055725  3600          0.6209367180 \n",
            "0.7188794634  0.7131018153  1.0000000000  0.9972375691  1.0000000000  0.9921073402  46.715328467  0.0002694762  5.7843055725  3700          0.6362010550 \n",
            "0.7268692050  0.7259273875  0.9997040836  0.9940805051  0.9994081673  0.9897395422  47.977904912  0.0023738948  5.7843055725  3800          0.6051948500 \n",
            "0.7473367528  0.7415153907  0.9980272243  0.9940805051  0.9964490037  0.9838200474  49.240481357  0.0045498827  5.7843055725  3900          0.6058934021 \n",
            "0.7382126652  0.7344119968  0.9985204182  0.9968429361  0.9986190570  0.9869771113  50.503057802  0.0044438702  5.7843055725  4000          0.5994641709 \n",
            "0.6705464589  0.6643646409  0.9996054449  0.9925019732  0.9985204182  0.9850039463  51.765634247  0.0016873248  5.7843055725  4100          0.6027762508 \n",
            "0.7104458473  0.7071823204  0.9964490037  0.9877663773  0.9947721444  0.9822415154  53.028210692  0.0083639084  5.7843055725  4200          0.6098940921 \n",
            "0.7332807260  0.7302683504  1.0000000000  0.9972375691  1.0000000000  0.9905288082  54.290787137  0.0016600816  5.7843055725  4300          0.6013520265 \n",
            "0.7476326692  0.7407261247  0.9999013612  0.9948697711  0.9993095285  0.9897395422  55.553363582  0.0006339125  5.7843055725  4400          0.6025332189 \n",
            "0.7573979089  0.7525651144  0.9995068061  0.9980268350  0.9997040836  0.9877663773  56.815940027  0.0026876356  5.7843055725  4500          0.6076181936 \n",
            "0.6943677254  0.6925808998  0.9982245019  0.9936858721  0.9981258631  0.9842146803  58.078516472  0.0067190079  5.7843055725  4600          0.6034590435 \n",
            "0.7445255474  0.7391475927  0.9998027224  0.9976322021  0.9998027224  0.9909234412  59.341092917  0.0018836914  5.7843055725  4700          0.6027166390 \n",
            "0.7162655356  0.7067876875  1.0000000000  0.9964483031  0.9995068061  0.9885556433  60.603669362  0.0002436092  5.7843055725  4800          0.6082473326 \n",
            "0.7426020911  0.7385556433  0.9997040836  0.9948697711  0.9996054449  0.9905288082  61.866245807  0.0029796615  5.7843055725  4900          0.6071765113 \n",
            "0.7145393569  0.7097474349  0.9997040836  0.9944751381  0.9995068061  0.9897395422  63.128822252  0.0053898869  5.7843055725  5000          0.5998121667 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_medium/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuk-R16KzgOs",
        "outputId": "88244172-31ce-4811-8014-0c01efa9820a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output/train_output_hard/\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|##########| 44.7M/44.7M [00:00<00:00, 122MB/s]\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             115.15087747 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.6141159964 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6257791138 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6224927640 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6194511318 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6173342490 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6224610925 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6156367707 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6182522154 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6168373513 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6274501014 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6201179457 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6196286297 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6265635109 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6200313568 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6176273632 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6281948471 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6170152378 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6204898381 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6164195275 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6218380213 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6168248272 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6204351020 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6241048074 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6225018644 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6205320001 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6193700123 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6194021606 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6208199739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6187628269 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6196645617 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6212025905 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6200934267 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6221250558 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6164404726 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6187021542 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6219896412 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6192560601 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6193850613 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6188530970 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6250334597 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6187652969 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6202621436 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6278406334 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6186798120 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6220876169 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6206880021 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6187240529 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6160216904 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6204047894 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6245353127 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output/train_output_hard/ \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd3W8kEpoNLl",
        "outputId": "3aafe63a-379d-4388-d85e-894fe453b5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/5 [00:00<?, ?it/s]\r                                                                                \rTotal records: 162\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.1 +/- 0.0               76.5 +/- 0.0               62.0 +/- 0.0               69.9                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   69.1 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        69.1 +/- 0.0               71.5 +/- 0.0               65.6 +/- 0.0               68.7                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtUrzrD4gOn",
        "outputId": "5a15d81f-aaee-46da-c1e9-64ebe124f6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3447425528  0.3441199684  0.4174393371  0.4167324388  0.3603274808  0.3756906077  0.0000000000  1.5444172621  5.6991815567  0             92.626631498 \n",
            "0.8121424344  0.8239936859  0.9850069047  0.9790844515  0.9830341290  0.9818468824  1.2625764451  0.1916547985  5.7843055725  100           0.6161201310 \n",
            "0.7284474255  0.7334254144  0.9866837641  0.9790844515  0.9876701519  0.9822415154  2.5251528901  0.0378335118  5.7843055725  200           0.6242212915 \n",
            "0.7226277372  0.7243488556  0.9810613533  0.9629044988  0.9826395739  0.9763220205  3.7877293352  0.0316097732  5.7843055725  300           0.6324607801 \n",
            "0.7568553955  0.7604577743  0.9951666995  0.9865824783  0.9946735056  0.9861878453  5.0503057802  0.0218457361  5.7843055725  400           0.6257872558 \n",
            "0.7536003156  0.7574980268  0.9976326692  0.9877663773  0.9951666995  0.9897395422  6.3128822253  0.0149130280  5.7843055725  500           0.6235587239 \n",
            "0.7291378970  0.7357932123  0.9983231407  0.9893449092  0.9986190570  0.9936858721  7.5754586703  0.0117882919  5.7843055725  600           0.6279401875 \n",
            "0.7667192740  0.7693370166  0.9972381140  0.9869771113  0.9940816729  0.9889502762  8.8380351154  0.0145306918  5.7843055725  700           0.6247380352 \n",
            "0.7499506806  0.7573007103  0.9987176958  0.9901341752  0.9971394752  0.9913180742  10.100611560  0.0118083848  5.7843055725  800           0.6312047601 \n",
            "0.7436871178  0.7490134175  0.9961530874  0.9853985793  0.9956598935  0.9897395422  11.363188005  0.0109967921  5.7843055725  900           0.6202681732 \n",
            "0.7388044979  0.7474348856  0.9984217794  0.9905288082  0.9988163346  0.9932912391  12.625764450  0.0094502301  5.7843055725  1000          0.6276606607 \n",
            "0.7751035707  0.7717048145  0.9973367528  0.9822415154  0.9943775893  0.9869771113  13.888340895  0.0125363544  5.7843055725  1100          0.6285728884 \n",
            "0.7802327875  0.7839384373  0.9979285855  0.9877663773  0.9977313080  0.9889502762  15.150917340  0.0060999116  5.7843055725  1200          0.6247079110 \n",
            "0.7494081673  0.7580899763  0.9963503650  0.9881610103  0.9939830341  0.9850039463  16.413493785  0.0112833397  5.7843055725  1300          0.6322773695 \n",
            "0.7387551785  0.7470402526  0.9997040836  0.9932912391  0.9991122509  0.9925019732  17.676070230  0.0054056202  5.7843055725  1400          0.6218444490 \n",
            "0.7769283882  0.7778216259  0.9954626159  0.9830307814  0.9946735056  0.9869771113  18.938646675  0.0055534037  5.7843055725  1500          0.6221671605 \n",
            "0.7031958966  0.7073796369  0.9993095285  0.9861878453  0.9988163346  0.9936858721  20.201223120  0.0049165712  5.7843055725  1600          0.6286919904 \n",
            "0.7267705662  0.7241515391  0.9984217794  0.9885556433  0.9983231407  0.9905288082  21.463799566  0.0085521347  5.7843055725  1700          0.6241571999 \n",
            "0.6414973368  0.6497632202  0.9959558098  0.9869771113  0.9966462813  0.9869771113  22.726376011  0.0072744866  5.7843055725  1800          0.6317688847 \n",
            "0.7176464786  0.7237569061  0.9986190570  0.9889502762  0.9985204182  0.9885556433  23.988952456  0.0103979792  5.7843055725  1900          0.6230329943 \n",
            "0.7049713948  0.7058011050  0.9990136122  0.9877663773  0.9986190570  0.9897395422  25.251528901  0.0090116992  5.7843055725  2000          0.6276224732 \n",
            "0.7456105741  0.7494080505  0.9995068061  0.9940805051  0.9988163346  0.9925019732  26.514105346  0.0028007768  5.7843055725  2100          0.6244829988 \n",
            "0.7336752811  0.7395422257  0.9983231407  0.9909234412  0.9982245019  0.9897395422  27.776681791  0.0026261529  5.7843055725  2200          0.6262957954 \n",
            "0.7256362202  0.7332280979  0.9992108897  0.9901341752  0.9988163346  0.9925019732  29.039258236  0.0057956400  5.7843055725  2300          0.6327015185 \n",
            "0.7500986388  0.7533543804  0.9999013612  0.9913180742  0.9996054449  0.9917127072  30.301834681  0.0036455327  5.7843055725  2400          0.6239596629 \n",
            "0.7312586309  0.7320441989  0.9995068061  0.9921073402  0.9990136122  0.9901341752  31.564411126  0.0055238133  5.7843055725  2500          0.6324523091 \n",
            "0.6998421779  0.7042225730  0.9975340304  0.9850039463  0.9986190570  0.9897395422  32.826987571  0.0033805106  5.7843055725  2600          0.6255412984 \n",
            "0.7127638587  0.7168508287  0.9993095285  0.9905288082  0.9987176958  0.9928966062  34.089564016  0.0076531138  5.7843055725  2700          0.6293179131 \n",
            "0.7118761097  0.7156669298  0.9982245019  0.9897395422  0.9994081673  0.9913180742  35.352140461  0.0009840014  5.7843055725  2800          0.6253333163 \n",
            "0.6811008088  0.6838989740  0.9984217794  0.9897395422  0.9981258631  0.9877663773  36.614716906  0.0084054508  5.7843055725  2900          0.6237844157 \n",
            "0.6834188203  0.6831097080  0.9950680608  0.9798737174  0.9948707832  0.9857932123  37.877293351  0.0044238523  5.7843055725  3000          0.6262417722 \n",
            "0.6974748471  0.6994869771  0.9990136122  0.9921073402  0.9991122509  0.9897395422  39.139869796  0.0053147116  5.7843055725  3100          0.6270702934 \n",
            "0.7625764451  0.7665745856  0.9983231407  0.9857932123  0.9987176958  0.9913180742  40.402446241  0.0073252049  5.7843055725  3200          0.6314353418 \n",
            "0.7540935096  0.7634175217  0.9960544486  0.9826361484  0.9956598935  0.9861878453  41.665022686  0.0049057113  5.7843055725  3300          0.6251897311 \n",
            "0.7499506806  0.7535516969  0.9972381140  0.9834254144  0.9981258631  0.9917127072  42.927599132  0.0060753603  5.7843055725  3400          0.6289313126 \n",
            "0.7582363385  0.7586819258  0.9996054449  0.9909234412  0.9991122509  0.9893449092  44.190175577  0.0043921365  5.7843055725  3500          0.6250557089 \n",
            "0.7938942592  0.7989344909  0.9983231407  0.9881610103  0.9973367528  0.9913180742  45.452752022  0.0058474739  5.7843055725  3600          0.6268724537 \n",
            "0.7414677451  0.7472375691  0.9993095285  0.9909234412  0.9994081673  0.9921073402  46.715328467  0.0069936835  5.7843055725  3700          0.6215211320 \n",
            "0.7010258434  0.7063930545  0.9998027224  0.9925019732  0.9993095285  0.9928966062  47.977904912  0.0050067931  5.7843055725  3800          0.6244132352 \n",
            "0.7601104754  0.7582872928  0.9984217794  0.9869771113  0.9954626159  0.9873717443  49.240481357  0.0033604602  5.7843055725  3900          0.6313518667 \n",
            "0.7292365358  0.7352012628  1.0000000000  0.9960536701  1.0000000000  0.9917127072  50.503057802  0.0013490497  5.7843055725  4000          0.6236331105 \n",
            "0.7278062734  0.7357932123  0.9999013612  0.9917127072  0.9997040836  0.9921073402  51.765634247  0.0003818883  5.7843055725  4100          0.6287024641 \n",
            "0.7287926613  0.7336227309  0.9989149734  0.9853985793  0.9990136122  0.9913180742  53.028210692  0.0050014239  5.7843055725  4200          0.6291932082 \n",
            "0.7303215624  0.7377663773  0.9999013612  0.9889502762  0.9997040836  0.9901341752  54.290787137  0.0019504495  5.7843055725  4300          0.6304660201 \n",
            "0.7283487867  0.7322415154  1.0000000000  0.9921073402  0.9992108897  0.9921073402  55.553363582  0.0029379294  5.7843055725  4400          0.6251601553 \n",
            "0.7387058591  0.7399368587  0.9985204182  0.9885556433  0.9974353916  0.9913180742  56.815940027  0.0021374228  5.7843055725  4500          0.6251562452 \n",
            "0.6670447820  0.6708760852  0.9999013612  0.9932912391  0.9989149734  0.9897395422  58.078516472  0.0064164825  5.7843055725  4600          0.6286752725 \n",
            "0.7800848294  0.7833464878  0.9954626159  0.9830307814  0.9954626159  0.9885556433  59.341092917  0.0082279910  5.7843055725  4700          0.6250292301 \n",
            "0.6997435392  0.7042225730  0.9991122509  0.9925019732  0.9993095285  0.9925019732  60.603669362  0.0060093180  5.7843055725  4800          0.6258044958 \n",
            "0.7043795620  0.7111286504  0.9996054449  0.9917127072  0.9991122509  0.9928966062  61.866245807  0.0029612238  5.7843055725  4900          0.6235942554 \n",
            "0.7195699349  0.7170481452  0.9990136122  0.9909234412  0.9976326692  0.9877663773  63.128822252  0.0055418774  5.7843055725  5000          0.6231913924 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_easy \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_easy \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVSmQgNyig5",
        "outputId": "d6ede5dd-1397-4f48-f18f-ba33b2f2faba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousM2M_medium\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.3572696784  0.3620757695  0.4539356875  0.4613259669  0.4520615506  0.4723756906  0.0000000000  1.6331243515  5.6991815567  0             55.661369085 \n",
            "0.4934405208  0.4964483031  0.9753403038  0.9688239937  0.9762280529  0.9723756906  1.2625764451  0.1566427394  5.7843055725  100           0.6162090135 \n",
            "0.5097159203  0.5185477506  0.9811599921  0.9775059195  0.9777076346  0.9668508287  2.5251528901  0.0377939333  5.7843055725  200           0.6225361347 \n",
            "0.5271256658  0.5380820837  0.9936871178  0.9881610103  0.9930952851  0.9861878453  3.7877293352  0.0288028434  5.7843055725  300           0.6236338639 \n",
            "0.4824422963  0.4968429361  0.9942789505  0.9877663773  0.9955612547  0.9909234412  5.0503057802  0.0388437792  5.7843055725  400           0.6268619251 \n",
            "0.5513908069  0.5586029992  0.9965476425  0.9869771113  0.9954626159  0.9869771113  6.3128822253  0.0148880032  5.7843055725  500           0.6201543760 \n",
            "0.4632570527  0.4727703236  0.9920102584  0.9794790845  0.9947721444  0.9857932123  7.5754586703  0.0180947598  5.7843055725  600           0.6200311804 \n",
            "0.3317715526  0.3326756117  0.9895442888  0.9767166535  0.9944762281  0.9893449092  8.8380351154  0.0098999443  5.7843055725  700           0.6183829451 \n",
            "0.4919609390  0.4948697711  0.9970408365  0.9865824783  0.9965476425  0.9857932123  10.100611560  0.0145966782  5.7843055725  800           0.6291699719 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousM2M_medium \\\n",
        "       --test_env 0\\\n",
        "       --output_dir /content/drive/MyDrive/ip/train_output_M2M/train_output_M2M_medium \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUY2J85V-Ad",
        "outputId": "9e6fcdee-21bb-48d4-e2a2-b3f4f60d6298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 51\n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.9 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.9 +/- 0.0               72.9                      \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousM2M_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   72.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousM2M_easy          Avg                       \n",
            "ERM                        72.0 +/- 0.0               72.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir /content/drive/MyDrive/ip/train_output_M2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFubiAzerSGY",
        "outputId": "f7a88181-e706-4af8-a327-0b1490d252a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                    | 0/13 [00:00<?, ?it/s]\r                                                                                \rTotal records: 53\n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               76.5 +/- 0.0               76.6                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_easy, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_easy          SpawriousO2O_medium        Avg                       \n",
            "ERM                        76.6 +/- 0.0               71.5 +/- 0.0               74.0                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW2WzQYG9FSV",
        "outputId": "66d56659-a265-45fe-fb14-15d19d5c51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_hard\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: train_output\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tarch: resnet18\n",
            "\tbatch_size: 128\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00016629177873519647\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: True\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.1975155295174919e-06\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.4142335766  0.4149565904  0.4636022884  0.4629044988  0.4567962123  0.4834254144  0.0000000000  1.6362296343  5.6991815567  0             99.749756574 \n",
            "0.6737522194  0.6799526440  0.9932925626  0.9928966062  0.9817518248  0.9771112865  1.2625764451  0.1007222116  5.7843055725  100           0.5983280587 \n",
            "0.6565890708  0.6610102605  0.9981258631  0.9936858721  0.9910238706  0.9822415154  2.5251528901  0.0317297802  5.7843055725  200           0.6206359911 \n",
            "0.6521996449  0.6568666140  0.9964490037  0.9952644041  0.9914184257  0.9830307814  3.7877293352  0.0230773503  5.7843055725  300           0.6142829299 \n",
            "0.6369599527  0.6377269140  0.9990136122  0.9944751381  0.9948707832  0.9838200474  5.0503057802  0.0168313400  5.7843055725  400           0.6070183587 \n",
            "0.6485500099  0.6499605367  0.9963503650  0.9925019732  0.9924048136  0.9826361484  6.3128822253  0.0153945841  5.7843055725  500           0.6080141449 \n",
            "0.7063523377  0.7048145225  0.9958571710  0.9893449092  0.9932925626  0.9779005525  7.5754586703  0.0123051464  5.7843055725  600           0.6082016397 \n",
            "0.6285263366  0.6310181531  0.9994081673  0.9964483031  0.9982245019  0.9857932123  8.8380351154  0.0085516402  5.7843055725  700           0.6092026901 \n",
            "0.5938548037  0.5909629045  0.9965476425  0.9921073402  0.9935884790  0.9775059195  10.100611560  0.0122149707  5.7843055725  800           0.6103980064 \n",
            "0.6399191162  0.6282557222  0.9989149734  0.9944751381  0.9983231407  0.9857932123  11.363188005  0.0123663498  5.7843055725  900           0.6360183382 \n",
            "0.6610278161  0.6527229676  0.9993095285  0.9952644041  0.9985204182  0.9850039463  12.625764450  0.0091402299  5.7843055725  1000          0.6049654841 \n",
            "0.6534819491  0.6507498027  0.9987176958  0.9932912391  0.9970408365  0.9838200474  13.888340895  0.0071214497  5.7843055725  1100          0.6108168197 \n",
            "0.6406589071  0.6400947119  0.9986190570  0.9948697711  0.9975340304  0.9822415154  15.150917340  0.0051001226  5.7843055725  1200          0.6118657756 \n",
            "0.6200434011  0.6181925809  0.9997040836  0.9964483031  0.9995068061  0.9897395422  16.413493785  0.0036594964  5.7843055725  1300          0.6163139319 \n",
            "0.6696093904  0.6685082873  0.9996054449  0.9948697711  0.9990136122  0.9885556433  17.676070230  0.0051081371  5.7843055725  1400          0.6108947682 \n",
            "0.6837147366  0.6801499605  0.9981258631  0.9921073402  0.9956598935  0.9857932123  18.938646675  0.0057097543  5.7843055725  1500          0.6053397083 \n",
            "0.6484513711  0.6430544594  0.9995068061  0.9956590371  0.9983231407  0.9869771113  20.201223120  0.0084781987  5.7843055725  1600          0.6072963905 \n",
            "0.6306963898  0.6276637727  0.9997040836  0.9956590371  0.9997040836  0.9901341752  21.463799566  0.0064773197  5.7843055725  1700          0.6118159246 \n",
            "0.6881041626  0.6831097080  0.9992108897  0.9936858721  0.9973367528  0.9814522494  22.726376011  0.0049345131  5.7843055725  1800          0.6154971886 \n",
            "0.7185342277  0.7085635359  0.9993095285  0.9925019732  0.9992108897  0.9857932123  23.988952456  0.0032887721  5.7843055725  1900          0.6100856686 \n",
            "0.6102288420  0.6065509077  0.9995068061  0.9948697711  0.9986190570  0.9865824783  25.251528901  0.0064822353  5.7843055725  2000          0.6081331706 \n",
            "0.6074176366  0.6075374901  0.9972381140  0.9905288082  0.9955612547  0.9826361484  26.514105346  0.0083867049  5.7843055725  2100          0.6135662699 \n",
            "0.6824324324  0.6777821626  0.9858946538  0.9767166535  0.9842177944  0.9644830308  27.776681791  0.0072365843  5.7843055725  2200          0.6160948730 \n",
            "0.6670941014  0.6653512234  0.9908265930  0.9818468824  0.9885579010  0.9751381215  29.039258236  0.0059027388  5.7843055725  2300          0.6087784386 \n",
            "0.6776484514  0.6837016575  0.9996054449  0.9925019732  0.9988163346  0.9830307814  30.301834681  0.0059906914  5.7843055725  2400          0.6098929572 \n",
            "0.6057407773  0.5990528808  0.9997040836  0.9936858721  0.9991122509  0.9869771113  31.564411126  0.0032687068  5.7843055725  2500          0.6067762327 \n",
            "0.7080785165  0.7024467245  0.9994081673  0.9936858721  0.9983231407  0.9869771113  32.826987571  0.0015344392  5.7843055725  2600          0.6125501800 \n",
            "0.6672913790  0.6564719811  0.9983231407  0.9901341752  0.9973367528  0.9818468824  34.089564016  0.0035554005  5.7843055725  2700          0.6110928893 \n",
            "0.6985598737  0.6925808998  0.9988163346  0.9944751381  0.9962517262  0.9775059195  35.352140461  0.0032736459  5.7843055725  2800          0.6085288739 \n",
            "0.6272933517  0.6274664562  0.9965476425  0.9917127072  0.9930952851  0.9755327545  36.614716906  0.0107579302  5.7843055725  2900          0.6073611617 \n",
            "0.6203886368  0.6146408840  0.9993095285  0.9913180742  0.9987176958  0.9850039463  37.877293351  0.0037031379  5.7843055725  3000          0.6072861338 \n",
            "0.6746892878  0.6675217048  0.9978299467  0.9905288082  0.9972381140  0.9834254144  39.139869796  0.0051513888  5.7843055725  3100          0.6083596730 \n",
            "0.6123495759  0.6081294396  0.9988163346  0.9948697711  0.9983231407  0.9822415154  40.402446241  0.0035550411  5.7843055725  3200          0.6128425336 \n",
            "0.7010751628  0.6951460142  0.9990136122  0.9909234412  0.9988163346  0.9861878453  41.665022686  0.0019089536  5.7843055725  3300          0.6068048215 \n",
            "0.6945650030  0.6882399369  0.9980272243  0.9921073402  0.9973367528  0.9834254144  42.927599132  0.0025875226  5.7843055725  3400          0.6056645203 \n",
            "0.6307457092  0.6306235201  0.9983231407  0.9901341752  0.9983231407  0.9850039463  44.190175577  0.0029144936  5.7843055725  3500          0.6041939640 \n",
            "0.6258630894  0.6130623520  0.9967449201  0.9885556433  0.9945748668  0.9779005525  45.452752022  0.0030408603  5.7843055725  3600          0.6081425190 \n",
            "0.5861116591  0.5854380426  0.9983231407  0.9932912391  0.9974353916  0.9889502762  46.715328467  0.0074355744  5.7843055725  3700          0.6051037884 \n",
            "0.5610080884  0.5538674033  0.9996054449  0.9936858721  0.9992108897  0.9865824783  47.977904912  0.0062556131  5.7843055725  3800          0.6070308352 \n",
            "0.6838133754  0.6809392265  1.0000000000  0.9932912391  0.9996054449  0.9861878453  49.240481357  0.0056100457  5.7843055725  3900          0.6057835174 \n",
            "0.6621621622  0.6574585635  0.9999013612  0.9952644041  1.0000000000  0.9885556433  50.503057802  0.0001384602  5.7843055725  4000          0.6114358330 \n",
            "0.6933320181  0.7002762431  0.9992108897  0.9936858721  0.9980272243  0.9850039463  51.765634247  0.0033535963  5.7843055725  4100          0.6085151696 \n",
            "0.6670941014  0.6746250987  0.9943775893  0.9901341752  0.9904320379  0.9775059195  53.028210692  0.0065575427  5.7843055725  4200          0.6074985671 \n",
            "0.6663543105  0.6612075770  1.0000000000  0.9952644041  0.9993095285  0.9893449092  54.290787137  0.0063064979  5.7843055725  4300          0.6056443095 \n",
            "0.6553067666  0.6515390687  0.9990136122  0.9921073402  0.9972381140  0.9818468824  55.553363582  0.0017513336  5.7843055725  4400          0.6110575628 \n",
            "0.6878082462  0.6838989740  1.0000000000  0.9944751381  0.9998027224  0.9877663773  56.815940027  0.0004895418  5.7843055725  4500          0.6077594399 \n",
            "0.6921976721  0.6941594317  0.9999013612  0.9944751381  0.9998027224  0.9893449092  58.078516472  0.0008005026  5.7843055725  4600          0.6041522574 \n",
            "0.6831229039  0.6868587214  1.0000000000  0.9960536701  1.0000000000  0.9901341752  59.341092917  0.0001352327  5.7843055725  4700          0.6092551422 \n",
            "0.6647267706  0.6612075770  0.9995068061  0.9940805051  0.9992108897  0.9885556433  60.603669362  0.0007101557  5.7843055725  4800          0.6140078497 \n",
            "0.6588577629  0.6594317285  0.9996054449  0.9940805051  0.9996054449  0.9869771113  61.866245807  0.0047851269  5.7843055725  4900          0.6102016497 \n",
            "0.6555040442  0.6521310182  0.9995068061  0.9932912391  0.9993095285  0.9810576164  63.128822252  0.0046393169  5.7843055725  5000          0.6084288812 \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.train \\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224 \\\n",
        "       --algorithm ERM \\\n",
        "       --dataset SpawriousO2O_hard \\\n",
        "       --test_env 0 \\\n",
        "       --hparams '{\"batch_size\": 128, \"class_balanced\": false, \"data_augmentation\": true, \"lr\": 0.00016629177873519647, \"nonlinear_classifier\": false, \"arch\": \"resnet18\", \"resnet18\": true, \"resnet_dropout\": 0.1, \"weight_decay\": 1.1975155295174919e-06}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyPsM8-qTs"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/train_output /content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTeSXi_BAsw2",
        "outputId": "f8a407f0-e5b5-4577-e522-74fb8eb078eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                     | 0/2 [00:00<?, ?it/s]\r                                                                                \rTotal records: 102\n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   76.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: training-domain validation set\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   62.0 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: training-domain validation set\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        76.5 +/- 0.0               62.0 +/- 0.0               69.3                      \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   X                     X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: leave-one-domain-out cross-validation\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        X                          X                          X                         \n",
            "\n",
            "-------- Dataset: SpawriousO2O_medium, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   71.5 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Dataset: SpawriousO2O_hard, model selection method: test-domain validation set (oracle)\n",
            "Algorithm             Test                  SC_group_1            SC_group_2            Avg                  \n",
            "ERM                   65.6 +/- 0.0          X                     X                     X                    \n",
            "\n",
            "-------- Averages, model selection method: test-domain validation set (oracle)\n",
            "Algorithm                  SpawriousO2O_medium        SpawriousO2O_hard          Avg                       \n",
            "ERM                        71.5 +/- 0.0               65.6 +/- 0.0               68.5                      \n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.collect_results\\\n",
        "       --input_dir=/content/drive/MyDrive/ip/train_output_hard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxPRKSpd7tW",
        "outputId": "e0a98e3b-2119-4b5a-d89a-0b08cc774ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
            "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
            "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
            "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 74, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 78, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
            "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
            "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
            "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/pretty/stringpict.py\", line 15, in <module>\n",
            "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Colab执行train.py脚本\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py\\\n",
        "        --data_dir=./domainbed/data/MNIST/\\\n",
        "        --algorithm IGA\\\n",
        "        --dataset ColoredMNIST\\\n",
        "        --test_env 2\n",
        "\n",
        "#启动python3解释器，并且执行名为train.py的python脚本\n",
        "#--data_dir, --algorithm, --dataset, --text_env是train.py文件中的命令行参数，命令行参数用来制定程序或脚本执行书所需要的配置，选项或参数。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXA5s87_0FX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 读取图像\n",
        "img = cv2.imread('input_image.jpg')\n",
        "\n",
        "# 创建与输入图像相同大小的掩码\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "\n",
        "# 创建前景和背景模型\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "# 定义一个矩形ROI，用于指定图像中的前景对象\n",
        "rect = (50,50,450,290)\n",
        "\n",
        "# 使用GrabCut算法进行图像分割\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# 将掩码中的可能的前景和可能的背景区域设置为0和2\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# 将原始图像与掩码相乘以获取前景对象\n",
        "img = img*mask2[:,:,np.newaxis]\n",
        "\n",
        "# 显示结果\n",
        "cv2.imshow('Result', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8MAbsYPTOg",
        "outputId": "4e5ff9f9-5fbd-4dbc-8b46-79903673f419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=\"/env/python:/content/DomainBed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2tbOpWGPat2",
        "outputId": "f18a4248-822b-47e9-ae93-45ef19092c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"/env/python:/content/DomainBed\"\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLo5O4wdhf9",
        "outputId": "2f40c461-8185-4792-f68e-3a0b676773ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a5269aa7743b791c64ed6649418c057a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 575962639\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/173bf54d6d078902e3c95d84cd058342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 177603528\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/35d2062ac241826e2573114eb184c10b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1731344775\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 7.625215427542097e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.00047223799345445756\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/30fd34e2f4f278867b6ff5b3217c9af4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1643360463\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/93cbbc15feea120dcb5ef40876e5d339\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1552394041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b85999a8f7f51d5d4618de70657b6458\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 872123425\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7c7b782b06a6e854e2a90f87af941fab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1532722295\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ad9ee36f7c977d2e63461bd67f281f65\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1348154927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c6917ed9721df5093c80bb496ec569e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1049203149\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 12\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e09d3ae124ba408cc7b777e802abfc3b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 820509365\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.0061945703598755e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0003150750110930775\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ec6ad8a352a25d018524a0799865c9c7\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 305456027\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a12555295bb7c7f7b16f49fa46aa6d43\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 335001469\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3933a42f4a7daf484c66126f193511cd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1090282834\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e0caf4e9b7f63f5f2e9dfc9c2cbd706f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 707756686\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.7028930742148706e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00044832883881609976\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a8bfbb8d29ad30056577251d58640c92\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1803180728\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3e97244e0bba4eff7f3112b1a237b744\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 988398352\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.5948054187960416e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.2409030903340844e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c56965d1318c614519d8d1aeeec2acc0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1033766585\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/359830bd171b960b8f49828cf7daea45\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1062091682\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c71071003a4a8e03d31fbc73dc56b251\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1323517681\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4c21df39fbbbbff9e17a2219b8a0bdb4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 899531956\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.1059719178287245e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0226894592810383e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 17\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/144f7e007023484daf0f1835e105fa02\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1174342691\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00028242988155030726\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.0915251755880437e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/60e1b946d5dfb28c75817cb3b0f37895\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 894262147\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 15\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.768725917122619e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.692204119563736e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9e4750f5e7cdef36d12c41b1a6b11d8b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 430670040\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/d407d5a24ac774b5d0e87374d7bb0dcc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 939727439\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.641171042858528e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0010784038403040138\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9b1089b3fd6bf0f3ece44fc77e993b3e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 406951466\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/eb213ec0817439be32acdbd077992b09\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 471015569\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa8f08ae34d3dae732c41aa5d02c8316\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 534836152\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 39\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.6979523566141523e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.7644358744009473e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/48d90e374515bb88643f4e2e9410980b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1405017170\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.456280188921339e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.005463379786545902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/123c1a60dc113b3ef130905aab29cf61\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1450517853\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 8\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/6830b2706bf869ab62120c8ec8a3d902\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1428592723\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3826168925328977e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.615900325399353e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a928b33eb83a3c2cd3efa5ea3f1ea8d9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1629628786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/476612568012d54c53a90e62b696d7bb\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1884237580\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 19\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f87bb4114b1895f7916f2b4ffc4cb860\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 536959106\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 11\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.323285967621206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.046120234156778e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b796a096bf44125b17789f4408dca06b\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1903818547\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00013965806120050562\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.007283936884822311\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2eee150674bdf7a82d8c51eb4b1ce04a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 23433006\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/abc93fad1fd1056001dbadf8a1ca9e19\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1664885690\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1d6201f69bb66d8b6e489eda38dccc2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1064525671\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/61034eaa8320196809d9f605b075ea24\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 95358269\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.9943608091645206e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00048345143761565696\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a2a7ca35a2f50073f1242eb91762424c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1823278137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 34\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 6.801736841150391e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.046949588651311e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/09c50cd0748144c2769d47af395d8a2f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 809856719\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4134e9367b6221b835b22b88489a951d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 164181522\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 1\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dff4b52c83c4125df3323fd2db2b9f81\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 275388093\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.2352558725944602e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.9967320578799288e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b91c3a1a306c19c073d526f06d69ba03\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 216618918\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2c1b55962114ca954a4293b359288011\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 441369813\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5f9a4b767b89224a4075aee4b86b6256\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2034037337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002383446436179699\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 6.431270010222042e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/8b64798c53a5a1bba405d5c75dbf27e9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 693005437\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4b0c702dd74c39ad2ca842e5f3fc8ffc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1721323264\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/5c18fb7899bf0c12dc359ebe9c1081d6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 244140596\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 15\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a44e96d250f70e7917800a5786e1f2fe\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 338717337\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00026243770328490603\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 4.1401051799998815e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7d28429d6d35cc9f06f22e3a55845051\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1588968328\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 19\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002748180350891229\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.9000025480760227e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/991425b1146b1f446d84b36c087a6ef2\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 895393786\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/23a434a5febeed79a9ed9afeeb610ea9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1005706515\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/e31aa2e37b983f5aa514b6243bb897e4\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 539823350\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 40\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001653813153854724\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.7643974709171963e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/97caedc9c298c79240b7148e65bd4864\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 848241137\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.827610691196775e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 2.240269970837554e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/37de55f16c6cadbf954bb9c28018c6c9\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1441525987\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f1b86d2e19fa131d32841fa95fc15428\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1025341559\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.079846025444368e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.634713155314057e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84459224cbcb079b22304c4ca0337b15\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 658930196\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/840cda333a109b446d2d0be1aec01f44\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 797173368\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.800456552908177e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.447522981440824e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/0db98c8fc5bbd3ad85f5198cd2a9e242\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1690752950\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 43\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.164032944108835e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0008766809489187495\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 9\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/00bb81be3e5faa7fa0e06a3d1b9fc214\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 640543768\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 35\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.203148467315319e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.5941595326730853e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a3cf6270845a5d9f19504a02c74d48d8\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 527331476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 12\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0001336817295222666\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 1.696474495087739e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b719be2f2334c73ca22825242a857d83\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 794168150\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/84dc1acf1587fab8013f239b8ee2a854\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 140411788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 10\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00021342049430752089\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.621412012322581e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3b7e19147f067cefd3e300112c5744d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 889114309\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/2bd0763b666af3a8b7180488e49f5df1\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1600026954\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 13\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/ee01751ed5822f49800f2dff6d39011c\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 652031788\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.282920045772228e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 2.900002872985468e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 18\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a1fc347c08f7519f1a9885e2e4e1cc5a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2028568414\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 29\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.3636153892690768e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 3.365802104690301e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/3967520349d463cc0f4b42aa0e5a3cdc\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2011109722\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/a068a437f435df1e975b81101ea52090\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 887238287\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dcded23bc701bc64d1143bea8426fa7a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 874017095\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b338ef7ae36014cea7290002c49cdeab\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 397958724\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.151959487063697e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 5.08174262971335e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/7fcd0102087c6411f477f01e6e94adcd\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1653294381\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f5541915a154a7ea2d59d32511dca70e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1008122992\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f4402201077fefda135d3f266680fb9d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1974935474\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 17\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00030305970528800703\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.033510591502665e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fef9439cc09895fc8d5ed384d557aa2e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1905078720\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/21ce002219dcf5223be83527bc032575\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 16214241\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 25\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.6841898471378446e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.005100223533962902\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/fae278ee4d6005566e976812d300076e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1838315136\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.0002692684204277505\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.539788355410888e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 7\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/15aef282c233ccf23bb82500660e4a85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1806374394\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 22\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.451235671690321e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 7.61339855085641e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/95dcaf3d7552b20d324e650e8344e391\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2139648535\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/b59d08c5158891d095647c260599df72\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 863415268\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 27\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.000211416337488096\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 2.812885384798702e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/396a66c0e9a33f42933162e9e157a7f6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1028178153\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 2\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/40a2ab0a6403041f72bcd672cd9685a6\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2114559099\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 37\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.95623643291898e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002016579493930936\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/dd31f52ac86bba2d9ad1ffdeee34c342\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 2029184004\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 8\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00024427949008037697\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0001792475881200468\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 5\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9cb8aefc8442b126f9c05a7cce526779\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 902654909\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 4.057057661309337e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 4.206907223916248e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 16\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/398e724ba11d5f6f2445d5b356ace1b0\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1764407478\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 13\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.410293091771717e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 1.63495416553105e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 6\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4256491a7b9ddea5fd4f3b9404ed7948\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1041059927\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.3982210782681486e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0002915412147288415\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/aa922f8e301f7a452a7d7802449b8900\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1622227716\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/bc89363eaa59127ca10cf772d2c57263\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1192519524\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/56102dff2a7005ef5db4c5933673ea85\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 152054124\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 21\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00011281359420053416\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 5.000446907120253e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f3f28d0e95f209ff5df269857a136372\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 472711008\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 14\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4514b27fbe9c296ab91cd05de3734f5e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1704833476\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 0.00015197093111758464\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 1.0329604555494109e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 3\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/9222fb7e414cd07468f4347ff233885d\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 463949901\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 2\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 24\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 2.259509333895171e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0038093795402535276\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 4\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/4d35045a63b1eff681e8a628d2988b23\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 37332015\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 18\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 3.1375153221880086e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.0\n",
            "\tweight_decay: 6.326696718610415e-06\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/f936c2b44cc3dab85a923d914871cc4a\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1141715041\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 2]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 9\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 5.160583788372758e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 3.538451007661713e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 11\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/c08bd5bdc0e4a927433e11e6f552089e\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1353102125\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [0, 1]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 16\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 1.8411898397443895e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.1\n",
            "\tweight_decay: 0.0016077694551523362\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Environment:\n",
            "\tPython: 3.10.12\n",
            "\tPyTorch: 2.2.1+cu121\n",
            "\tTorchvision: 0.17.1+cu121\n",
            "\tCUDA: 12.1\n",
            "\tCUDNN: 8902\n",
            "\tNumPy: 1.25.2\n",
            "\tPIL: 9.4.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: /content/drive/MyDrive/ip/spawrious224\n",
            "\tdataset: SpawriousO2O_easy\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: None\n",
            "\thparams_seed: 10\n",
            "\toutput_dir: /content/MyDrive/ip/sweep_output/205162f67cb34c386d1288cf23a3e73f\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 1743459794\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [1, 2]\n",
            "\ttrial_seed: 1\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 33\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tlr: 9.123844754558304e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tresnet18: False\n",
            "\tresnet_dropout: 0.5\n",
            "\tweight_decay: 0.00023343984082907065\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 102, in <module>\n",
            "    dataset = vars(datasets)[args.dataset](args.data_dir,\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 517, in __init__\n",
            "    super().__init__(combinations['train_combinations'], combinations['test_combinations'], root_dir, hparams['data_augmentation'], type1=True)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 400, in __init__\n",
            "    train_datasets, test_datasets = self._prepare_data_lists(train_combinations, test_combinations, root_dir, augment)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 423, in _prepare_data_lists\n",
            "    train_data_list = self._create_data_list(train_combinations, root_dir, train_transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 446, in _create_data_list\n",
            "    data = CustomImageFolder(folder_path=path, class_index=self.class_list.index(cls), limit=limit, transform=transforms)\n",
            "  File \"/content/DomainBed/domainbed/datasets.py\", line 374, in __init__\n",
            "    self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ip/spawrious224/1/snow/corgi'\n",
            "Launched 360 jobs!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!PYTHONPATH=\"/env/python:/content/DomainBed\" python -m domainbed.scripts.sweep launch\\\n",
        "       --data_dir=/content/drive/MyDrive/ip/spawrious224\\\n",
        "       --output_dir=/content/MyDrive/ip/sweep_output\\\n",
        "       --command_launcher local\\\n",
        "       --algorithms ERM\\\n",
        "       --datasets SpawriousO2O_easy\\\n",
        "       --skip_confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr393evgOlTE",
        "outputId": "ace5ca35-edc0-49e3-ff67-4f086f769414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files and folders in directory: /content/domainbed/data\n",
            "MNIST\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 指定要查看的目录路径\n",
        "data_dir = '/content/domainbed/data'  # 这里替换为你下载数据的目录路径\n",
        "\n",
        "# 列出指定目录下的文件和文件夹\n",
        "files_and_folders = os.listdir(data_dir)\n",
        "\n",
        "# 输出文件和文件夹列表\n",
        "print(\"Files and folders in directory:\", data_dir)\n",
        "for item in files_and_folders:\n",
        "    print(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLTQ7T-5lgV"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peRMyZEz54u3",
        "outputId": "4d3a351e-775f-465a-a50d-86f28087b753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnjVjGVkZAQy"
      },
      "source": [
        "将所有图片转换成rgb形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZYfhASF-6u"
      },
      "outputs": [],
      "source": [
        "from datasets import SpawriousO2O_easy\n",
        "from datasets import SpawriousO2O_medium\n",
        "from datasets import SpawriousO2O_hard\n",
        "from datasets import SpawriousM2M_easy\n",
        "from datasets import SpawriousM2M_medium\n",
        "from datasets import SpawriousM2M_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hzsjtd9Fn2k"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/ip/spawrious224/\"\n",
        "hparams = {\"data_augmentation\": True}\n",
        "test_envs = 0\n",
        "spawrious_o2o_easy = SpawriousO2O_easy(root_dir, test_envs, hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ByCqk5tsF2L8",
        "outputId": "bee03919-976b-48c0-fa21-5842a7b81a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CHECKPOINT_FREQ', 'ENVIRONMENTS', 'INPUT_SHAPE', 'N_STEPS', 'N_WORKERS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_create_data_list', '_prepare_data_lists', 'build_type1_combination', 'build_type2_combination', 'class_list', 'datasets', 'input_shape', 'num_classes', 'type1']\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'build_type1_combination' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-d9a268ae9e32>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawrious_o2o_easy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_type1_combination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_type1_combination' is not defined"
          ]
        }
      ],
      "source": [
        "print(dir(spawrious_o2o_easy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "8bwrHD3Qsnwv",
        "outputId": "2062da6d-58a0-4ecd-e19d-3fbc65dac0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 3168/3168 [01:48<00:00, 29.17it/s]\n",
            "  4%|▍         | 136/3168 [00:32<12:02,  4.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-115b0497dc50>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0munloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnormalized_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk43pd2wZJ0M"
      },
      "source": [
        "寻找corgi类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUk9545INv",
        "outputId": "1c907d20-5c53-4e72-a511-78a91db9bbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corgi_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2441.png', 'drive/MyDrive/ip/spawrious224/1/jungle/corgi/jungle_corgi_2.png'), 'corgi')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "\n",
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/corgi/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "\n",
        "corgi_image_pairs = []\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    corgi_image_pairs.append((image_pair, 'corgi'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "\n",
        "# 将 corgi_image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(corgi_image_pairs, f)\n",
        "\n",
        "print(\"Corgi_image pairs saved successfully.\")\n",
        "print(corgi_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeA1A4ALZNYR"
      },
      "source": [
        "寻找bulldog类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyT3OSv5IQT",
        "outputId": "585e03c4-a5f5-45a1-c88f-c595dffa4f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Bulldog_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/bulldog/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "bulldog_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    bulldog_image_pairs.append((image_pair, 'bulldog'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(bulldog_image_pairs, f)\n",
        "\n",
        "print(\"Bulldog_image pairs saved successfully.\")\n",
        "print(bulldog_image_pairs[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZakjqAa0mfd",
        "outputId": "cb31c59b-f8c1-4cdc-c285-42c4174ee333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bulldog\n"
          ]
        }
      ],
      "source": [
        "print(bulldog_image_pairs[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5rsjqJZRZA"
      },
      "source": [
        "寻找dachshund类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECFZVVm5ISR",
        "outputId": "4ae21f17-ad08-4abf-b6b4-32a0599c1603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "Dachshund_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/dachshund/jungle_dachshund_2902.png', 'drive/MyDrive/ip/spawrious224/0/dirt/dachshund/dirt_dachshund_343.png'), 'dachshund')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/dachshund/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "dachshund_image_pairs=[]\n",
        "\n",
        "# 遍历每个图像路径，提取种类信息，并将图像路径与种类信息组合成元组，加入 corgi_image_pairs 列表中\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    dachshund_image_pairs.append((image_pair, 'dachshund'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(dachshund_image_pairs, f)\n",
        "\n",
        "print(\"Dachshund_image pairs saved successfully.\")\n",
        "print(dachshund_image_pairs[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rg9-OhsZW5L"
      },
      "source": [
        "寻找labrador类的配对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJlI-7ZYi36",
        "outputId": "46c742ff-2dfa-4b2b-b784-b0159d897f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38016\n",
            "labrador_image pairs saved successfully.\n",
            "(('drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_1201.png', 'drive/MyDrive/ip/spawrious224/1/jungle/labrador/jungle_labrador_563.png'), 'labrador')\n"
          ]
        }
      ],
      "source": [
        "folder_paths = glob.glob(f\"drive/MyDrive/ip/spawrious224/**/labrador/**\", recursive=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    image_paths.extend(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
        "print(len(image_paths))\n",
        "\n",
        "labrador_image_pairs=[]\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image_pair = (image_path, random.choice(image_paths))  # 随机选择另一张图像作为配对\n",
        "    labrador_image_pairs.append((image_pair, 'labrador'))\n",
        "\n",
        "save_path = 'drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "# 将 image_pairs 序列化并保存到文件中\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(labrador_image_pairs, f)\n",
        "\n",
        "print(\"labrador_image pairs saved successfully.\")\n",
        "print(labrador_image_pairs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXZrnXz155UP",
        "outputId": "53e9bcbf-5edf-4b44-ca94-7e3105e3d6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_84.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1530.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_767.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1743.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2387.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_760.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_277.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_726.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2953.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_108.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3163.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2315.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2777.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1187.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_453.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_15.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2413.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_561.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_924.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_232.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1990.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2670.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1076.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_72.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1741.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2743.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_239.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_325.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1091.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_570.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_358.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_892.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3150.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2448.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3015.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_186.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1691.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1509.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_642.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1888.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_150.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2282.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3003.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1379.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2980.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2456.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2364.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2308.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_248.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2026.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2679.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_2952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_307.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2849.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1887.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3136.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2786.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_3000.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_470.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2965.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_791.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2599.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3161.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1707.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1886.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_830.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2378.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_916.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_768.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2295.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2137.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1126.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2966.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1845.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_418.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_232.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2885.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1513.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2699.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1051.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_159.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2067.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2853.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_98.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2226.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1131.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1441.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2613.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2625.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_877.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_424.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2505.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_2908.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_535.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1043.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_663.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1536.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1818.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1616.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2796.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_376.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1318.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_261.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1939.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1933.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2282.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_1356.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_6.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_222.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2452.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2738.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1883.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2041.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1149.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_895.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3084.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_167.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2461.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2204.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1463.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2982.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_541.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1523.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_2483.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1299.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_867.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2379.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_1309.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2053.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2740.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_920.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_2389.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2985.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_2435.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_803.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1697.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_291.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1006.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1563.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_1796.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1753.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2466.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_935.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_2864.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1505.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_772.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1364.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3008.png', 'drive/MyDrive/ip/spawrious224/1/dirt/bulldog/dirt_bulldog_2936.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_364.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_1347.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_797.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_1124.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1574.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_1934.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2514.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_52.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1388.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_2320.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2129.png', 'drive/MyDrive/ip/spawrious224/1/mountain/bulldog/mountain_bulldog_3076.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1084.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_1468.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_329.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_89.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2630.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_2588.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2372.png', 'drive/MyDrive/ip/spawrious224/0/dirt/bulldog/dirt_bulldog_1952.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_730.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_2140.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2166.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_3046.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1634.png', 'drive/MyDrive/ip/spawrious224/0/snow/bulldog/snow_bulldog_1942.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_839.png', 'drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_473.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_420.png', 'drive/MyDrive/ip/spawrious224/0/jungle/bulldog/jungle_bulldog_30.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2847.png', 'drive/MyDrive/ip/spawrious224/1/beach/bulldog/beach_bulldog_2576.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2185.png', 'drive/MyDrive/ip/spawrious224/1/desert/bulldog/desert_bulldog_923.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1769.png', 'drive/MyDrive/ip/spawrious224/0/desert/bulldog/desert_bulldog_508.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_486.png', 'drive/MyDrive/ip/spawrious224/0/mountain/bulldog/mountain_bulldog_3099.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1973.png', 'drive/MyDrive/ip/spawrious224/1/snow/bulldog/snow_bulldog_244.png'), 'bulldog'), (('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_2066.png', 'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3054.png'), 'bulldog')]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# 打开 .pkl 文件\n",
        "file_path = 'drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 查看文件中的数据\n",
        "print(data[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaxZX0939Vu",
        "outputId": "88087c2c-bcfe-4b6a-a3f4-22a7b0ea6311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('drive/MyDrive/ip/spawrious224/1/jungle/bulldog/jungle_bulldog_1061.png',\n",
              "  'drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_3059.png'),\n",
              " 'bulldog')"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 定义一个函数来加载单个 .pkl 文件\n",
        "def load_pkl(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "# 定义多个 .pkl 文件夹的路径\n",
        "file1='drive/MyDrive/ip/bulldog_image_pairs.pkl'\n",
        "file2='drive/MyDrive/ip/corgi_image_pairs.pkl'\n",
        "file3='drive/MyDrive/ip/dachshund_image_pairs.pkl'\n",
        "file4='drive/MyDrive/ip/labrador_image_pairs.pkl'\n",
        "\n",
        "file_paths = [file1, file2, file3, file4]\n",
        "\n",
        "# 合并\n",
        "merged_data = []\n",
        "for file_path in file_paths:\n",
        "    data = load_pkl(file_path)\n",
        "    merged_data.extend(data)\n",
        "\n",
        "\n",
        "merged_data[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG4ZrbJW7gNT"
      },
      "source": [
        "定义图像变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fnPAS-3b7ff1",
        "outputId": "3a41426e-6d81-4bfb-b9cb-59838d2ff4ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 62094/152064 [15:29<22:26, 66.80it/s]    \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-c26271761609>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtransformed_image_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtransformed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 定义图像变换\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整大小为 224x224\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 对 merged_data 中所有图片路径应用变换\n",
        "transformed_data = []\n",
        "for image_pair, category in tqdm(merged_data):\n",
        "    transformed_image_pair = (transform(Image.open(image_pair[0])), transform(Image.open(image_pair[1])))\n",
        "    transformed_data.append((transformed_image_pair, category))\n",
        "\n",
        "# 输出变换后的数据\n",
        "print(transformed_data[1])\n",
        "\n",
        "\n",
        "dataloader = DataLoader(transformed_data, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsDg8lb7Lo9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "# 定义自定义数据集类\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 定义 ResNet18 模型\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)  # 修改最后一层全连接层，输出为2类（假设是二分类任务）\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 准备数据集\n",
        "image_paths = ['path/to/image1.jpg', 'path/to/image2.jpg', ...]  # 假设这里是你的图像数据集路径列表\n",
        "transform = transforms.Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "dataset = CustomDataset(image_paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, batch_images in enumerate(dataloader):\n",
        "        inputs = batch_images\n",
        "        labels = torch.randint(0, 2, (batch_images.size(0),))  # 假设这里是随机生成的标签\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # 每 10 个 mini-batch 输出一次损失值\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UR2Se1J7LrL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCvom3K7LtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dSlXY-7LvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar0YMs7R7LxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQW2CdWBYwpu",
        "outputId": "c5e3a98e-6ec4-445d-b016-181739cbdc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image size is 224 pixels wide by 224 pixels high.\n"
          ]
        }
      ],
      "source": [
        "# 替换下面的路径为你图像的实际路径\n",
        "image_path = '/content/drive/My Drive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png'\n",
        "\n",
        "# 加载图像\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# 获取图像的大小\n",
        "width, height = img.size\n",
        "\n",
        "# 打印图像的大小\n",
        "print(f'The image size is {width} pixels wide by {height} pixels high.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWiRyFGtY8iJ",
        "outputId": "5bc07ce5-0670-4e35-910a-e2d5bbc58c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'spawrious224_rgb': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 定义转换：归一化和转换为Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "input_folder_path = '/content/drive/MyDrive/ip/spawrious224/**/corgi/'\n",
        "output_folder_path = '/content/drive/MyDrive/ip/spawrious224_normalized'  # 新的文件夹路径\n",
        "\n",
        "\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "for root, dirs, files in os.walk(input_folder_path):\n",
        "    for file in tqdm(files):\n",
        "        input_file_path = os.path.join(root, file)\n",
        "        output_file_path = os.path.join(output_folder_path, file)  # 新的文件路径\n",
        "\n",
        "        image = Image.open(input_file_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        transformed_image = transform(image)\n",
        "\n",
        "        # 保存归一化后的图像到新文件夹\n",
        "        unloader = transforms.ToPILImage()\n",
        "        normalized_image = unloader(transformed_image)\n",
        "        normalized_image.save(output_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56vrZ45Ywri"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 提取特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 定义图像预处理步骤\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 调整图像大小为 ResNet18 模型的输入大小\n",
        "    transforms.ToTensor(),  # 将图像转换为 Tensor 格式\n",
        "])\n",
        "\n",
        "# 加载 RGB 图像并进行预处理\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 添加 batch 维度，变成一个大小为 (1, C, H, W) 的 Tensor\n",
        "\n",
        "# 将图像输入到 ResNet18 模型中，并提取全局平均池化层的输出\n",
        "with torch.no_grad():\n",
        "    features = feature_extractor(input_batch)\n",
        "\n",
        "# 将特征转换为一个向量（reshape 为 (1, num_features)）\n",
        "global_avg_pooling_output = features.view(features.size(0), -1)\n",
        "\n",
        "# 输出向量的大小\n",
        "print(\"Global Average Pooling Output Shape:\", global_avg_pooling_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHUMXcfxBRH",
        "outputId": "5023f978-9943-4b52-db95-3917306e8d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape: torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH72AAHsxBTv",
        "outputId": "a309654e-c496-4611-d74e-d199df8e5239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor Output Shape (with pooling): torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# 加载预训练的 ResNet18 模型\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 获取 ResNet18 模型的特征提取部分（不包括最后一层全连接层）\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])\n",
        "\n",
        "# 随机生成一个输入图像用于测试\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # 假设输入图像大小为 224x224，通道数为 3（RGB）\n",
        "\n",
        "# 将输入图像传入特征提取部分\n",
        "features = feature_extractor(input_tensor)\n",
        "\n",
        "# 打印特征提取部分的输出维度\n",
        "print(\"Feature Extractor Output Shape:\", features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp4djmqsxBWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ7JRGRmxBYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2sOryq0lgGL",
        "outputId": "aef2dd6a-3c69-42b0-e04c-713082b138eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
            "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
            "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
            "        ...,\n",
            "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
            "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
            "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]],\n",
            "       requires_grad=True)\n",
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# 加载预训练的 ResNet-18 模型\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 截取特征提取器部分（不包括最后的全连接层）\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "weights=model.fc.weight\n",
        "print(weights)\n",
        "print(len(weights))\n",
        "\n",
        "\n",
        "\n",
        "# 加载并预处理上传的两张图片数据\n",
        "image1_path = 'path/to/your/first/image.jpg'\n",
        "image2_path = 'path/to/your/second/image.jpg'\n",
        "image1 = preprocess_image(image1_path)\n",
        "image2 = preprocess_image(image2_path)\n",
        "\n",
        "# 提取图片的特征向量\n",
        "with torch.no_grad():\n",
        "    feature1 = feature_extractor(image1)\n",
        "    feature2 = feature_extractor(image2)\n",
        "\n",
        "# 对提取的特征向量进行全局平均池化操作\n",
        "global_avg_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "feature1_vector = global_avg_pool(feature1).squeeze()\n",
        "feature2_vector = global_avg_pool(feature2).squeeze()\n",
        "\n",
        "# 打印两个特征向量\n",
        "print(\"Feature vector for image 1:\", feature1_vector)\n",
        "print(\"Feature vector for image 2:\", feature2_vector)\n",
        "\n",
        "\n",
        "# 定义损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#定义损失函数\n",
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "\n",
        "        # 自定义损失函数的计算过程，这里假设是平方误差损失\n",
        "        loss = torch.mean((output - target)**2)\n",
        "        return loss\n",
        "\n",
        "#定义损失函数\n",
        "def loss():\n",
        "  lam_loss_all=0\n",
        "  for i in range(batch_size):\n",
        "\toriginal=Feature map[i]\n",
        "\tpair=Feature map[10+i]\n",
        "        y_1=y[i]\n",
        "        w=Classification head weight[y_1]**2\n",
        "\tdistance=(original-pair)**2\n",
        "        lam_loss=0\n",
        "        For k 1to 2048:\n",
        "              lam_loss+=w[I]*distance[I]\n",
        "\tlam_loss_all+=lam_loss\n",
        "\n",
        "lam_loss_all/=10\n",
        "\n",
        "loss=erm_loss+lambda*lam_loss_all\n",
        "\n",
        "#开始训练\n",
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # 解压当前 batch 中的图片对\n",
        "        images1, images2 = batch\n",
        "\n",
        "        # 前向传播\n",
        "        outputs1 = model(images1)\n",
        "        outputs2 = model(images2)\n",
        "\n",
        "        feature1 = feature_extractor(images1)\n",
        "        feature2 = feature_extractor(images2)\n",
        "\n",
        "        # 计算损失\n",
        "        loss = loss_fn(outputs1, outputs2)\n",
        "\n",
        "        # 反向传播与参数更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 打印当前损失\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# 定义优化器，并将所有参数添加到优化器中\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 训练过程中的损失计算示例\n",
        "# 假设 inputs 是模型的输入数据，targets 是真实标签\n",
        "#outputs = model(inputs)\n",
        "\n",
        "\n",
        "#loss = criterion(outputs, targets)\n",
        "\n",
        "# 反向传播与参数更新\n",
        "#optimizer.zero_grad()\n",
        "#loss.backward()\n",
        "#optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8AYk6QV59s0",
        "outputId": "1d1fd7af-edde-41d9-f342-9d9d3297ec39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "images = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_0.png\")\n",
        "inputs = processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "image_features = model.get_image_features(**inputs)\n",
        "image_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRBhDp1-EQK",
        "outputId": "db7e1d1e-4b2b-46dc-db74-248de8d8e3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8947], grad_fn=<SumBackward1>)\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(\"drive/MyDrive/ip/spawrious224/0/beach/bulldog/beach_bulldog_6.png\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
        "other_features = model.get_image_features(**inputs)\n",
        "\n",
        "\n",
        "\n",
        "similarity = torch.cosine_similarity(image_features, other_features, dim=1)\n",
        "print(similarity)\n",
        "\n",
        "#similar_images.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNpx89JdYAW"
      },
      "outputs": [],
      "source": [
        "# tensor --> numpy array\n",
        "# 10*768 --> 10*10\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "pairwise_cos=cosine_similarity(all_features_image0, all_features_image0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzY4-Bg9amE0",
        "outputId": "2c8648e7-753e-4e45-f242-874989629e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The path of the file is: /content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 要查找的文件名\n",
        "filename = 'train.py'\n",
        "\n",
        "# 使用 os.walk() 函数遍历文件系统，查找文件\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    if filename in files:\n",
        "        file_path = os.path.join(root, filename)\n",
        "        print(\"The path of the file is:\", file_path)\n",
        "        break\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll4ydb8Tf1ZL"
      },
      "outputs": [],
      "source": [
        "import domainbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHz6ikvEbKB4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# 将当前工作目录添加到模块搜索路径中\n",
        "sys.path.append('/content/DomainBed/domainbed/scripts')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXILhm1Z5Lu",
        "outputId": "bc18d9c5-2477-4aec-db5a-4a9f44a6515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DomainBed/domainbed/scripts/train.py\", line 18, in <module>\n",
            "    from domainbed import datasets\n",
            "ModuleNotFoundError: No module named 'domainbed'\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/DomainBed/domainbed/scripts')\n",
        "\n",
        "\n",
        "\n",
        "!python3 /content/DomainBed/domainbed/scripts/train.py  --data_dir=./domainbed/data/mnist_data/MNIST/MNIST/raw\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHZs22kIHITz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEui0DbG2T-"
      },
      "outputs": [],
      "source": [
        "import domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ccrCEUpIe3U",
        "outputId": "973b3d5a-7e54-40c2-c79f-c33db6b566b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "import domainbed.scripts.train\n",
        "print(domainbed.scripts.train.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_8DJU6GQkP",
        "outputId": "647d4860-e9ce-4939-ed22-e6fbcbf2c271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6nF9hh2B20I"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/DomainBed/domainbed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpBUtnGDDP_T",
        "outputId": "e0bdf4c4-f6a2-4ee1-c05c-469b1ac9223c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "domainbed 模块已经上传到 Colab 环境中。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 列出当前目录下的文件和文件夹\n",
        "files_and_folders = os.listdir()\n",
        "\n",
        "# 检查是否有 domainbed 相关的文件或者文件夹存在\n",
        "if 'DomainBed' in files_and_folders:\n",
        "    print(\"domainbed 模块已经上传到 Colab 环境中。\")\n",
        "else:\n",
        "    print(\"domainbed 模块未上传到 Colab 环境中，请上传该模块。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "U73FCwSYCtHs",
        "outputId": "9eedd15b-ca7a-44e8-9c8a-62b6fc3c7c1e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'DomainBed.scripts'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-671f19c45cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDomainBed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DomainBed.scripts'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import DomainBed.scripts.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104WHdolBMr9",
        "outputId": "9532160a-2771-495f-edbe-236058077489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'domainbed.scripts.train' (ModuleNotFoundError: No module named 'domainbed')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m domainbed.scripts.train\\\n",
        "       --data_dir=/content/DomainBed/domainbed/data/MNIST/\\\n",
        "       --algorithm IGA\\\n",
        "       --dataset ColoredMNIST\\\n",
        "       --test_env 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-wDOYOGcrBd",
        "outputId": "1c155a51-cb25-4d33-cef8-b9d66beba886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CODE_OF_CONDUCT.md  CONTRIBUTING.md  domainbed\tLICENSE  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tpA8g5crEd",
        "outputId": "4c37650f-6c66-41ca-a43b-a054019e7395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DomainBed/domainbed\n"
          ]
        }
      ],
      "source": [
        "%cd domainbed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOpMP-JYcrG8",
        "outputId": "a5671b8c-1378-43db-800d-025f0fd06a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/DomainBed/domainbed/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9j-jXU4qnV",
        "outputId": "9a47a5e4-38bc-4ad0-9e0a-116112baebe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=c2d66b9d68e869eab2d7fb0ceb797bc93c5a2eba8da460ac75e6fa1222eaeafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Pwi1MG4s0Q"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLqCJYk6Z-H"
      },
      "outputs": [],
      "source": [
        "sc = SparkContext(\"local\", \"Example App\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoTkcfW9crKX",
        "outputId": "51c83067-2d6c-4cfe-ab10-a058f03451b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = sc.parallelize(range(1, 100))\n",
        "t = 50\n",
        "B = A.filter(lambda x: x < t)\n",
        "B.cache()\n",
        "t = 10\n",
        "\n",
        "C = B.filter(lambda x: x > t)\n",
        "\n",
        "print(C.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722a2LCPcrMx",
        "outputId": "dc6f003d-0d78-4ad2-94f9-3dddb67f9ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product: 233\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "def dot_product(rdd1, rdd2):\n",
        "  zipped_rdd = rdd1.zip(rdd2)\n",
        "  dot_product = zipped_rdd.map(lambda x: x[0]*x[1]).reduce(lambda x,y:x+y)\n",
        "  return dot_product\n",
        "\n",
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "result = dot_product(r1, r2)\n",
        "print(\"Dot product:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_pdehnc-7kN6",
        "outputId": "0bfc6140-a0ec-4ffd-895c-cef3f0637ee2"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e471822f655>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the total dot product by summing up the partial results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtotal_dot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_product_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dot product:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_dot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 8) (7a67d335b174 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\", line 1919, in func\n    initial = next(iterator)\n  File \"<ipython-input-19-0e471822f655>\", line 10, in compute_dot_product\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 339, in _load_stream_without_unbatching\n    raise ValueError(\nValueError: Can not deserialize PairRDD with different number of items in batches: (3, 2)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "r1 = sc.parallelize([4, 2, 3, 1, 3, 4, 5, 6, 7, 8, 5], 3)\n",
        "r2 = sc.parallelize([1, 3, 4, 5, 6, 7, 3, 5, 4, 9, 3], 3)\n",
        "\n",
        "# Induce a different partitioning\n",
        "r2 = r2.flatMap(lambda x: [] if x == 1 else [x])\\\n",
        "       .flatMap(lambda x: [9, 9] if x == 9 else [x])\n",
        "\n",
        "def compute_dot_product(partition):\n",
        "    partial_sum = 0\n",
        "    for x, y in partition:\n",
        "        partial_sum += x * y\n",
        "    yield partial_sum\n",
        "\n",
        "dot_product_rdd = r1.zip(r2).mapPartitions(compute_dot_product)\n",
        "\n",
        "# Compute the total dot product by summing up the partial results\n",
        "total_dot_product = dot_product_rdd.reduce(lambda x, y: x + y)\n",
        "\n",
        "print(\"Dot product:\", total_dot_product)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "faf0203ade3e4d6d95de506945873501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2473c911f9934e4ab801f1e91dd49182",
              "IPY_MODEL_dc04e368de3e48b4b2837591490e1bc1",
              "IPY_MODEL_7f9931b24ac44650b3652d44d6cf0aa4"
            ],
            "layout": "IPY_MODEL_98ce801c92a240f2ab8b887f6c42145f"
          }
        },
        "2473c911f9934e4ab801f1e91dd49182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595a936ef28246309976d12e3aa84168",
            "placeholder": "​",
            "style": "IPY_MODEL_d24e944b880c49728193b32a79ddf541",
            "value": "config.json: 100%"
          }
        },
        "dc04e368de3e48b4b2837591490e1bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dda789eab754f2c8607c93c867c348a",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7015de9f4e974759ba4d63683a026711",
            "value": 4186
          }
        },
        "7f9931b24ac44650b3652d44d6cf0aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82eafc40c2e546d787830b1203f30c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb9f02ac3a348f7ad96a3adfa757934",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 316kB/s]"
          }
        },
        "98ce801c92a240f2ab8b887f6c42145f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595a936ef28246309976d12e3aa84168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24e944b880c49728193b32a79ddf541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dda789eab754f2c8607c93c867c348a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7015de9f4e974759ba4d63683a026711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82eafc40c2e546d787830b1203f30c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb9f02ac3a348f7ad96a3adfa757934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "556464689c8d4e218b42c74e17cc9915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f08024ab1c6e4ae8a67abe3557c67330",
              "IPY_MODEL_68de135480854c139c5099eb157ca40a",
              "IPY_MODEL_b7f4bb79f0534854b07904889e6ecf3f"
            ],
            "layout": "IPY_MODEL_26c378ba460243ac99cfa9ac6df6172c"
          }
        },
        "f08024ab1c6e4ae8a67abe3557c67330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f889a2302ed041df8eb8b0ffe1744504",
            "placeholder": "​",
            "style": "IPY_MODEL_65a83793b69e4e5d859405944642c501",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "68de135480854c139c5099eb157ca40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51769e5b2c3742fa85bf1c7acb3c8d6c",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58dcbfcb64184f3596903ae08236d284",
            "value": 605247071
          }
        },
        "b7f4bb79f0534854b07904889e6ecf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7e7eee1fa24b5faed7fae7530d5aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b704eca4f374935b0124622d1217ff8",
            "value": " 605M/605M [00:02&lt;00:00, 239MB/s]"
          }
        },
        "26c378ba460243ac99cfa9ac6df6172c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f889a2302ed041df8eb8b0ffe1744504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a83793b69e4e5d859405944642c501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51769e5b2c3742fa85bf1c7acb3c8d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58dcbfcb64184f3596903ae08236d284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff7e7eee1fa24b5faed7fae7530d5aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b704eca4f374935b0124622d1217ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}